{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "augment_wikitable_context.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "02Rn-fDWOcFs"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "import codecs\n",
        "from template_config import *\n",
        "from nltk import word_tokenize\n",
        "from collections import defaultdict\n",
        "from transformers.tokenization_roberta import RobertaTokenizer\n",
        "\n",
        "SEP_TOKEN = \"</s>\"\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "MAX_TOKEN_LEN = 189"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRWIkNJnOcFv"
      },
      "source": [
        "### Read tables from text files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwFgJmCVOcFx"
      },
      "source": [
        "train_corpus = \"data/wikitable_dup1_row1.txt\"\n",
        "# output_file = \"data/data_comb_tables.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0w-HMUZOcFx"
      },
      "source": [
        "def hasNumbers(inputString):\n",
        "    return any(char.isdigit() for char in inputString)\n",
        "\n",
        "def check_name(inpStr):\n",
        "    return len(inpStr) > 1 and \"-\" not in inpStr and not hasNumbers(inpStr)\n",
        "\n",
        "def gen_name(title, must_have=False):\n",
        "    title_tokens = title.split(\" \")\n",
        "    qualify_words = []\n",
        "    for w in title_tokens:\n",
        "        if check_name(w):\n",
        "            qualify_words.append(w)\n",
        "    \n",
        "    if random.random() < 0.4:\n",
        "        name = \" \".join(qualify_words[-2:])\n",
        "    else:\n",
        "        name = \" \".join(qualify_words[-1:])\n",
        "    \n",
        "    if name != \"\":\n",
        "        return name\n",
        "    \n",
        "    if must_have:\n",
        "        return title_tokens[0]\n",
        "    else:\n",
        "        return name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m3NBYCvOcFy"
      },
      "source": [
        "def main_process(train_corpus):\n",
        "    total_count = 0\n",
        "    webtables = []\n",
        "    with open(train_corpus, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            skip = False\n",
        "            if total_count % 100000 == 0:\n",
        "                print(\"processed: \", total_count)\n",
        "            tokens = line.lower().replace(\"<special7>\", \"<tabn>\").replace(\"<special8>\", \"<coln>\").replace(\"<special9>\", \"<entry>\").replace(\"*\", \"\").replace(\"|||\", \"\")\n",
        "            table = {\"columns\": [], \"values\": [], \"columns_original\": [], \"column_types\": []}\n",
        "            chunks = tokens.split(\" <coln> \")\n",
        "            for chunk in chunks:\n",
        "                if \"<tabn>\" in chunk:\n",
        "                    page_title = chunk.replace(\"<tabn>\", \"\").strip()\n",
        "                    table_name = gen_name(page_title)\n",
        "                    table[\"name\"] = table_name\n",
        "                    if table_name == \"\" or len(table_name) < 2:\n",
        "                        skip = True\n",
        "                else:\n",
        "                    assert \"<entry>\" in chunk\n",
        "                    chunk_toks = chunk.split(\" <entry> \")\n",
        "                    if len(chunk_toks) == 2:\n",
        "                        col_name, entry = chunk_toks[0].strip(), chunk_toks[1].strip()\n",
        "                        if len(col_name) > 1:\n",
        "                            table[\"columns\"].append(\" \".join(col_name.split(\" \")[:5]))\n",
        "                            table[\"columns_original\"].append(col_name)\n",
        "                            ctype = \"text\"\n",
        "                            if entry.isdigit():\n",
        "                                ctype = \"real\"\n",
        "                            table[\"column_types\"].append(ctype)\n",
        "                            table[\"values\"].append(\" \".join(entry.split(\" \")[:5]))\n",
        "                            \n",
        "            \n",
        "            if len(table[\"columns\"]) < 3:\n",
        "                skip = True\n",
        "            if not skip:\n",
        "                table_name = table[\"name\"]\n",
        "                table[\"columns\"] = [table_name + \" *\"] + table[\"columns\"]\n",
        "                table[\"columns_original\"] = [\"*\"] + table[\"columns_original\"]\n",
        "                table[\"column_types\"] = [\"text\"] + table[\"column_types\"]\n",
        "                table[\"values\"] = [\"all\"] + table[\"values\"]\n",
        "                tabn_str = \"_\".join(table_name.split(\" \"))\n",
        "                table[\"columns\"] = [tabn_str +\" \"+ hd for hd in table[\"columns\"]]\n",
        "                if \"*\" not in table['columns'][0]:\n",
        "                    print(table['columns'])\n",
        "                webtables.append(table)\n",
        "                \n",
        "            total_count += 1\n",
        "            \n",
        "    return webtables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4hwvdtFOcFz",
        "outputId": "15a2febb-53b2-4c35-f5b1-007362bebed5"
      },
      "source": [
        "web_tables = main_process(train_corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processed:  0\n",
            "processed:  100000\n",
            "processed:  200000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRgpd08cOcF0",
        "outputId": "2c404aad-3a32-489b-da00-51b4b6f148d2"
      },
      "source": [
        "web_tables[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'columns': ['transit transit *',\n",
              "  'transit order year',\n",
              "  'transit manufacturer',\n",
              "  'transit model',\n",
              "  'transit fleet series ( quantity )',\n",
              "  'transit powertrain ( engine/transmission )',\n",
              "  'transit fuel propulsion'],\n",
              " 'values': ['all',\n",
              "  '1111-11',\n",
              "  'gillig',\n",
              "  'phantom ( high floor )',\n",
              "  '111-111 ( 11 )',\n",
              "  'dd s10egr allison wb-100r',\n",
              "  'diesel'],\n",
              " 'columns_original': ['*',\n",
              "  'order year',\n",
              "  'manufacturer',\n",
              "  'model',\n",
              "  'fleet series ( quantity )',\n",
              "  'powertrain ( engine/transmission )',\n",
              "  'fuel propulsion'],\n",
              " 'column_types': ['text', 'text', 'text', 'text', 'text', 'text', 'text'],\n",
              " 'name': 'transit'}"
            ]
          },
          "execution_count": 694,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifSEEhX9OcF1"
      },
      "source": [
        "### Read NL-SQL templates and sql component mapping file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nT0hIAZOcF1"
      },
      "source": [
        "MAX_COL_NUM = 25\n",
        "OPS = [\"=\", \">\", \"<\", \">=\", \"<=\", \"!=\", \"LIKE\"]\n",
        "nlsql_templates_file = \"data/nlsql_templates_context.txt\"\n",
        "nlsql_templates_iso_file = \"data/nlsql_templates.txt\"\n",
        "sql_components_file = \"data/sql_components.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc1rE8gJOcF2"
      },
      "source": [
        "# read NL-SQL templates\n",
        "templates = []\n",
        "with open(nlsql_templates_file) as fp:\n",
        "    lines = fp.readlines()\n",
        "    template_one = {}\n",
        "    for line in lines:\n",
        "        if \"\\n\" == line:\n",
        "            templates.append(template_one) \n",
        "        elif \"SQL Pattern:\" in line:\n",
        "            template_one = {}\n",
        "            sps = line.strip().replace(\"SQL Pattern: \", \"\").split(\"|||\")\n",
        "            template_one[\"questions\"] = []\n",
        "            if len(sps) == 1:\n",
        "                template_one[\"SQL pattern\"] = sps[0]\n",
        "                template_one[\"SQL constraints\"] = []\n",
        "            elif len(sps) == 2:\n",
        "                template_one[\"SQL pattern\"] = sps[0]\n",
        "                template_one[\"SQL constraints\"] = [x.strip() for x in sps[1].split(\"|\") if x != \" \"]\n",
        "            else:\n",
        "                print(\"\\n======Error warning!!!!\")\n",
        "        elif \"count: \" in line:\n",
        "            sql_count = int(line.strip().replace(\"count: \", \"\"))\n",
        "            template_one[\"count\"] = sql_count\n",
        "        elif \"question:  \" in line:\n",
        "            sps = line.strip().replace(\"question:  \", \"\").split(\"|||\")\n",
        "            question = sps[0]\n",
        "            if len(sps) == 2:\n",
        "                q_constraints = [x.strip() for x in sps[1].split(\"|\") if x != \" \"]\n",
        "            else:\n",
        "                q_constraints = []\n",
        "            template_one[\"questions\"].append((question, q_constraints))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_RIh45nOcF3"
      },
      "source": [
        "templates_one_table = []\n",
        "for template in templates:\n",
        "    sql_constraints = template['SQL constraints']\n",
        "    sql_pattern = template[\"SQL pattern\"]\n",
        "    questions = template[\"questions\"]\n",
        "    skip = False\n",
        "    for constraint in sql_constraints:\n",
        "        if \"id\" in constraint or \"T1\" in constraint:\n",
        "            skip = True\n",
        "    questions_after = []     \n",
        "    if not skip:\n",
        "        for q, qc in questions:\n",
        "            if \"TABLE1\" not in q:\n",
        "                questions_after.append((q, qc))\n",
        "        if len(questions_after) > 0:\n",
        "            template_one = {}\n",
        "            template_one['SQL constraints'] = sql_constraints\n",
        "            template_one['SQL pattern'] = sql_pattern\n",
        "            template_one[\"questions\"] = questions_after\n",
        "            templates_one_table.append(template_one)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olsyMQjcOcF3",
        "outputId": "62abd14a-2e9a-4588-af1e-73a5e90b4e29"
      },
      "source": [
        "all_constraints = []\n",
        "for tmp in templates_one_table:\n",
        "    all_constraints.extend(tmp['SQL constraints'])\n",
        "    for q in tmp['questions']:\n",
        "        all_constraints.extend(q[1])\n",
        "\n",
        "print(list(set(all_constraints)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['P0==']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_gjrpOxOcF3"
      },
      "source": [
        "# read SQL component file\n",
        "with open(sql_components_file) as json_file:\n",
        "    sql_components = json.load(json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suKkTXiMOcF4"
      },
      "source": [
        "# get labels for question sep tokens\n",
        "\n",
        "templates_all = []\n",
        "with open(nlsql_templates_iso_file) as fp:\n",
        "    lines = fp.readlines()\n",
        "    template_one = {}\n",
        "    for line in lines:\n",
        "        if \"\\n\" == line:\n",
        "            templates_all.append(template_one['SQL pattern']) \n",
        "        elif \"SQL Pattern:\" in line:\n",
        "            template_one = {}\n",
        "            sps = line.strip().replace(\"SQL Pattern: \", \"\").split(\"|||\")\n",
        "            template_one[\"questions\"] = []\n",
        "            if len(sps) == 1:\n",
        "                template_one[\"SQL pattern\"] = sps[0]\n",
        "                template_one[\"SQL constraints\"] = []\n",
        "            elif len(sps) == 2:\n",
        "                template_one[\"SQL pattern\"] = sps[0]\n",
        "                template_one[\"SQL constraints\"] = [x.strip() for x in sps[1].split(\"|\") if x != \" \"]\n",
        "            else:\n",
        "                print(\"\\n======Error warning!!!!\")\n",
        "        elif \"count: \" in line:\n",
        "            sql_count = int(line.strip().replace(\"count: \", \"\"))\n",
        "            template_one[\"count\"] = sql_count\n",
        "        elif \"question:  \" in line:\n",
        "            sps = line.strip().replace(\"question:  \", \"\").split(\"|||\")\n",
        "            question = sps[0]\n",
        "            if len(sps) == 2:\n",
        "                q_constraints = [x.strip() for x in sps[1].split(\"|\") if x != \" \"]\n",
        "            else:\n",
        "                q_constraints = []\n",
        "            template_one[\"questions\"].append((question, q_constraints))\n",
        "\n",
        "context_templates_file = \"data/context_templates.json\"\n",
        "with open(context_templates_file) as json_file:\n",
        "    context_templates = json.load(json_file)\n",
        "\n",
        "for ct in context_templates:\n",
        "    templates_all.insert(0, ct[\"label\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "850xbMKyOcF4"
      },
      "source": [
        "qsep_label_map = {}\n",
        "for i, ex in enumerate(templates_all):\n",
        "    qsep_label_map[ex] = i + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypL9KGQvOcF4"
      },
      "source": [
        "# qsep_label_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwyh3FOvOcF5"
      },
      "source": [
        "with open(\"data/qsep_label_map.json\", \"w\") as f:\n",
        "    json.dump(qsep_label_map, f, indent=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su9l7vk2OcF5"
      },
      "source": [
        "### Unify and combine tables as databases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDV-gQ1jOcF5"
      },
      "source": [
        "def create_dbs(tables):\n",
        "#     random.shuffle(tables)  \n",
        "    dbs = []\n",
        "    cur_cols = []\n",
        "    db_one = []\n",
        "    ahd_cols = []\n",
        "    for i, tab in enumerate(tables):\n",
        "        if i % 100000 == 0:\n",
        "            print(\"processed: \", i)\n",
        "        if len(db_one) <= random.choice([0, 1]) and len(ahd_cols) < MAX_COL_NUM:\n",
        "            db_one.append(tab)\n",
        "            cur_cols.extend([col+\".\"+tab[\"name\"] for col in tab[\"columns\"]])\n",
        "            if i+1 < len(tables):\n",
        "                ahd_cols = cur_cols + [col+\".\"+tables[i+1][\"name\"] for col in tables[i+1][\"columns\"]]\n",
        "            else:\n",
        "                 break\n",
        "        else:\n",
        "            if len(cur_cols) == len(list(set(cur_cols))):\n",
        "                if len(db_one) > 1:\n",
        "                    db_one_new = []\n",
        "                    for tab in db_one:\n",
        "                        if tab[\"columns\"][0] == \"id\":\n",
        "                            tab[\"columns\"] = tab[\"columns\"][1:]\n",
        "                            tab[\"column_types\"] = tab[\"column_types\"][1:]\n",
        "                            tab[\"columns_original\"] = tab[\"columns_original\"][1:]\n",
        "                            tab[\"values\"] = tab[\"values\"][1:]\n",
        "                            \n",
        "                        if random.random() < 0.7:\n",
        "                            index_col = \"id\"\n",
        "                            if random.random() < 0.3:\n",
        "                                index_col = \"name\"\n",
        "\n",
        "                            if index_col not in tab[\"columns\"]:\n",
        "                                tabn_str = \"_\".join(tab[\"name\"].split(\" \"))\n",
        "                                tab[\"columns\"] = [tab[\"columns\"][0]] + [tabn_str +\" \"+ index_col] + tab[\"columns\"][1:]\n",
        "                                val_add = 1\n",
        "                                if index_col == \"name\":\n",
        "                                    val_add = \"value\"\n",
        "                                tab[\"values\"] = [tab[\"values\"][0]] + [val_add] + tab[\"values\"][1:]\n",
        "                                tab[\"column_types\"] = [tab[\"column_types\"][0]] + [\"text\"] + tab[\"column_types\"][1:]\n",
        "                                tab[\"columns_original\"] = [tab[\"columns_original\"][0]] + [index_col] + tab[\"columns_original\"][1:]\n",
        "                        db_one_new.append(tab)\n",
        "                    dbs.append(db_one_new)\n",
        "                else:\n",
        "                    dbs.append(db_one)\n",
        "            db_one = []\n",
        "            cur_cols = []\n",
        "            ahd_cols = []\n",
        "            \n",
        "    return dbs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq2MBr8IOcF5",
        "outputId": "92d36b10-1b7e-4041-ed46-b074d9b0c8e0"
      },
      "source": [
        "webtable_dbs = create_dbs(web_tables)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processed:  0\n",
            "processed:  100000\n",
            "processed:  200000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCwYU8EYOcF6",
        "outputId": "16e58d0e-38f3-41f2-9ad2-a4be50346d79"
      },
      "source": [
        "len(webtable_dbs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "83973"
            ]
          },
          "execution_count": 762,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cXv_xXlOcF6",
        "outputId": "7e3bd74f-7e8b-4fac-f8cd-56611652cc79"
      },
      "source": [
        "webtable_dbs[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'columns': ['year_award year award *',\n",
              "   'year_award season',\n",
              "   'year_award player',\n",
              "   'year_award position',\n",
              "   'year_award nationality',\n",
              "   'year_award team',\n",
              "   'year_award draft pick #',\n",
              "   'year_award draft class',\n",
              "   'year_award college'],\n",
              "  'values': ['all',\n",
              "   '1111',\n",
              "   'steve ralston category : articles',\n",
              "   'midfielder',\n",
              "   'united states',\n",
              "   'tampa bay mutiny',\n",
              "   '11',\n",
              "   '1111 mls college draft',\n",
              "   'florida international'],\n",
              "  'columns_original': ['*',\n",
              "   'season',\n",
              "   'player',\n",
              "   'position',\n",
              "   'nationality',\n",
              "   'team',\n",
              "   'draft pick #',\n",
              "   'draft class',\n",
              "   'college'],\n",
              "  'column_types': ['text',\n",
              "   'real',\n",
              "   'text',\n",
              "   'text',\n",
              "   'text',\n",
              "   'text',\n",
              "   'real',\n",
              "   'text',\n",
              "   'text'],\n",
              "  'name': 'year award'},\n",
              " {'columns': ['directions directions *',\n",
              "   'directions name',\n",
              "   'directions name',\n",
              "   'directions direction',\n",
              "   'directions mantra',\n",
              "   'directions weapon',\n",
              "   'directions consort',\n",
              "   'directions graha ( planet )',\n",
              "   'directions guardian mātṛkā'],\n",
              "  'values': ['all',\n",
              "   'value',\n",
              "   'kubera',\n",
              "   'north',\n",
              "   'oṃ śaṃ kuberāya namaḥ',\n",
              "   'gadā ( mace )',\n",
              "   'kuberajāyā',\n",
              "   'budha ( mercury )',\n",
              "   'kumārī'],\n",
              "  'columns_original': ['*',\n",
              "   'name',\n",
              "   'name',\n",
              "   'direction',\n",
              "   'mantra',\n",
              "   'weapon',\n",
              "   'consort',\n",
              "   'graha ( planet )',\n",
              "   'guardian mātṛkā'],\n",
              "  'column_types': ['text',\n",
              "   'text',\n",
              "   'text',\n",
              "   'text',\n",
              "   'text',\n",
              "   'text',\n",
              "   'text',\n",
              "   'text',\n",
              "   'text'],\n",
              "  'name': 'directions'}]"
            ]
          },
          "execution_count": 763,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVGZtTo9OcF6"
      },
      "source": [
        "for db in webtable_dbs[:1000]:\n",
        "    tab_names = []\n",
        "    col_count = 0\n",
        "    for tab in db:\n",
        "        tab_names.append(tab[\"name\"])\n",
        "        col_count += len(tab[\"columns\"])\n",
        "    print(\"----------\")\n",
        "    print(\"table names: \", tab_names)\n",
        "    print(\"column num: \", col_count)\n",
        "    print(\"table num: \", len(tab_names))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIWcwsmBOcF7"
      },
      "source": [
        "### Start generate NL-SQL examples based on new databases and CFG grammars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCRcNUZsOcF7"
      },
      "source": [
        "##### detect question and SQL slots and process constraints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auaGEF_-OcF_"
      },
      "source": [
        "def get_sql_slots(sql_pattern):\n",
        "    sql_tokens = sql_pattern.split(\" \")\n",
        "    columns = {}\n",
        "    ops = {}\n",
        "    values = {}\n",
        "    aggs = {}\n",
        "    dasc = False\n",
        "    slots = []\n",
        "    val_pros = []\n",
        "    for i, tok in enumerate(sql_tokens):\n",
        "        if \"{\" in tok and \"}\" in tok and \"FROM\" not in tok:\n",
        "            if tok not in slots:\n",
        "                slots.append(tok)\n",
        "                \n",
        "        if \"AGG\" in tok:\n",
        "            if i + 2 < len(sql_tokens) and \"(\" == sql_tokens[i+1]:\n",
        "                if \"COLUMN\" in sql_tokens[i+2]:\n",
        "                    if sql_tokens[i+2] not in columns.keys():\n",
        "                        columns[sql_tokens[i+2]] = [\"number\"]\n",
        "                    else:\n",
        "                        columns[sql_tokens[i+2]].append(\"number\")\n",
        "                    aggs[tok] = sql_tokens[i+2]\n",
        "                else:\n",
        "                    print(\"\\nTemplate Error: AGG format is wrong!!!\")\n",
        "                    print(sql_pattern)\n",
        "        elif \"COLUMN\" in tok:\n",
        "            if tok not in columns.keys():\n",
        "                columns[tok] = []\n",
        "        elif \"OP\" in tok:\n",
        "            if i - 1 >= 0 and \"COLUMN\" in sql_tokens[i-1]:\n",
        "                ops[tok] = [sql_tokens[i-1]]\n",
        "                if i + 1 < len(sql_tokens) and \"VALUE\" in sql_tokens[i+1]:\n",
        "                    ops[tok].append(sql_tokens[i+1])\n",
        "                    val_pros.append(sql_tokens[i+1])\n",
        "            elif i - 2 >= 0 and \")\" == sql_tokens[i-1] and (\"COLUMN\" in sql_tokens[i-2] or \"*\" == sql_tokens[i-2]):\n",
        "                ops[tok] = [sql_tokens[i-2]]\n",
        "                if i + 1 < len(sql_tokens) and \"VALUE\" in sql_tokens[i+1]:\n",
        "                    ops[tok].append(sql_tokens[i+1])\n",
        "                    val_pros.append(sql_tokens[i+1])\n",
        "            else:\n",
        "                print(\"\\nTemplate Error: OP format is wrong!!!\")\n",
        "                print(sql_pattern)\n",
        "        elif \"VALUE\" in tok and tok not in val_pros:\n",
        "            \"\"\"\n",
        "            OP} {VALUE0}\n",
        "            LIMIT {VALUE0}\n",
        "            {COLUMN1} BETWEEN {VALUE0} AND {VALUE1}\n",
        "            HAVING COUNT ( * ) {OP1} {VALUE1}\n",
        "            = {VALUE1}\n",
        "            \"\"\"\n",
        "            if i - 2 >= 0 and (\"BETWEEN\" == sql_tokens[i-1] or \"AND\" == sql_tokens[i-1]):\n",
        "                values[tok] = \"number\"\n",
        "                if \"BETWEEN\" == sql_tokens[i-1]:\n",
        "                    columns[sql_tokens[i-2]].append(\"number\")\n",
        "            elif i - 1 >= 0 and \"LIMIT\" == sql_tokens[i-1]:\n",
        "                values[tok] = \"integer\"\n",
        "            elif i - 1 >= 0 and \"=\" == sql_tokens[i-1]:\n",
        "                assert \"COLUMN\" in sql_tokens[i-2]\n",
        "                columns[sql_tokens[i-2]].append(tok)\n",
        "            else:\n",
        "                print(\"\\nTemplate Error: VALUE format is wrong!!!\")\n",
        "                print(sql_pattern)\n",
        "        elif \"DASC\" in tok:\n",
        "            dasc = True\n",
        "    \n",
        "    return (list(set(slots)), columns, ops, values, aggs, dasc)\n",
        "\n",
        "\n",
        "def get_q_slots(question):\n",
        "    q_toks = [x.replace(\"?\", \"\").replace(\"!\", \"\").replace(\".\", \"\") for x in question.strip().split(\" \")]\n",
        "    q_slots = list(set([tok for tok in q_toks if \"TABLE\" in tok or \"SC\" in tok or (\"{\" in tok and \"}\" in tok)]))\n",
        "    \n",
        "    return q_slots\n",
        "    \n",
        "\n",
        "def process_constraints(constraints, columns, slots):\n",
        "    slot_values = {}\n",
        "    skip_db_with_one_table = False\n",
        "    for constraint in constraints:\n",
        "        if \"P0==\" == constraint:\n",
        "            assert \"{OP0}\" in slots\n",
        "            slot_values[\"{OP0}\"] = \"=\"\n",
        "        elif \"P1==\" == constraint:\n",
        "            assert \"{OP1}\" in slots\n",
        "            slot_values[\"{OP1}\"] = \"=\"\n",
        "        elif \"P0=P1==\" == constraint:\n",
        "            assert \"{OP0}\" in slots and \"{OP1}\" in slots\n",
        "            slot_values[\"{OP0}\"] = \"=\"\n",
        "            slot_values[\"{OP1}\"] = \"=\"\n",
        "        elif \"P0=P1=P2==\" == constraint:\n",
        "            assert \"{OP0}\" in slots and \"{OP1}\" in slots and \"{OP2}\" in slots\n",
        "            slot_values[\"{OP0}\"] = \"=\"\n",
        "            slot_values[\"{OP1}\"] = \"=\"\n",
        "            slot_values[\"{OP2}\"] = \"=\"\n",
        "        elif \"P0=>\" == constraint:\n",
        "            assert \"{OP0}\" in slots\n",
        "            slot_values[\"{OP0}\"] = \">\"\n",
        "        elif \"P0=<\" == constraint:\n",
        "            assert \"{OP0}\" in slots\n",
        "            slot_values[\"{OP0}\"] = \"<\"\n",
        "        elif \"{AGG0}=MIN\" == constraint:\n",
        "            assert \"{AGG0}\" in slots\n",
        "            slot_values[\"{AGG0}\"] = \"MIN\"\n",
        "        elif \"{AGG0}=MAX\" == constraint:\n",
        "            assert \"{AGG0}\" in slots\n",
        "            slot_values[\"{AGG0}\"] = \"MAX\"\n",
        "        elif \"C0-id\" == constraint:\n",
        "            skip_db_with_one_table = True\n",
        "            assert \"{COLUMN0}\" in slots and \"{COLUMN0}\" in columns.keys()\n",
        "            columns[\"{COLUMN0}\"].append(\"id\")\n",
        "        elif \"C1-id\" == constraint:\n",
        "            skip_db_with_one_table = True\n",
        "            assert \"{COLUMN1}\" in slots and \"{COLUMN1}\" in columns.keys()\n",
        "            columns[\"{COLUMN1}\"].append(\"id\")\n",
        "        elif \"C2-id\" == constraint:\n",
        "            skip_db_with_one_table = True\n",
        "            assert \"{COLUMN2}\" in slots and \"{COLUMN2}\" in columns.keys()\n",
        "            columns[\"{COLUMN2}\"].append(\"id\")\n",
        "        elif \"C3-T1\" == constraint:\n",
        "            skip_db_with_one_table = True\n",
        "            assert \"{COLUMN3}\" in slots and \"{COLUMN3}\" in columns.keys()\n",
        "            columns[\"{COLUMN3}\"].append(\"T1\")\n",
        "        elif \"T0-T1-JOIN\" == constraint or 'T0-T1-NO-JOIN' == constraint:\n",
        "            skip_db_with_one_table = True\n",
        "            columns[\"{COLUMN0}\"].append(\"T0\")\n",
        "            if \"{COLUMN1}\" in columns.keys():\n",
        "                columns[\"{COLUMN1}\"].append(\"T1\")\n",
        "    \n",
        "    return (slot_values, columns, skip_db_with_one_table)\n",
        "\n",
        "\n",
        "# helper function\n",
        "def gen_col_info(col_str, columns, columns_inf):\n",
        "    col_conds = columns[col_str]\n",
        "    value_slot = [cc for cc in col_conds if \"VALUE\" in cc]\n",
        "    col = \"\"\n",
        "    value_val = None\n",
        "    if \"id\" in col_conds:\n",
        "        has_id = False\n",
        "        for c, t, v in columns_inf:\n",
        "            if \"id\" in col or \"name\" in col:\n",
        "                has_id = True\n",
        "                col, ctype, values = c, t, v\n",
        "                break\n",
        "        if not has_id:\n",
        "            col, ctype, value = columns_inf[0]\n",
        "    elif \"number\" in col_conds:\n",
        "        for colinfo in columns_inf[1:]:\n",
        "            if colinfo[1] == \"real\":\n",
        "                col, ctype, value = colinfo\n",
        "    if col == \"\":\n",
        "        col, ctype, value = random.choice(columns_inf[1:])\n",
        "\n",
        "    if len(value_slot) > 0:\n",
        "        assert len(value_slot) < 3\n",
        "        if len(value_slot) == 1:\n",
        "            value_val = [(value_slot[0], value)]\n",
        "        else:\n",
        "            value_val = [(value_slot[0], value), (value_slot[1], value)]\n",
        "    \n",
        "    return (col, value_val)\n",
        "\n",
        "\n",
        "def replace_dict(inp, dicts):\n",
        "    for rep_in, rep_out in dicts.items():\n",
        "        inp = inp.replace(rep_in, str(rep_out))\n",
        "    \n",
        "    return inp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaiBfvAKOcF_"
      },
      "source": [
        "##### Get classification label for each column based on SQL templates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIRC5a9mOcF_"
      },
      "source": [
        "STRUCT_KEYWORDS = [\"WHERE\", \"GROUP_BY\", \"HAVING\", \"ORDER_BY\", \"SELECT\"]\n",
        "EXTRA_OPS = [\"NOT_IN\", \"IN\", \"BETWEEN\", \"=\"]\n",
        "COUNT = \"COUNT\"\n",
        "OTHER_KEYWORDS = [\"LIMIT\"] #AGG, OP, DASC, OR, =\n",
        "NEST_KEYWORDS = [\"EXCEPT\", \"UNION\", \"INTERSECT\"]\n",
        "\n",
        "def get_labels(sql_pattern):\n",
        "    sql_tokens = sql_pattern.replace(\"GROUP BY\", \"GROUP_BY\").replace(\"ORDER BY\", \"ORDER_BY\").replace(\"NOT IN\", \"NOT_IN\").split(\" \")\n",
        "    columns = {}\n",
        "    cur_nest = \"\"\n",
        "    cur_struct = \"\"\n",
        "    cur_len = len(sql_tokens)\n",
        "    select_count = 0\n",
        "    skip = False\n",
        "    for i, tok in enumerate(sql_tokens):\n",
        "        if tok in NEST_KEYWORDS:\n",
        "            if cur_nest == \"\" or cur_nest == \"OP_SEL\":\n",
        "                cur_nest = tok\n",
        "            else:\n",
        "                cur_nest = cur_nest + \" \" + tok\n",
        "        elif tok in STRUCT_KEYWORDS:\n",
        "            cur_struct = tok\n",
        "            if tok == \"SELECT\":\n",
        "                select_count += 1\n",
        "                if select_count > 1 and cur_nest == \"\":\n",
        "                    cur_nest = \"OP_SEL\"\n",
        "        elif \"COLUMN\" in tok or \"*\" == tok:\n",
        "            if tok not in columns.keys():\n",
        "                columns[tok] = []\n",
        "            # SELECT {COLUMN0}\n",
        "            # SELECT {COLUMN0} , {COLUMN1}\n",
        "            # SELECT {AGG0} ( {COLUMN0} )\n",
        "            # SELECT {COLUMN0} {FROM} WHERE {COLUMN1} {OP} ( SELECT {AGG0} ( {COLUMN1} ) {FROM} ) AND {COLUMN2} {OP0} {VALUE0}\n",
        "            if cur_struct == \"SELECT\":\n",
        "                if \",\" == sql_tokens[i-1] or \"SELECT\" == sql_tokens[i-1]:\n",
        "                    columns[tok].append(cur_nest + \" \" + cur_struct)\n",
        "                elif \"(\" == sql_tokens[i-1]:\n",
        "                    columns[tok].append(cur_nest + \" \" + cur_struct + \" \" + sql_tokens[i-2])\n",
        "                else:\n",
        "                    print(\"\\nWarning: unexcepted SELECT format\")\n",
        "                    skip = True\n",
        "                    print(sql_pattern)\n",
        "            # WHERE {COLUMN} {OP}\n",
        "            # WHERE {COLUMN2} {OP0}\n",
        "            # WHERE OR {COLUMN2} {OP0}\n",
        "            # WHERE {COLUMN2} BETWEEN\n",
        "            elif cur_struct == \"WHERE\":\n",
        "                assert \"OP\" in sql_tokens[i+1] or sql_tokens[i+1] in EXTRA_OPS\n",
        "                last_tok = sql_tokens[i-1]\n",
        "                if \"OR\" == last_tok or (i+3 < cur_len and \"OR\" == sql_tokens[i+3]):\n",
        "                    columns[tok].append(cur_nest + \" \" + cur_struct + \" OR \" + sql_tokens[i+1])\n",
        "                elif \"WHERE\" == last_tok or \"AND\" == last_tok:\n",
        "                    columns[tok].append(cur_nest + \" \" + cur_struct + \" \" + sql_tokens[i+1])\n",
        "                else:\n",
        "                    print(\"\\nWarning: unexcepted WHERE format\")\n",
        "                    skip = True\n",
        "            # GROUP BY {COLUMN0} , {COLUMN0}\n",
        "            elif cur_struct == \"GROUP_BY\":\n",
        "                columns[tok].append(cur_nest + \" \" + cur_struct)\n",
        "            # HAVING COUNT ( * ) {OP0}\n",
        "            # HAVING {AGG0} ( {COLUMN2} ) {OP0}\n",
        "            elif cur_struct == \"HAVING\":\n",
        "                last_tok = sql_tokens[i-1]\n",
        "                if last_tok != \"(\" and not (\"AGG\" in sql_tokens[i-2] or COUNT == sql_tokens[i-2]):\n",
        "                    print(\"\\nWarning: unexcepted HAVING format\")\n",
        "                    skip = True\n",
        "                columns[tok].append(cur_nest + \" \" + cur_struct + \" \" + sql_tokens[i-2] + \" \" + sql_tokens[i+2])\n",
        "            # ORDER BY COUNT ( * ) {DASC} LIMIT\n",
        "            # ORDER BY COUNT ( * ) {DASC}\n",
        "            # ORDER BY {COLUMN1} {DASC} LIMIT\n",
        "            # ORDER BY {COLUMN1} LIMIT\n",
        "            # ORDER BY {COLUMN1} , {COLUMN1} {DASC} LIMIT\n",
        "            # ORDER BY {COLUMN1} {DASC} if no DASC then is ASC\n",
        "            elif cur_struct == \"ORDER_BY\":\n",
        "                last_tok = sql_tokens[i-1]\n",
        "                if last_tok == \"(\":\n",
        "                    dasc_tok = \"{DASC}\"\n",
        "                    limit_tok = \"\"\n",
        "                    if sql_tokens[i+2] != \"{DASC}\":\n",
        "                        dasc_tok = \"ASC\"\n",
        "                        if sql_tokens[i+2] == \"LIMIT\":\n",
        "                            limit_tok = \"LIMIT\"\n",
        "                    elif i+3 < cur_len and sql_tokens[i+3] == \"LIMIT\":\n",
        "                        limit_tok = \"LIMIT\"\n",
        "                        \n",
        "                    columns[tok].append(cur_nest + \" \" + cur_struct + \" \" + sql_tokens[i-2] + \" \" + dasc_tok + \" \" + limit_tok)\n",
        "                elif last_tok == \"ORDER_BY\" or last_tok == \",\":\n",
        "                    dasc_tok = \"ASC\"\n",
        "                    limit_tok = \"\"\n",
        "                    # small dirty pass\n",
        "                    if i+1 < cur_len and sql_tokens[i+1] == \"{DASC}\":\n",
        "                        dasc_tok = \"{DASC}\"\n",
        "                        if i+2 < cur_len and sql_tokens[i+2] == \"LIMIT\":\n",
        "                            limit_tok = \"LIMIT\"\n",
        "                    elif i+1 < cur_len and sql_tokens[i+1] == \"LIMIT\":\n",
        "                        limit_tok = \"LIMIT\"\n",
        "                    \n",
        "                    columns[tok].append(cur_nest + \" \" + cur_struct + \" \" + dasc_tok + \" \" + limit_tok)\n",
        "        \n",
        "            else:\n",
        "                print(\"\\n------------Warning: unexcepted COLUMN label format\")\n",
        "                skip = True\n",
        "    \n",
        "    column_labels = {}\n",
        "    for col, labels in columns.items():\n",
        "        label_str = \" \".join([l.strip() for l in labels])\n",
        "        column_labels[col] = label_str\n",
        "        \n",
        "    return column_labels, skip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYIBWLs4OcGA"
      },
      "source": [
        "##### Populate one example for a given database based on a given nl-SQL template and sql component mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP5kPQyEOcGA"
      },
      "source": [
        "def populate_one(db, templates, templates_one, sql_components):\n",
        "    \"\"\"\n",
        "    'P0=P1==', 'P0=P1=P2==', 'P0==', 'P1==', 'P0=>', 'P0=<', '{AGG0}=MAX', '{AGG0}=MIN'\n",
        "    'T0-T1-JOIN', 'T0-T1-NO-JOIN', \n",
        "    'C0-id',, 'C2-id', , 'C1-id',  'C3-T1'\n",
        "    \"\"\"\n",
        "    if len(db) > 1:\n",
        "        template = random.choice(templates)\n",
        "    else:\n",
        "        template = random.choice(templates_one)\n",
        "        \n",
        "    sql_constraints = template['SQL constraints']\n",
        "    sql_pattern = template[\"SQL pattern\"]\n",
        "    question, q_constraints = random.choice(template[\"questions\"])\n",
        "    constraints = list(set(sql_constraints + q_constraints))\n",
        "\n",
        "    slots, columns, ops, vals, aggs, dasc = get_sql_slots(sql_pattern)\n",
        "    slot_values, columns, skip_db_with_one_table = process_constraints(constraints, columns, slots)\n",
        "\n",
        "    q_slots = get_q_slots(question)\n",
        "    q_slot_values = {}\n",
        "\n",
        "    # 1 process ops - update columns and values constraints\n",
        "    for op, colv in ops.items():\n",
        "        if colv[0] == \"*\":\n",
        "            if op not in slot_values.keys():\n",
        "                op_val = random.choice([\">\", \"<\", \">=\", \"<=\", \"=\"])\n",
        "                slot_values[op] = op_val\n",
        "                if len(colv) == 2:\n",
        "                    slot_values[colv[1]] = random.randint(1, 10)\n",
        "        else:\n",
        "            if colv[0] not in columns.keys():\n",
        "                print(\"\\n-----colv[0] not in columns.keys(): \")\n",
        "                print(columns.keys())\n",
        "                print(ops)\n",
        "            assert colv[0] in columns.keys()\n",
        "            if op not in slot_values.keys():\n",
        "                if random.random() < 0.4:\n",
        "                    op_val = \"=\"\n",
        "                else:\n",
        "                    op_val = random.choice(OPS)\n",
        "                slot_values[op] = op_val\n",
        "                if op_val in [\">\", \"<\", \">=\", \"<=\"]:\n",
        "                    columns[colv[0]].append(\"number\")\n",
        "            if len(colv) == 2:\n",
        "                columns[colv[0]].append(colv[1])\n",
        "    \n",
        "    # 2 process columns\n",
        "    random.shuffle(db)\n",
        "    table_0, table_1 = None, None\n",
        "    table_label_0 = \"\"\n",
        "    table_label_1 = \"\"\n",
        "    use_table_1 = False\n",
        "    \n",
        "    if \"{COLUMN0}\" in columns.keys() or \"{TABLE0}\" in q_slots:\n",
        "        table_label_0 = \"SELECT\"\n",
        "        \n",
        "    if len(db) >= 2:\n",
        "        table_0, table_1 = db[:2]\n",
        "        if \"{TABLE1}\" in q_slots:\n",
        "            table_label_1 = \"SELECT\"\n",
        "            if \"{TABLE0}\" in q_slots:\n",
        "                # p<0.5 from T0, T1 AND to SELECT T1 *\n",
        "                # otherwise all from T0 AND to SELECT T1 *\n",
        "                if random.random() < 0.5:\n",
        "                    use_table_1 = True                 \n",
        "            else:\n",
        "                # p<0.4 all from T0 \n",
        "                # AND to SELECT T1 *\n",
        "                if random.random() < 0.6:\n",
        "                    use_table_1 = True\n",
        "                    if \"{COLUMN1}\" in columns.keys():\n",
        "                        table_label_1 = \"SELECT\"\n",
        "        else:\n",
        "            # p<0.5 from T0, T1 AND to SELECT T1 *\n",
        "            # otherwise all from T0, NOT to SELECT T1 *\n",
        "            if random.random() < 0.5:\n",
        "                use_table_1 = True\n",
        "                if \"{COLUMN1}\" in columns.keys():\n",
        "                    table_label_1 = \"SELECT\"\n",
        "    else:\n",
        "        table_0, table_1 = db[0], db[0]\n",
        "    \n",
        "    T0 = table_0[\"name\"]\n",
        "    T1 = table_1[\"name\"]\n",
        "    columns_inf_0 = list(zip(table_0[\"columns\"], table_0[\"column_types\"], table_0[\"values\"]))[1:]\n",
        "    if use_table_1:\n",
        "        columns_inf_1 = list(zip(table_1[\"columns\"], table_1[\"column_types\"], table_1[\"values\"]))[1:]\n",
        "    \n",
        "    if \"{COLUMN0}\" in columns.keys():\n",
        "        col_0, value_0 = gen_col_info(\"{COLUMN0}\", columns, columns_inf_0)\n",
        "        slot_values[\"{COLUMN0}\"] = col_0\n",
        "        if value_0 is not None:\n",
        "            for k, v in value_0:\n",
        "                slot_values[k] = v\n",
        "        if len(columns_inf_0) > 2:\n",
        "            columns_inf_0 = [(col, ctype, val) for col, ctype, val in columns_inf_0 if col != col_0]\n",
        "    \n",
        "    if use_table_1:\n",
        "        columns_input = columns_inf_1\n",
        "        columns_all = columns_inf_0 + columns_inf_1\n",
        "    else:\n",
        "        columns_input = columns_inf_0\n",
        "        columns_all = columns_inf_0\n",
        "                \n",
        "    if \"{COLUMN1}\" in columns.keys():\n",
        "        col_1, value_1 = gen_col_info(\"{COLUMN1}\", columns, columns_input)\n",
        "        slot_values[\"{COLUMN1}\"] = col_1\n",
        "        if value_1 is not None:\n",
        "            for k, v in value_1:\n",
        "                slot_values[k] = v\n",
        "        columns_input_org = columns_input\n",
        "        if len(columns_input) > 3:\n",
        "            columns_input = [(col, ctype, val) for col, ctype, val in columns_input if col != col_1]\n",
        "        if len(columns_input) < 2:\n",
        "            columns_input = columns_input_org\n",
        "        columns_all = [(col, ctype, val) for col, ctype, val in columns_all if col != col_1]\n",
        "        \n",
        "    if \"{COLUMN2}\" in columns.keys():\n",
        "        col_2, value_2 = gen_col_info(\"{COLUMN2}\", columns, columns_input)\n",
        "        slot_values[\"{COLUMN2}\"] = col_2\n",
        "        if value_2 is not None:\n",
        "            for k, v in value_2:\n",
        "                slot_values[k] = v\n",
        "        columns_input_org = columns_input\n",
        "        if len(columns_input) > 2:\n",
        "            columns_input = [(col, ctype, val) for col, ctype, val in columns_input if col != col_2]\n",
        "        if len(columns_input) < 2:\n",
        "            columns_input = columns_input_org\n",
        "        columns_all = [(col, ctype, val) for col, ctype, val in columns_all if col != col_2]\n",
        "                \n",
        "    if \"{COLUMN3}\" in columns.keys():\n",
        "        col_3, value_3 = gen_col_info(\"{COLUMN3}\", columns, columns_input)\n",
        "        slot_values[\"{COLUMN3}\"] = col_3\n",
        "        if value_3 is not None:\n",
        "            for k, v in value_3:\n",
        "                slot_values[k] = v\n",
        "        columns_all = [(col, ctype, val) for col, ctype, val in columns_all if col != col_3]\n",
        "                \n",
        "        \n",
        "    # 3 aggs\n",
        "    for agg in aggs.keys():\n",
        "        if agg not in slot_values.keys():\n",
        "            slot_values[agg] = random.choice([\"MAX\", \"MIN\", \"SUM\", \"AVG\"])\n",
        "    # 4 values\n",
        "    NUM = 1\n",
        "    for val, cond in vals.items():\n",
        "        assert val not in slot_values.keys()\n",
        "        if cond == \"integer\":\n",
        "            if random.random() < 0.5:\n",
        "                slot_values[val] = 1\n",
        "            else:\n",
        "                NUM = random.randint(2, 10)\n",
        "                slot_values[val] = NUM\n",
        "        else:\n",
        "            slot_values[val] = random.randint(0, 100)\n",
        "                    \n",
        "    # 5 dasc - true\n",
        "    if dasc == True:\n",
        "        slot_values[\"{DASC}\"] = random.choice([\"ASC\", \"DESC\"])\n",
        "    \n",
        "    # 6 check if all sql slot values are done\n",
        "    if len(slots) != len(slot_values):\n",
        "        print(\"\\nlen(slots) != len(slot_values)\")\n",
        "        print(\"sql_pattern: \", sql_pattern)\n",
        "        print(\"slots: \", slots)\n",
        "        print(\"slot_values: \", slot_values.keys())\n",
        "    assert len(slots) == len(slot_values)\n",
        "    \n",
        "    # 7 for the questions slots:\n",
        "    for qs in q_slots:\n",
        "        if qs == \"{TABLE0}\":\n",
        "            q_slot_values[\"{TABLE0}\"] = T0\n",
        "        elif qs == \"{TABLE1}\":\n",
        "            q_slot_values[\"{TABLE1}\"] = T1\n",
        "        elif \"SC\" in qs:\n",
        "            sc = slot_values[\"{DASC}\"]\n",
        "            if \"SC\" == qs:\n",
        "                q_slot_values[qs] = random.choice(sql_components[\"SC\"][sc])\n",
        "            elif \"SC_COL_LIMIT\" == qs:\n",
        "                if NUM > 1:\n",
        "                    sc =  sc + \"_NUM\"\n",
        "                    q_slot_values[qs] = random.choice(sql_components[\"SC_COL_LIMIT\"][sc]).replace(\"[NUM]\", str(NUM))\n",
        "                else:\n",
        "                    q_slot_values[qs] = random.choice(sql_components[\"SC_COL_LIMIT\"][sc])\n",
        "            elif \"SC_COL_COUNT_LIMIT\" in qs:\n",
        "                sc_type = qs.replace(\"SC_COL_COUNT_LIMIT\", \"\")\n",
        "                if NUM > 1:\n",
        "                    sc =  sc + \"_NUM\" + sc_type\n",
        "                    q_slot_values[qs] = random.choice(sql_components[\"SC_COL_COUNT_LIMIT\"][sc]).replace(\"[NUM]\", str(NUM))\n",
        "                else:\n",
        "                    sc =  sc + sc_type\n",
        "                    q_slot_values[qs] = random.choice(sql_components[\"SC_COL_COUNT_LIMIT\"][sc])\n",
        "            else:\n",
        "                if \"-\" not in qs:\n",
        "                    print(\"qs wrong\", qs)\n",
        "                assert \"-\" in qs\n",
        "                if \"C1\" in qs:\n",
        "                    sc_col = slot_values[\"{COLUMN1}\"]\n",
        "                elif \"C2\" in qs:\n",
        "                    sc_col = slot_values[\"{COLUMN2}\"]\n",
        "                q_slot_values[qs] = random.choice(sql_components[\"SC_COL\"][sc]).replace(\"[COL]\", sc_col)\n",
        "        else:\n",
        "            if qs not in slot_values.keys():\n",
        "                print(\"qs not in sv: \", qs)\n",
        "                print(\"sql_pattern: \", sql_pattern)\n",
        "                print(\"slot_values: \", slot_values)\n",
        "            assert qs in slot_values.keys()\n",
        "            if \"OP\" in qs:\n",
        "                q_slot_values[qs] = random.choice(sql_components[\"OP\"][slot_values[qs]])\n",
        "            elif \"AGG\" in qs:\n",
        "                q_slot_values[qs] = random.choice(sql_components[\"AGG\"][slot_values[qs]])\n",
        "            elif \"COLUMN\" in qs:\n",
        "                q_slot_values[qs] = \" \".join(slot_values[qs].split(\" \")[:6])\n",
        "            elif \"VALUE\" in qs:\n",
        "                q_slot_values[qs] = \" \".join(str(slot_values[qs]).split(\" \")[:5])\n",
        "            else:\n",
        "                print(\"\\nWarning: some q slot type not considered!\")\n",
        "                print(qs)\n",
        "    \n",
        "    # 8 check if all question slots are processed\n",
        "    assert len(q_slots) == len(q_slot_values)\n",
        "    \n",
        "    # 9 generate final SQL-question pair\n",
        "    question_gen = replace_dict(question, q_slot_values)\n",
        "    \n",
        "    \n",
        "    # 10 generate column labels\n",
        "    slot_values_new = {}\n",
        "    for sl, vl in slot_values.items():\n",
        "        if \"COLUMN\" in sl:\n",
        "            slot_values_new[sl] = \"_=_\".join(vl.split(\" \"))\n",
        "        else:\n",
        "            slot_values_new[sl] = vl\n",
        "            \n",
        "    column_labels, skip = get_labels(sql_pattern)\n",
        "    column_lables_real = {}\n",
        "    for col, label in column_labels.items():\n",
        "        if col != \"*\":\n",
        "            col = slot_values[col]\n",
        "        for slot, value in slot_values.items():\n",
        "            label = label.replace(slot, str(value))\n",
        "        column_lables_real[col] = label\n",
        "    \n",
        "    # also add labels for table column * \n",
        "    if table_label_0 != \"\":\n",
        "        column_lables_real[table_0[\"columns\"][0]] = table_label_0\n",
        "    if table_label_1 != \"\":\n",
        "        column_lables_real[table_1[\"columns\"][0]] = table_label_1\n",
        "    \n",
        "    sql_gen = replace_dict(sql_pattern.replace(\" {FROM}\", \"\"), slot_values_new)\n",
        "    \n",
        "    return (sql_gen, question_gen, column_lables_real, q_slot_values, slot_values, template[\"SQL pattern\"], columns_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM2oY4I-OcGA"
      },
      "source": [
        "##### generatee examples for all databases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ts8yzDjOcGA"
      },
      "source": [
        "# let's start data augmentation!\n",
        "def augment_db(db, templates, templates_one_table, sql_components, aug_limit):\n",
        "    count = 0\n",
        "    augment_pairs = []\n",
        "    while count < aug_limit:\n",
        "        sql_gen, question_gen, column_lables, q_slot_values, slot_values, template, columns_all = populate_one(db, templates, templates_one_table, sql_components)\n",
        "        qsep_label = qsep_label_map[template]\n",
        "        augment_pairs.append((question_gen, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all, [qsep_label]))\n",
        "        count += 1\n",
        "    \n",
        "    return augment_pairs\n",
        "    \n",
        "\n",
        "def augment_all_dbs(dbs, templates, templates_one_table, sql_components, aug_limit):\n",
        "    augment_data = {}\n",
        "    schema_dbs = {}\n",
        "    for idx, db in enumerate(dbs):\n",
        "        if idx % 10000 == 0:\n",
        "            print(\"processed: \", idx)\n",
        "        db_cols = [\"*\"]\n",
        "        db_values = [\"\"]\n",
        "        for tab in db:\n",
        "            db_cols.extend(tab[\"columns\"])\n",
        "            db_values.extend(tab[\"values\"])\n",
        "        schema_str = \" </s> \".join(db_cols)\n",
        "        values_str = \" </s> \".join([str(k) for k in db_values])\n",
        "        schema_str = schema_str + \" |-| \" + values_str\n",
        "        augment_pairs = augment_db(db, templates, templates_one_table, sql_components, aug_limit)\n",
        "        augment_data[schema_str] = augment_pairs\n",
        "        schema_dbs[schema_str] = db\n",
        "    \n",
        "    return augment_data, schema_dbs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ibDgfV85OcGB",
        "outputId": "2abf8db0-0b53-4251-8e7d-5076caeab973"
      },
      "source": [
        "augment_first_webtable, schema_dbs_webtable = augment_all_dbs(webtable_dbs, templates, templates_one_table, sql_components, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processed:  0\n",
            "processed:  10000\n",
            "processed:  20000\n",
            "processed:  30000\n",
            "processed:  40000\n",
            "processed:  50000\n",
            "processed:  60000\n",
            "processed:  70000\n",
            "processed:  80000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APs5qwBOOcGB"
      },
      "source": [
        "# read context template file\n",
        "context_templates_file = \"data/context_templates.json\"\n",
        "with open(context_templates_file) as json_file:\n",
        "    context_templates = json.load(json_file)\n",
        "\n",
        "\n",
        "# context_label_maps = {}\n",
        "# for i, ct in enumerate(context_templates):\n",
        "#     context_label_maps[ct[\"label\"]] = i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUH3luaJOcGB"
      },
      "source": [
        "SQL_OPS = ('INTERSECT', 'UNION', 'EXCEPT')\n",
        "AGG_OPS = [\"MAX\", \"MIN\", \"SUM\", \"AVG\"]\n",
        "OPS = [\">\", \"<\", \">=\", \"<=\", \"=\", \"!=\"]\n",
        "SQLPARSE_MAP = {\"\\n      \": \" \", \"\\n     \": \" \", \"\\n    \": \" \", \"\\n   \": \" \", \"\\n  \": \" \", \"\\n \": \" \", \"\\nhaving\": \" having\", \"\\nlimit\": \" limit\"}\n",
        "import sqlparse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HfNX9ikOcGB"
      },
      "source": [
        "prev_token = \" <unk> \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y72B-7adOcGB"
      },
      "source": [
        "def col_select(col_conds, columns_inf):\n",
        "    value_slot = [cc for cc in col_conds if \"VALUE\" in cc]\n",
        "    col = \"\"\n",
        "    value_val = None\n",
        "    if \"id\" in col_conds:\n",
        "        has_id = False\n",
        "        for c, t, v in columns_inf:\n",
        "            if \"id\" in col or \"name\" in col:\n",
        "                has_id = True\n",
        "                col, ctype, values = c, t, v\n",
        "                break\n",
        "        if not has_id:\n",
        "            col, ctype, value = columns_inf[0]\n",
        "    elif \"number\" in col_conds:\n",
        "        for colinfo in columns_inf:\n",
        "            if colinfo[1] == \"real\":\n",
        "                col, ctype, value = colinfo\n",
        "    if len(columns_inf) == 0:\n",
        "        print(\"\\n---------------------------------------- columns_inf: \", columns_inf)\n",
        "    if col == \"\":\n",
        "        col, ctype, value = random.choice(columns_inf)\n",
        "\n",
        "    if len(value_slot) > 0:\n",
        "        assert len(value_slot) < 3\n",
        "        if len(value_slot) == 1:\n",
        "            value_val = [(value_slot[0], value)]\n",
        "        else:\n",
        "            value_val = [(value_slot[0], value), (value_slot[1], value)]\n",
        "    \n",
        "    return (col, value_val)\n",
        "\n",
        "\n",
        "def replace_words(s, words):\n",
        "    for k, v in words.items():\n",
        "        s = s.replace(k, v)\n",
        "    return s\n",
        "\n",
        "\n",
        "def edit_sql(sql_pattern, context_label, slot_values_prev, columns_all_prev, context_template):\n",
        "    sql = sql_pattern.lower().replace(\"{from}\", \"\", 1).strip()\n",
        "    sql_clauses = {\"select\": \"\", \"where\": \"\", \"group_by\": \"\", \"order_by\": \"\"}\n",
        "    sql = sqlparse.format(sql, reindent=True)\n",
        "    parsed = [x for x in replace_words(sql, SQLPARSE_MAP).split(\"\\n\")]\n",
        "    slot_values = slot_values_prev.copy()\n",
        "    for p in parsed:\n",
        "        p_toks = p.split(\" \")\n",
        "        if p_toks[0] == \"select\":\n",
        "            sql_clauses[\"select\"] = p\n",
        "        elif p_toks[0] == \"where\":\n",
        "            sql_clauses[\"where\"] = p\n",
        "        elif p_toks[0] == \"group\":\n",
        "            sql_clauses[\"group_by\"] = p\n",
        "        elif p_toks[0] == \"order\":\n",
        "            sql_clauses[\"order_by\"] = p\n",
        "        else:\n",
        "            raise Exception(\"unexcepted sql clause: \", p)\n",
        "            \n",
        "    context_question, context_constraints = random.choice(context_template[\"questions\"])\n",
        "    context_q_slots = get_q_slots(context_question)\n",
        "    context_q_slots = [x.replace(\"1\", \"10\").replace(\"2\", \"20\").replace(\"3\", \"30\") for x in context_q_slots]\n",
        "            \n",
        "    q_slot_values = {}\n",
        "    sql_pattern_new = \"\"\n",
        "    context_q = \"\"\n",
        "    satisfy = True\n",
        "    \n",
        "    if context_label == \"select replace column\":\n",
        "        if sql_clauses[\"group_by\"] != \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            sql_clauses[\"select\"] = \"select \" + \" , \".join(context_q_slots)\n",
        "            col_num = len(context_q_slots)\n",
        "            for i, qs in enumerate(context_q_slots):\n",
        "                col, _ = col_select([], columns_all_prev)\n",
        "    #             if col_num - i <= len(columns_all_prev) and len(columns_all_prev) > 1:\n",
        "    #                 columns_all_prev = [x for x in columns_all_prev if x[0] != col]\n",
        "                q_slot_values[qs] = \" \".join(col.split(\" \")[:5])\n",
        "                slot_values[qs] = col\n",
        "    elif context_label == \"select insert column\":\n",
        "        sql_clauses[\"select\"] = sql_clauses[\"select\"] + \" , \" + \" , \".join(context_q_slots)\n",
        "        col_num = len(context_q_slots)\n",
        "        for i, qs in enumerate(context_q_slots):\n",
        "            col, _ = col_select([], columns_all_prev)\n",
        "#             if col_num - i <= len(columns_all_prev) and len(columns_all_prev) > 1:\n",
        "#                 columns_all_prev = [x for x in columns_all_prev if x[0] != col]\n",
        "            q_slot_values[qs] = \" \".join(col.split(\" \")[:5])\n",
        "            slot_values[qs] = col\n",
        "    elif context_label == \"select replace agg\":\n",
        "        if 'agg' not in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"agg\") > 1:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            assert sql_clauses[\"select\"].count(\"agg\") == 1\n",
        "            for s, v in slot_values.items():\n",
        "                if \"AGG\" in s:\n",
        "                    agg_kw_prev, agg_prev = s, v\n",
        "                    break\n",
        "            agg_cur_list = [x for x in AGG_OPS if x != agg_prev]\n",
        "            agg_kw_cur = context_q_slots[0]\n",
        "            sql_clauses[\"select\"] = sql_clauses[\"select\"].replace(agg_kw_prev.lower(), agg_kw_cur)\n",
        "            agg_cur = random.choice(agg_cur_list)\n",
        "            q_slot_values[agg_kw_cur] = random.choice(sql_components[\"AGG\"][agg_cur])\n",
        "            slot_values[agg_kw_cur] = agg_cur\n",
        "            if \"COLUMN0\" in context_question:\n",
        "                q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "    elif context_label == \"select delete column\":\n",
        "        if \"agg\" in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"column\") <= 1 or (sql_clauses[\"select\"].count(\"column\") <= 2 and len(context_q_slots) == 2):\n",
        "            satisfy = False\n",
        "        else:\n",
        "            assert sql_clauses[\"select\"].count(\"column\") > 1\n",
        "            sql_clauses[\"select\"] = \"select \" + \" , \".join(context_q_slots)\n",
        "            for qs in context_q_slots:\n",
        "                if \"{COLUMN10}\" == qs:\n",
        "                    if \"{COLUMN12}\" in slot_values.keys():\n",
        "                        slot_values[\"{COLUMN10}\"] = slot_values[\"{COLUMN12}\"]\n",
        "                    elif \"{COLUMN11}\" in slot_values.keys():\n",
        "                        slot_values[\"{COLUMN10}\"] = slot_values[\"{COLUMN11}\"]\n",
        "                    elif \"{COLUMN1}\" in slot_values.keys():\n",
        "                        slot_values[\"{COLUMN10}\"] = slot_values[\"{COLUMN1}\"]\n",
        "                    q_slot_values[qs] = slot_values[\"{COLUMN10}\"]\n",
        "                else:\n",
        "                    q_slot_values[qs] = slot_values[qs]\n",
        "    elif context_label == \"select delete agg\": # need to check more examples\n",
        "        if \"count\" not in sql_clauses[\"select\"] or (\"*\" in sql_clauses[\"select\"] and \"column\" in sql_clauses[\"select\"]) or (sql_clauses[\"select\"].count(\"column\") == 0 and len(context_q_slots) == 0) or (sql_clauses[\"select\"].count(\"column0\") == 0 and \"COLUMN0\" in context_question):\n",
        "            satisfy = False\n",
        "        else:\n",
        "            if len(context_q_slots) == 0:\n",
        "                sql_clauses[\"select\"] = \"select {COLUMN0}\"\n",
        "            elif \"{COLUMN0}\" in context_q_slots:\n",
        "                q_slot_values[context_q_slots[0]] = slot_values[\"{COLUMN0}\"]\n",
        "            else:\n",
        "                col, _ = col_select([], columns_all_prev)\n",
        "                q_slot_values[context_q_slots[0]] = col\n",
        "                slot_values[context_q_slots[0]] = col\n",
        "                sql_clauses[\"select\"] = \"select \" + context_q_slots[0]\n",
        "    elif context_label == \"select insert agg\":\n",
        "        if \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"column\") > 1:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            \n",
        "            if \"{AGG0}\" in context_q_slots:\n",
        "                slot_values[\"{AGG0}\"] = random.choices([\"MAX\", \"MIN\", \"SUM\", \"AVG\", \"COUNT\"], weights=(1, 1, 1, 1, 3), k=1)[0]\n",
        "                q_slot_values[\"{AGG0}\"] = random.choice(sql_components[\"AGG\"][slot_values[\"{AGG0}\"]])\n",
        "            else:\n",
        "                slot_values[\"{AGG0}\"] = \"COUNT\"\n",
        "                \n",
        "            if sql_clauses[\"select\"].count(\"column\") == 0:\n",
        "                sql_clauses[\"select\"] = \"select {AGG0} (*)\"\n",
        "                q_slot_values[\"{COLUMN0}\"] = \"\"\n",
        "            elif sql_clauses[\"select\"].count(\"column\") == 1:\n",
        "                sql_clauses[\"select\"] = \"select {AGG0} ({COLUMN0})\"\n",
        "                q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            else:\n",
        "                raise Exception(\"unexcepted select clause: \", sql_clauses[\"select\"])\n",
        "    elif context_label == \"select insert agg and column\":\n",
        "        if \"agg\" not in sql_clauses[\"select\"] and sql_clauses[\"group_by\"] == \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            sql_clauses[\"select\"] = sql_clauses[\"select\"] + \" , \" + \"{agg10} ({column10})\"\n",
        "            for i, qs in enumerate(context_q_slots):\n",
        "                if \"AGG\" in qs:\n",
        "                    slot_values[qs] = random.choice(AGG_OPS)\n",
        "                    q_slot_values[qs] = random.choice(sql_components[\"AGG\"][slot_values[qs]])\n",
        "                elif \"COLUMN\" in qs:\n",
        "                    col, _ = col_select([\"number\"], columns_all_prev)\n",
        "                    q_slot_values[qs] = \" \".join(col.split(\" \")[:5])\n",
        "                    slot_values[qs] = col\n",
        "\n",
        "            if \"agg\" in sql_clauses[\"select\"] and \"COLUMN\" not in context_question:\n",
        "                slot_values[\"{COLUMN10}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            \n",
        "            if \"agg\" not in sql_clauses[\"select\"] and \"COLUMN\" not in context_question:\n",
        "                satisfy = False\n",
        "    elif context_label == \"select replace agg and column\":\n",
        "        if sql_clauses[\"group_by\"] == \"\" and sql_clauses[\"where\"] == \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            sql_clauses[\"select\"] = \"select {agg10} ({column10})\"\n",
        "            for i, qs in enumerate(context_q_slots):\n",
        "                if \"AGG\" in qs:\n",
        "                    slot_values[qs] = random.choice(AGG_OPS)\n",
        "                    q_slot_values[qs] = random.choice(sql_components[\"AGG\"][slot_values[qs]])\n",
        "                elif \"COLUMN\" in qs:\n",
        "                    col, _ = col_select([\"number\"], columns_all_prev)\n",
        "                    q_slot_values[qs] = \" \".join(col.split(\" \")[:5])\n",
        "                    slot_values[qs] = col\n",
        "                    \n",
        "            if len(context_q_slots) == 0:\n",
        "                slot_values[\"{AGG10}\"] = \"COUNT\"\n",
        "                slot_values[\"{COLUMN10}\"] = \"*\"\n",
        "            elif len(context_q_slots) == 4:\n",
        "                sql_clauses[\"select\"] = \"select {agg10} ({column10}) , {agg20} ({column20})\"\n",
        "            \n",
        "            if sql_clauses[\"group_by\"] != \"\":\n",
        "                gb_col = sql_clauses[\"group_by\"].split(\" \")[2].upper()\n",
        "                assert \"COLUMN\" in gb_col\n",
        "                sql_clauses[\"select\"] = sql_clauses[\"select\"] + \" , \" + gb_col\n",
        "    elif context_label == \"where insert\":\n",
        "        if \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"]:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            if sql_clauses[\"where\"] != \"\":\n",
        "                sql_clauses[\"where\"] = sql_clauses[\"where\"] + \" AND \" + \"{COLUMN10} {OP10} {VALUE10}\"\n",
        "            else:\n",
        "                sql_clauses[\"where\"] = \"WHERE {COLUMN10} {OP10} {VALUE10}\"\n",
        "            \n",
        "            if \"{OP\" in context_question:\n",
        "                op_val = random.choice([\">\", \"<\", \">=\", \"<=\", \"=\"])\n",
        "            else:\n",
        "                op_val = \"=\"\n",
        "                \n",
        "            slot_values[\"{OP10}\"] = op_val\n",
        "            q_slot_values[\"{OP10}\"] = random.choice(sql_components[\"OP\"][op_val])\n",
        "                \n",
        "            if op_val != \"=\":\n",
        "                col, value = col_select([\"number\", \"VALUE10\"], columns_all_prev)\n",
        "            else:\n",
        "                col, value = col_select([\"VALUE10\"], columns_all_prev)\n",
        "            \n",
        "            q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "            slot_values[\"{COLUMN10}\"] = col\n",
        "            q_slot_values[\"{VALUE10}\"] = \" \".join(str(value[0][1]).split(\" \")[:5])\n",
        "            slot_values[\"{VALUE10}\"] = value[0][1]\n",
        "            if \"COLUMN0\" in context_question:\n",
        "                q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "    elif context_label == \"where replace\":\n",
        "        if sql_clauses[\"where\"].count(\"column\") != 1:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            sql_clauses[\"where\"] = \"WHERE {COLUMN10} {OP10} {VALUE10}\"\n",
        "            \n",
        "            if \"{OP\" in context_question:\n",
        "                op_val = random.choice([\">\", \"<\", \">=\", \"<=\", \"=\"])\n",
        "            else:\n",
        "                op_val = \"=\"\n",
        "                \n",
        "            slot_values[\"{OP10}\"] = op_val\n",
        "            q_slot_values[\"{OP10}\"] = random.choice(sql_components[\"OP\"][op_val])\n",
        "                \n",
        "            if op_val != \"=\":\n",
        "                col, value = col_select([\"number\", \"VALUE10\"], columns_all_prev)\n",
        "            else:\n",
        "                col, value = col_select([\"VALUE10\"], columns_all_prev)\n",
        "            \n",
        "            q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "            slot_values[\"{COLUMN10}\"] = col\n",
        "            q_slot_values[\"{VALUE10}\"] = \" \".join(str(value[0][1]).split(\" \")[:5])\n",
        "            slot_values[\"{VALUE10}\"] = value[0][1]\n",
        "            if \"COLUMN0\" in context_question:\n",
        "                q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "    elif context_label == \"where replace value\":\n",
        "        if sql_clauses[\"where\"].count(\"column\") != 1 or sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            wh_toks = sql_clauses[\"where\"].split(\" \")\n",
        "            for tok in wh_toks:\n",
        "                if \"column\" in tok:\n",
        "                    wh_col = tok\n",
        "                elif \"value\" in tok:\n",
        "                    wh_val = tok\n",
        "            sql_clauses[\"where\"] = sql_clauses[\"where\"].replace(wh_val, \"{VALUE10}\")\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[wh_col.upper()]\n",
        "            q_slot_values[\"{VALUE10}\"] = \" \".join(str(slot_values[wh_val.upper()]).split(\" \")[:2]) + \" \" + q_slot_values[\"{COLUMN0}\"].split(\" \")[0] #just to add noisy to fake value\n",
        "            slot_values[\"{VALUE10}\"] = q_slot_values[\"{VALUE10}\"]\n",
        "    elif context_label == \"where replace operation\":\n",
        "        if sql_clauses[\"where\"].count(\"column\") != 1 or sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            wh_toks = sql_clauses[\"where\"].split(\" \")\n",
        "            for tok in wh_toks:\n",
        "                if \"column\" in tok:\n",
        "                    wh_col = tok\n",
        "                elif \"value\" in tok:\n",
        "                    wh_val = tok\n",
        "                elif \"op\" in tok:\n",
        "                    wh_op = tok\n",
        "            sql_clauses[\"where\"] = sql_clauses[\"where\"].replace(wh_op, \"{OP10}\")\n",
        "            q_slot_values[\"{VALUE0}\"] = \" \".join(str(slot_values[wh_val.upper()]).split(\" \")[:4])\n",
        "            op_prev = slot_values[wh_op.upper()]\n",
        "            op_cur_list = [x for x in OPS if x != op_prev]\n",
        "            op_val = random.choice(op_cur_list)\n",
        "            slot_values[\"{OP10}\"] = op_val\n",
        "            q_slot_values[\"{OP10}\"] = random.choice(sql_components[\"OP\"][op_val])\n",
        "    \n",
        "    elif context_label == \"order_by insert\":\n",
        "        if \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            sql_clauses[\"order_by\"] = \"order by {column10} {dasc}\"\n",
        "            sc = random.choice([\"ASC\", \"DESC\"])\n",
        "            slot_values[\"{DASC}\"] = sc\n",
        "            col, _ = col_select([], columns_all_prev)\n",
        "            slot_values[\"{COLUMN10}\"] = col\n",
        "            q_slot_values[\"SC_COL\"] = random.choice(sql_components[\"SC_COL\"][sc]).replace(\"[COL]\", \" \".join(col.split(\" \")[:5]))\n",
        "    elif context_label == \"order_by insert limit\":\n",
        "        if \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or sql_clauses[\"order_by\"] == \"\" or \"limit\" in sql_clauses[\"order_by\"]:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            if \"{dasc}\" in sql_clauses[\"order_by\"]:\n",
        "                sc = slot_values[\"{DASC}\"]\n",
        "            else:\n",
        "                sc = \"ASC\"\n",
        "            sql_clauses[\"order_by\"] += \" limit {value10}\"\n",
        "            limit_val = random.choice([1,1,1,2,3,5])\n",
        "            slot_values[\"{VALUE10}\"] = limit_val\n",
        "            if limit_val == 1:\n",
        "                q_slot_values[\"SC_COL_LIMIT\"] = random.choice(sql_components[\"SC_COL_LIMIT\"][sc])\n",
        "            else:\n",
        "                q_slot_values[\"SC_COL_LIMIT\"] = random.choice(sql_components[\"SC_COL_LIMIT\"][sc+\"_NUM\"]).replace(\"[NUM]\", str(limit_val))\n",
        "    elif context_label == \"order_by insert limit | select delete agg and column\":\n",
        "        if \"count\" not in sql_clauses[\"select\"] or sql_clauses[\"group_by\"] == \"\" or sql_clauses[\"order_by\"] != \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            sql_clauses[\"order_by\"] = \"order by count (*) {dasc} limit 1\"\n",
        "            sel_cols = [x for x in sql_clauses[\"select\"].split(\" \") if \"column\" in x]\n",
        "            sql_clauses[\"select\"] = \"select \" + \" , \".join(sel_cols)\n",
        "            sc = random.choice([\"ASC\", \"DESC\"])\n",
        "            slot_values[\"{DASC}\"] = sc\n",
        "            q_slot_values[\"SC_COL_LIMIT\"] = random.choice(sql_components[\"SC_COL_LIMIT\"][sc])\n",
        "            if \"{COLUMN0}\" in slot_values.keys():\n",
        "                q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "    elif context_label == \"order_by insert limit | select replace column\":\n",
        "        if sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"] != \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            col, _ = col_select([], columns_all_prev)\n",
        "            q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "            slot_values[\"{COLUMN10}\"] = col\n",
        "            sql_clauses[\"select\"] = \"select {column10}\"\n",
        "            \n",
        "            sc = random.choice([\"ASC\", \"DESC\"])\n",
        "            slot_values[\"{DASC}\"] = sc\n",
        "            q_slot_values[\"SC_COL_LIMIT\"] = random.choice(sql_components[\"SC_COL_LIMIT\"][sc])\n",
        "            \n",
        "            if \"{COLUMN2}\" in context_question:\n",
        "                col2, _ = col_select([\"number\"], columns_all_prev)\n",
        "                q_slot_values[\"{COLUMN20}\"] = \" \".join(col2.split(\" \")[:5])\n",
        "                slot_values[\"{COLUMN20}\"] = col2\n",
        "                sql_clauses[\"order_by\"] = \"order by {column20} {dasc} limit 1\" \n",
        "            else:\n",
        "                sql_clauses[\"order_by\"] = \"order by count (*) {dasc} limit 1\"           \n",
        "    elif context_label == \"order_by replace sc\":\n",
        "        if \"agg\" in sql_clauses[\"select\"] or \"limit\" not in sql_clauses[\"order_by\"]:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            if \"{dasc}\" in sql_clauses[\"order_by\"]:\n",
        "                sc_prev = slot_values[\"{DASC}\"]\n",
        "            else:\n",
        "                sc_prev = \"ASC\"\n",
        "            sc = \"DESC\" if sc_prev == \"ASC\" else \"ASC\"\n",
        "            slot_values[\"{DASC}\"] = sc\n",
        "            q_slot_values[\"SC_COL_LIMIT\"] = random.choice(sql_components[\"SC_COL_LIMIT\"][sc])\n",
        "            if \"{COLUMN0}\" in slot_values.keys():\n",
        "                q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "    elif context_label == \"no change\":\n",
        "        if \"having\" not in sql_clauses[\"group_by\"] and \"value\" not in sql_clauses[\"order_by\"]:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            q_slot_values[\"{OP0}\"] = \"top\"\n",
        "            q_slot_values[\"[NUM]\"] = random.choice([3,5,10])\n",
        "            if \"having\" in sql_clauses[\"group_by\"]:\n",
        "                gb_toks = sql_clauses[\"group_by\"].split(\" \")\n",
        "                for tok in gb_toks:\n",
        "                    if \"op\" in tok:\n",
        "                        gb_op = tok.upper()\n",
        "                        q_slot_values[\"{OP0}\"] = random.choice(sql_components[\"OP\"][slot_values[gb_op]])\n",
        "    elif context_label == \"group_by insert | select insert agg and column\":\n",
        "        if sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"].count(\"column\") > 1 or \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or \"column0\" not in sql_clauses[\"select\"]:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            sql_clauses[\"group_by\"] = \"group by {column0}\"\n",
        "            if \"AGG\" not in context_question:\n",
        "                sql_clauses[\"select\"] = sql_clauses[\"select\"] + \" , count (*)\"\n",
        "            else:\n",
        "                sql_clauses[\"select\"] = sql_clauses[\"select\"] + \" , {agg10} ({column10})\"\n",
        "                agg_cur = random.choice(AGG_OPS)\n",
        "                slot_values[\"{AGG10}\"] = agg_cur\n",
        "                q_slot_values[\"{AGG10}\"] = random.choice(sql_components[\"AGG\"][agg_cur])\n",
        "                col, _ = col_select([\"number\"], columns_all_prev)\n",
        "                q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "                slot_values[\"{COLUMN10}\"] = col\n",
        "    elif context_label == \"group_by insert | select replace agg and column\":\n",
        "        if sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"] != \"\" or \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or \"column0\" not in sql_clauses[\"select\"]:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            sql_clauses[\"group_by\"] = \"group by {column0}\"\n",
        "            if \"AGG\" not in context_question:\n",
        "                sql_clauses[\"select\"] = \"select {column0} , count (*)\"\n",
        "            else:\n",
        "                if \"COLUMN1\" in context_question:\n",
        "                    col, _ = col_select([], columns_all_prev)\n",
        "                    q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "                    slot_values[\"{COLUMN10}\"] = col\n",
        "                    sql_clauses[\"select\"] = \"select {column10} , {agg10} ({column20})\"\n",
        "                    sql_clauses[\"group_by\"] = \"group by {column10}\"\n",
        "                else:\n",
        "                    sql_clauses[\"select\"] = \"select {column0} , {agg10} ({column20})\"\n",
        "                agg_cur = random.choice(AGG_OPS)\n",
        "                slot_values[\"{AGG10}\"] = agg_cur\n",
        "                q_slot_values[\"{AGG10}\"] = random.choice(sql_components[\"AGG\"][agg_cur])\n",
        "                col, _ = col_select([\"number\"], columns_all_prev)\n",
        "                q_slot_values[\"{COLUMN20}\"] = \" \".join(col.split(\" \")[:5])\n",
        "                slot_values[\"{COLUMN20}\"] = col\n",
        "    elif context_label == \"group_by insert | order_by insert\":\n",
        "        if sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"] != \"\" or \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or \"column0\" not in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"column\") > 2:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            sql_clauses[\"group_by\"] = \"group by {column0}\"\n",
        "            sql_clauses[\"order_by\"] = \"order by count (*) {dasc}\"\n",
        "\n",
        "            if \"COLUMN1\" in context_question:\n",
        "                col, _ = col_select([], columns_all_prev)\n",
        "                q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "                slot_values[\"{COLUMN10}\"] = col\n",
        "                sql_clauses[\"group_by\"] = \"group by {column10}\"\n",
        "            \n",
        "            sc = random.choice([\"ASC\", \"DESC\"])\n",
        "            slot_values[\"{DASC}\"] = sc\n",
        "            q_slot_values[\"SC\"] = random.choice(sql_components[\"SC\"][sc])\n",
        "    elif context_label == \"group_by insert having\":\n",
        "        if \"having\" in sql_clauses[\"group_by\"] or sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"] != \"\" or \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or \"column0\" not in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"column\") > 2:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            if sql_clauses[\"group_by\"] == \"\":\n",
        "                sql_clauses[\"group_by\"] = \"group by {column0} having count (*) {op0} {value0}\"\n",
        "            else:\n",
        "                sql_clauses[\"group_by\"] += \" having count (*) {op0} {value0}\"\n",
        "            \n",
        "            op_val = random.choice(OPS)\n",
        "            slot_values[\"{OP0}\"] = op_val\n",
        "            q_slot_values[\"{OP0}\"] = random.choice(sql_components[\"OP\"][op_val])\n",
        "            \n",
        "            value = random.choice([1, 3, 5, 10])\n",
        "            slot_values[\"{VALUE0}\"] = value\n",
        "            q_slot_values[\"{VALUE0}\"] = str(value)\n",
        "    elif context_label == \"group_by insert having | select delete agg and column\":\n",
        "        if \"having\" in sql_clauses[\"group_by\"] or sql_clauses[\"group_by\"] == \"\" or sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"] != \"\" or (\"agg\" not in sql_clauses[\"select\"] and \"count\" not in sql_clauses[\"select\"]) or \"column0\" not in sql_clauses[\"select\"]:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            sel_toks = sql_clauses[\"select\"].split(\" \")\n",
        "            agg_col_toks = []\n",
        "            for tok in sel_toks:\n",
        "                if \"select\" not in tok and \",\" not in tok:\n",
        "                    if \"({column\" in tok or \"column\" not in tok:\n",
        "                        agg_col_toks.append(tok)\n",
        "                if \")\" in tok:\n",
        "                    break\n",
        "            agg_col = \" \".join(agg_col_toks)\n",
        "            sql_clauses[\"select\"] = \" \".join([x for x in sel_toks if x not in agg_col_toks])\n",
        "            \n",
        "            sql_clauses[\"group_by\"] += \" having \" + agg_col + \" {op0} {value0}\"\n",
        "            \n",
        "            op_val = random.choice(OPS)\n",
        "            slot_values[\"{OP0}\"] = op_val\n",
        "            q_slot_values[\"{OP0}\"] = random.choice(sql_components[\"OP\"][op_val])\n",
        "            \n",
        "            value = random.choice([1, 3, 5, 10])\n",
        "            slot_values[\"{VALUE0}\"] = value\n",
        "            q_slot_values[\"{VALUE0}\"] = str(value)\n",
        "    elif context_label == \"group_by replace | select replace column\":\n",
        "        if sql_clauses[\"group_by\"] == \"\" or sql_clauses[\"where\"] != \"\" or \"column0\" not in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"column\") > 2:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            col, _ = col_select([], columns_all_prev)\n",
        "            q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "            slot_values[\"{COLUMN10}\"] = col\n",
        "            if \"{column0}\" in sql_clauses[\"group_by\"]:\n",
        "                sql_clauses[\"select\"] = sql_clauses[\"select\"].replace(\"{column0}\", \"{column10}\")\n",
        "                sql_clauses[\"group_by\"] = sql_clauses[\"group_by\"].replace(\"{column0}\", \"{column10}\")\n",
        "            elif \"{column1}\" in sql_clauses[\"group_by\"]:\n",
        "                sql_clauses[\"select\"] = sql_clauses[\"select\"].replace(\"{column1}\", \"{column10}\")\n",
        "                sql_clauses[\"group_by\"] = sql_clauses[\"group_by\"].replace(\"{column1}\", \"{column10}\")\n",
        "            else:\n",
        "                satisfy = False\n",
        "    elif context_label == \"insert SQL\":\n",
        "        if sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"].count(\"value\") != 1 or \"select\" in sql_clauses[\"where\"] or \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or \"column0\" not in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"column\") > 2:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            wh_toks = sql_clauses[\"where\"].split(\" \")\n",
        "            for tok in wh_toks:\n",
        "                if \"column\" in tok:\n",
        "                    wh_col = tok\n",
        "                elif \"value\" in tok:\n",
        "                    wh_val = tok\n",
        "                elif \"op\" in tok:\n",
        "                    wh_op = tok\n",
        "            \n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[wh_col.upper()]\n",
        "            q_slot_values[\"{VALUE0}\"] = slot_values[wh_val.upper()]\n",
        "            value = random.choice([1, 3, 5, 10])\n",
        "            slot_values[\"{VALUE10}\"] = value\n",
        "            q_slot_values[\"{VALUE10}\"] = str(value)\n",
        "            op_val = random.choice(OPS)\n",
        "            slot_values[\"{OP10}\"] = op_val\n",
        "            q_slot_values[\"{OP10}\"] = random.choice(sql_components[\"OP\"][op_val])\n",
        "            if \"{OP1\" in context_question:\n",
        "                sql_where = \" where {column0} {op10} {value10}\"\n",
        "            elif \"{VALUE1\" in context_question:\n",
        "                sql_where = \" where {column0} {op0} {value10}\"\n",
        "            else:\n",
        "                sql_where = \" where {column0} {op0} {value0}\"\n",
        "            if \"COLUMN1\" in context_question:\n",
        "                col, _ = col_select([], columns_all_prev)\n",
        "                q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "                slot_values[\"{COLUMN10}\"] = col\n",
        "                sql_clauses[\"select\"] = \"select {column10}\"\n",
        "            if context_constraints[0] == \"intersect\":\n",
        "                sql_clauses[\"group_by\"] = \"intersect \" + sql_clauses[\"select\"] + sql_where\n",
        "            else:\n",
        "                sql_clauses[\"group_by\"] = \"except \" + sql_clauses[\"select\"] + sql_where\n",
        "                sql_clauses[\"where\"] = \"\"\n",
        "    elif context_label == \"where insert SQL\":\n",
        "        if sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"].count(\"column\") > 1 or \"select\" in sql_clauses[\"where\"] or \"count\" in sql_clauses[\"select\"] or \"column0\" not in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"column\") > 1:\n",
        "            satisfy = False\n",
        "        elif \"agg\" in sql_clauses[\"select\"] and context_constraints[0] == \"op\":\n",
        "            col, _ = col_select([], columns_all_prev)\n",
        "            q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "            slot_values[\"{COLUMN10}\"] = col\n",
        "            sql_clauses[\"select\"] = \"select {column10}\"\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            op_val = random.choice(OPS)\n",
        "            slot_values[\"{OP10}\"] = op_val\n",
        "            q_slot_values[\"{OP10}\"] = random.choice(sql_components[\"OP\"][op_val])\n",
        "            sql_clauses[\"where\"] = \"where {column0} {op10} (\" + sql_pattern.lower() + \")\"\n",
        "            sql_clauses[\"where\"] = sql_clauses[\"where\"].replace(\"( \", \"(\").replace(\" )\", \")\")\n",
        "        elif \"agg\" not in sql_clauses[\"select\"] and context_constraints[0] != \"op\":\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            if \"{TABLE0}\" in slot_values.keys():\n",
        "                q_slot_values[\"{TABLE0}\"] = slot_values[\"{TABLE0}\"]\n",
        "            else:\n",
        "                q_slot_values[\"{TABLE0}\"] = \"\"\n",
        "                \n",
        "            if \"COLUMN1\" in context_question:\n",
        "                col, _ = col_select([], columns_all_prev)\n",
        "                q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "                slot_values[\"{COLUMN10}\"] = col\n",
        "                sql_clauses[\"select\"] = \"select {column10}\"\n",
        "                \n",
        "            if context_constraints[0] == \"not in\":\n",
        "                sql_clauses[\"where\"] = \"where {column0} not in (\" + sql_pattern.lower() + \")\"\n",
        "            else:\n",
        "                sql_clauses[\"where\"] = \"where {column0} in (\" + sql_pattern.lower() + \")\"\n",
        "            sql_clauses[\"where\"] = sql_clauses[\"where\"].replace(\"( \", \"(\").replace(\" )\", \")\")\n",
        "        else:\n",
        "            satisfy = False\n",
        "    else:\n",
        "        print(\"\\n--------------------Unexcepted context template: \", context_label)\n",
        "        satisfy = False\n",
        "    \n",
        "        \n",
        "    if satisfy:\n",
        "#         print(\"parsed prev sql: \", parsed)\n",
        "#         print(\"slot_values: \", slot_values)\n",
        "#         print(\"q_slot_values: \", q_slot_values)\n",
        "        sql_str_list = [v for k, v in sql_clauses.items() if v != \"\"]\n",
        "        sql_str_list.insert(1, \"{from}\")\n",
        "\n",
        "        sql_pattern_new = \" \".join(sql_str_list).upper().replace(\"(\", \"( \").replace(\")\", \" )\")\n",
        "        \n",
        "        # 9 generate final SQL-question pair\n",
        "        q_slot_values = {k.replace(\"10\", \"1\").replace(\"20\", \"2\").replace(\"30\", \"3\"): v for k, v in q_slot_values.items()}\n",
        "        context_q = replace_dict(context_question, q_slot_values)\n",
        "\n",
        "    return sql_pattern_new, slot_values, context_q, satisfy\n",
        "\n",
        "\n",
        "def add_augment_context(augment_data, context_templates, schema_dbs):\n",
        "    #question_gen, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all\n",
        "\n",
        "    data_new = {}\n",
        "    skip_count = 0\n",
        "    count = 0\n",
        "    augment_iso = augment_data.copy()\n",
        "    for schema_str, exs in augment_iso.items():\n",
        "        count += 1\n",
        "        if count % 10000 == 0:\n",
        "            print(\"processed: \", count)\n",
        "        data_new[schema_str] = []\n",
        "        for ex in exs:\n",
        "            sql_pattern = ex[5]\n",
        "            columns_all_prev = ex[6].copy()\n",
        "            question_prev = ex[0]\n",
        "            sql_prev = ex[1]\n",
        "            col_labels_prev = ex[2].copy()\n",
        "            q_slot_values_prev = ex[3]\n",
        "            slot_values_prev = ex[4].copy()\n",
        "            context_label_list = ex[7].copy()\n",
        "            \n",
        "            if random.random() <= 0.8:\n",
        "                try_num = 0\n",
        "                if \"INTERSECT\" in sql_pattern or \"UNION\" in sql_pattern or \"EXCEPT\" in sql_pattern or len(columns_all_prev) < 1:\n",
        "                    continue\n",
        "\n",
        "                while try_num < 3:\n",
        "                    context_template = random.choice(context_templates)\n",
        "                    context_label = context_template['label']\n",
        "                    prereqs = context_template[\"prereqs\"]\n",
        "                    edited_sql_pattern, slot_values, context_q, satisfy = edit_sql(sql_pattern, context_label, slot_values_prev, columns_all_prev, context_template)\n",
        "\n",
        "                    try_num += 1\n",
        "                    if satisfy:\n",
        "                        break\n",
        "\n",
        "                if not satisfy:\n",
        "                    continue\n",
        "\n",
        "                context_q = context_q + prev_token + question_prev\n",
        "\n",
        "    #             print(\"question: \", context_q)\n",
        "    #             print(\"previous sql pattern: \", sql_pattern)\n",
        "    #             print(\"edited_sql_pattern: \", edited_sql_pattern)\n",
        "\n",
        "                # 10 generate column labels\n",
        "                slot_values_new = {}\n",
        "                for sl, vl in slot_values.items():\n",
        "                    if \"COLUMN\" in sl:\n",
        "                        slot_values_new[sl] = \"_=_\".join(vl.split(\" \"))\n",
        "                    else:\n",
        "                        slot_values_new[sl] = vl\n",
        "\n",
        "                column_labels, skip = get_labels(edited_sql_pattern)\n",
        "                if skip:\n",
        "                    continue\n",
        "                column_lables_real = {}\n",
        "                for col, label in column_labels.items():\n",
        "                    if col != \"*\":\n",
        "                        col = slot_values[col]\n",
        "                    for slot, value in slot_values.items():\n",
        "                        label = label.replace(slot, str(value))\n",
        "                    column_lables_real[col] = label\n",
        "\n",
        "                edited_sql = replace_dict(edited_sql_pattern.replace(\" {FROM}\", \"\"), slot_values_new)\n",
        "\n",
        "                #(question_gen, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all)\n",
        "\n",
        "    #             print(\"edited_sql: \", edited_sql)\n",
        "    #             print(\"column_lables_real: \", column_lables_real)\n",
        "    #             print(\"\")\n",
        "                context_label_int = qsep_label_map[context_label]\n",
        "                context_label_list.insert(0, context_label_int)\n",
        "                data_new[schema_str].append((context_q, edited_sql, column_lables_real, None, slot_values, edited_sql_pattern, columns_all_prev, context_label_list))\n",
        "            else:\n",
        "                db = schema_dbs[schema_str]\n",
        "                sql_gen, question_gen, column_lables, q_slot_values, slot_values, template, columns_all = populate_one(db, templates, templates_one_table, sql_components)\n",
        "                context_q = question_gen + prev_token + question_prev\n",
        "                context_label_list.insert(0, 0)\n",
        "                data_new[schema_str].append((context_q, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all, context_label_list))\n",
        "            \n",
        "    return data_new       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DZ2gcWkJOcGC",
        "outputId": "2df9d908-d26f-4173-9c55-fdb32298f5c6"
      },
      "source": [
        "augment_second_webtable = add_augment_context(augment_first_webtable, context_templates, schema_dbs_webtable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processed:  10000\n",
            "processed:  20000\n",
            "processed:  30000\n",
            "processed:  40000\n",
            "processed:  50000\n",
            "processed:  60000\n",
            "processed:  70000\n",
            "processed:  80000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "PmPqQ-9oOcGD"
      },
      "source": [
        "two_count = 0\n",
        "for schema, examples in augment_second_webtable.items():\n",
        "    if two_count > 100:\n",
        "        break\n",
        "    for ex in examples:\n",
        "        two_count += 1\n",
        "        sql_pattern = ex[5]\n",
        "        columns_all_prev = ex[6]\n",
        "        question_prev = ex[0]\n",
        "        sql_prev = ex[1]\n",
        "        col_labels_prev = ex[2]\n",
        "        q_slot_values_prev = ex[3]\n",
        "        slot_values_prev = ex[4]\n",
        "        context_label_list = ex[7]\n",
        "        print(\"\\nsql_pattern: \", sql_pattern)\n",
        "        print(\"question: \", question_prev)\n",
        "        print(\"sql: \", sql_prev)\n",
        "        print(\"column labels: \", col_labels_prev)\n",
        "        print(\"slot values: \", slot_values_prev)\n",
        "        print(\"context_label_list: \", context_label_list)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB8CoqD9OcGD"
      },
      "source": [
        "slot_update_dict = {\"10\": \"11\", \"20\": \"21\", \"30\": \"31\"}\n",
        "\n",
        "def add_augment_context_second(augment_second_data, context_templates, schema_dbs):\n",
        "    #question_gen, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all, [context_label_int]\n",
        "\n",
        "    data_new = {}\n",
        "    skip_count = 0\n",
        "    count = 0\n",
        "    augment_second_iso = augment_second_data.copy()\n",
        "    for schema_str, exs in augment_second_iso.items():\n",
        "        count += 1\n",
        "        if count % 10000 == 0:\n",
        "            print(\"processed: \", count)\n",
        "        data_new[schema_str] = []\n",
        "        for ex in exs:\n",
        "            sql_pattern = replace_dict(ex[5], slot_update_dict)\n",
        "            columns_all_prev = ex[6].copy()\n",
        "            question_prev = ex[0]\n",
        "            sql_prev = ex[1]\n",
        "            col_labels_prev = ex[2].copy()\n",
        "            q_slot_values_prev = ex[3]\n",
        "            slot_values_prev = {replace_dict(k, slot_update_dict) : v for k, v in ex[4].items()}.copy()\n",
        "            context_label_list = ex[7].copy()\n",
        "            \n",
        "            \n",
        "            if random.random() <= 0.8:\n",
        "                try_num = 0\n",
        "                if \"INTERSECT\" in sql_pattern or \"UNION\" in sql_pattern or \"EXCEPT\" in sql_pattern or len(columns_all_prev) < 1:\n",
        "                    continue\n",
        "\n",
        "                while try_num < 3:\n",
        "                    context_template = random.choice(context_templates)\n",
        "                    context_label = context_template['label']\n",
        "                    prereqs = context_template[\"prereqs\"]\n",
        "                    edited_sql_pattern, slot_values, context_q, satisfy = edit_sql(sql_pattern, context_label, slot_values_prev, columns_all_prev, context_template)\n",
        "\n",
        "                    try_num += 1\n",
        "                    if satisfy:\n",
        "                        break\n",
        "\n",
        "                if not satisfy:\n",
        "                    continue\n",
        "\n",
        "                context_q = context_q + prev_token + question_prev\n",
        "\n",
        "    #             print(\"question: \", context_q)\n",
        "    #             print(\"previous sql pattern: \", sql_pattern)\n",
        "    #             print(\"edited_sql_pattern: \", edited_sql_pattern)\n",
        "\n",
        "                # 10 generate column labels\n",
        "                slot_values_new = {}\n",
        "                for sl, vl in slot_values.items():\n",
        "                    if \"COLUMN\" in sl:\n",
        "                        slot_values_new[sl] = \"_=_\".join(vl.split(\" \"))\n",
        "                    else:\n",
        "                        slot_values_new[sl] = vl\n",
        "\n",
        "                column_labels, skip = get_labels(edited_sql_pattern)\n",
        "                if skip:\n",
        "                    continue\n",
        "                column_lables_real = {}\n",
        "                for col, label in column_labels.items():\n",
        "                    if col != \"*\":\n",
        "                        if col not in slot_values.keys():\n",
        "                            print(\"slot_values_prev: \", slot_values_prev)\n",
        "                            print(\"q_slot_values_prev: \", q_slot_values_prev)\n",
        "                            print(\"sql_pattern: \", sql_pattern)\n",
        "                            print(\"context_label: \", context_label)\n",
        "                            print(\"edited_sql_pattern: \", edited_sql_pattern)\n",
        "                            print(\"slot_values: \", slot_values)\n",
        "                            print(\"column_labels: \", column_labels)\n",
        "                        col = slot_values[col]\n",
        "                    for slot, value in slot_values.items():\n",
        "                        label = label.replace(slot, str(value))\n",
        "                    column_lables_real[col] = label\n",
        "\n",
        "                edited_sql = replace_dict(edited_sql_pattern.replace(\" {FROM}\", \"\"), slot_values_new)\n",
        "\n",
        "                #(question_gen, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all)\n",
        "\n",
        "    #             print(\"edited_sql: \", edited_sql)\n",
        "    #             print(\"column_lables_real: \", column_lables_real)\n",
        "    #             print(\"\")\n",
        "                context_label_int = qsep_label_map[context_label]\n",
        "                context_label_list.insert(0, context_label_int)\n",
        "                \n",
        "                data_new[schema_str].append((context_q, edited_sql, column_lables_real, None, slot_values, edited_sql_pattern, columns_all_prev, context_label_list))\n",
        "            else:\n",
        "                db = schema_dbs[schema_str]\n",
        "                sql_gen, question_gen, column_lables, q_slot_values, slot_values, template, columns_all = populate_one(db, templates, templates_one_table, sql_components)\n",
        "                context_q = question_gen + prev_token + question_prev\n",
        "                context_label_list.insert(0, 0)\n",
        "                data_new[schema_str].append((context_q, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all, context_label_list))\n",
        "            \n",
        "    return data_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dJ7kRdmWOcGD"
      },
      "source": [
        "augment_third_webtable = add_augment_context_second(augment_second_webtable, context_templates, schema_dbs_webtable)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zkSceF9QOcGD",
        "outputId": "c4fadbcc-d1cf-4741-aa75-babcc6f0a438"
      },
      "source": [
        "two_count = 0\n",
        "for schema, examples in augment_third_webtable.items():\n",
        "    for ex in examples:\n",
        "        two_count += 1\n",
        "#         sql_pattern = ex[5]\n",
        "#         columns_all_prev = ex[6]\n",
        "#         question_prev = ex[0]\n",
        "#         sql_prev = ex[1]\n",
        "#         col_labels_prev = ex[2]\n",
        "#         q_slot_values_prev = ex[3]\n",
        "#         slot_values_prev = ex[4]\n",
        "#         context_label_list = ex[7]\n",
        "#         print(\"\\nsql_pattern: \", sql_pattern)\n",
        "#         print(\"question: \", question_prev)\n",
        "#         print(\"sql: \", sql_prev)\n",
        "#         print(\"column labels: \", col_labels_prev)\n",
        "#         print(\"context_label_list: \", context_label_list)\n",
        "#         print(\"slot_values: \", slot_values_prev)\n",
        "print(two_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4u892njOcGE"
      },
      "source": [
        "slot_update_dict = {\"10\": \"12\", \"20\": \"22\", \"30\": \"32\"}\n",
        "\n",
        "def add_augment_context_third(augment_third_data, context_templates, schema_dbs):\n",
        "    #question_gen, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all, [context_label_int]\n",
        "\n",
        "    data_new = {}\n",
        "    skip_count = 0\n",
        "    count = 0\n",
        "    augment_third_iso = augment_third_data.copy()\n",
        "    for schema_str, exs in augment_third_iso.items():\n",
        "        count += 1\n",
        "        if count % 10000 == 0:\n",
        "            print(\"processed: \", count)\n",
        "        data_new[schema_str] = []\n",
        "        for ex in exs:\n",
        "            sql_pattern = replace_dict(ex[5], slot_update_dict)\n",
        "            columns_all_prev = ex[6].copy()\n",
        "            question_prev = ex[0]\n",
        "            sql_prev = ex[1]\n",
        "            col_labels_prev = ex[2].copy()\n",
        "            q_slot_values_prev = ex[3]\n",
        "            slot_values_prev = {replace_dict(k, slot_update_dict) : v for k, v in ex[4].items()}.copy()\n",
        "            context_label_list = ex[7].copy()\n",
        "            \n",
        "            \n",
        "            if random.random() <= 0.8:\n",
        "                try_num = 0\n",
        "                if \"INTERSECT\" in sql_pattern or \"UNION\" in sql_pattern or \"EXCEPT\" in sql_pattern or len(columns_all_prev) < 1:\n",
        "                    continue\n",
        "\n",
        "                while try_num < 3:\n",
        "                    context_template = random.choice(context_templates)\n",
        "                    context_label = context_template['label']\n",
        "                    prereqs = context_template[\"prereqs\"]\n",
        "                    edited_sql_pattern, slot_values, context_q, satisfy = edit_sql(sql_pattern, context_label, slot_values_prev, columns_all_prev, context_template)\n",
        "\n",
        "                    try_num += 1\n",
        "                    if satisfy:\n",
        "                        break\n",
        "\n",
        "                if not satisfy:\n",
        "                    continue\n",
        "\n",
        "                context_q = context_q + prev_token + question_prev\n",
        "\n",
        "    #             print(\"question: \", context_q)\n",
        "    #             print(\"previous sql pattern: \", sql_pattern)\n",
        "    #             print(\"edited_sql_pattern: \", edited_sql_pattern)\n",
        "\n",
        "                # 10 generate column labels\n",
        "                slot_values_new = {}\n",
        "                for sl, vl in slot_values.items():\n",
        "                    if \"COLUMN\" in sl:\n",
        "                        slot_values_new[sl] = \"_=_\".join(vl.split(\" \"))\n",
        "                    else:\n",
        "                        slot_values_new[sl] = vl\n",
        "\n",
        "                column_labels, skip = get_labels(edited_sql_pattern)\n",
        "                if skip:\n",
        "                    continue\n",
        "                column_lables_real = {}\n",
        "                for col, label in column_labels.items():\n",
        "                    if col != \"*\":\n",
        "                        if col not in slot_values.keys():\n",
        "                            print(\"slot_values_prev: \", slot_values_prev)\n",
        "                            print(\"q_slot_values_prev: \", q_slot_values_prev)\n",
        "                            print(\"sql_pattern: \", sql_pattern)\n",
        "                            print(\"context_label: \", context_label)\n",
        "                            print(\"edited_sql_pattern: \", edited_sql_pattern)\n",
        "                            print(\"slot_values: \", slot_values)\n",
        "                            print(\"column_labels: \", column_labels)\n",
        "                        col = slot_values[col]\n",
        "                    for slot, value in slot_values.items():\n",
        "                        label = label.replace(slot, str(value))\n",
        "                    column_lables_real[col] = label\n",
        "\n",
        "                edited_sql = replace_dict(edited_sql_pattern.replace(\" {FROM}\", \"\"), slot_values_new)\n",
        "\n",
        "                #(question_gen, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all)\n",
        "\n",
        "    #             print(\"edited_sql: \", edited_sql)\n",
        "    #             print(\"column_lables_real: \", column_lables_real)\n",
        "    #             print(\"\")\n",
        "                context_label_int = qsep_label_map[context_label]\n",
        "                context_label_list.insert(0, context_label_int)\n",
        "                \n",
        "                data_new[schema_str].append((context_q, edited_sql, column_lables_real, None, slot_values, edited_sql_pattern, columns_all_prev, context_label_list))\n",
        "            else:\n",
        "                db = schema_dbs[schema_str]\n",
        "                sql_gen, question_gen, column_lables, q_slot_values, slot_values, template, columns_all = populate_one(db, templates, templates_one_table, sql_components)\n",
        "                context_q = question_gen + prev_token + question_prev\n",
        "                context_label_list.insert(0, 0)\n",
        "                data_new[schema_str].append((context_q, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all, context_label_list))\n",
        "            \n",
        "    return data_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--23zgGcOcGE",
        "outputId": "4b1a3cd9-d6c8-4546-85ce-ef8319b772ac"
      },
      "source": [
        "augment_fourth_webtable = add_augment_context_third(augment_third_webtable, context_templates, schema_dbs_webtable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Warning: unexcepted SELECT format\n",
            "SELECT {COLUMN12} {FROM} WHERE {COLUMN0} NOT IN ( SELECT {COLUMN0} { FROM} ) AND {COLUMN10} {OP10} {VALUE10}\n",
            "processed:  10000\n",
            "\n",
            "Warning: unexcepted SELECT format\n",
            "SELECT {COLUMN0} , {COLUMN12} {FROM} WHERE {COLUMN0} NOT IN ( SELECT {COLUMN0} { FROM} ) AND {COLUMN10} {OP10} {VALUE10}\n",
            "processed:  20000\n",
            "\n",
            "Warning: unexcepted SELECT format\n",
            "SELECT {COLUMN11} , {COLUMN12} , {COLUMN22} {FROM} WHERE {COLUMN0} IN ( SELECT {COLUMN0} { FROM} ) AND {COLUMN10} {OP10} {VALUE10}\n",
            "processed:  30000\n",
            "processed:  40000\n",
            "\n",
            "Warning: unexcepted SELECT format\n",
            "SELECT {COLUMN0} , {COLUMN12} {FROM} WHERE {COLUMN0} NOT IN ( SELECT {COLUMN0} { FROM} ) AND {COLUMN10} {OP10} {VALUE10}\n",
            "processed:  50000\n",
            "processed:  60000\n",
            "processed:  70000\n",
            "processed:  80000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mWSqelagOcGE"
      },
      "source": [
        "two_count = 0\n",
        "for schema, examples in augment_fourth_webtable.items():\n",
        "    if two_count > 100:\n",
        "        break\n",
        "    for ex in examples:\n",
        "        two_count += 1\n",
        "        sql_pattern = ex[5]\n",
        "        columns_all_prev = ex[6]\n",
        "        question_prev = ex[0]\n",
        "        sql_prev = ex[1]\n",
        "        col_labels_prev = ex[2]\n",
        "        q_slot_values_prev = ex[3]\n",
        "        slot_values_prev = ex[4]\n",
        "        context_label_list = ex[7]\n",
        "        print(\"\\nsql_pattern: \", sql_pattern)\n",
        "        print(\"question: \", question_prev)\n",
        "        print(\"sql: \", sql_prev)\n",
        "        print(\"column labels: \", col_labels_prev)\n",
        "        print(\"slot values: \", slot_values_prev)\n",
        "        print(\"context_label_list: \", context_label_list)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SbP4tz39OcGE",
        "outputId": "23c8f1a5-c2b7-4628-d105-bd28095bd8fa"
      },
      "source": [
        "two_count = 0\n",
        "for schema, examples in augment_fourth_webtable.items():\n",
        "    for ex in examples:\n",
        "        two_count += 1\n",
        "#         sql_pattern = ex[5]\n",
        "#         columns_all_prev = ex[6]\n",
        "#         question_prev = ex[0]\n",
        "#         sql_prev = ex[1]\n",
        "#         col_labels_prev = ex[2]\n",
        "#         q_slot_values_prev = ex[3]\n",
        "#         slot_values_prev = ex[4]\n",
        "#         context_label_list = ex[7]\n",
        "#         print(\"\\nsql_pattern: \", sql_pattern)\n",
        "#         print(\"question: \", question_prev)\n",
        "#         print(\"sql: \", sql_prev)\n",
        "#         print(\"column labels: \", col_labels_prev)\n",
        "#         print(\"context_label_list: \", context_label_list)\n",
        "#         print(\"slot_values: \", slot_values_prev)\n",
        "print(two_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "54557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtigjTnNOcGE"
      },
      "source": [
        "prev1_token = \" </ \"\n",
        "prev2_token = \" :/ \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4W10E4WOcGF"
      },
      "source": [
        "##### Map SQL labels of all augmented examples into numeric labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn8VnI_ZOcGF"
      },
      "source": [
        "### process label prints for each column\n",
        "def get_label_map(data):\n",
        "    label_dict = defaultdict(int)\n",
        "    for schema_str, example_list in data.items():\n",
        "        for example in example_list:\n",
        "            (question, sql, col_labels) = example\n",
        "            for val in col_labels.values():\n",
        "                label_dict[val] += 1\n",
        "    label_list = sorted(label_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
        "    label_map = {}\n",
        "    count = 1\n",
        "    for label, _ in label_list:\n",
        "        label_map[label] = count\n",
        "        count += 1\n",
        "    \n",
        "    return label_map\n",
        "\n",
        "def map_labels(data, label_map, is_dev=False):\n",
        "    data_new = {}\n",
        "    skip_count = 0\n",
        "    count = 0\n",
        "    augment_data = data.copy()\n",
        "    for schema_str, exs in augment_data.items():\n",
        "        count += 1\n",
        "        if count % 100000 == 0:\n",
        "            print(\"processed: \", count)\n",
        "        data_new[schema_str] = []\n",
        "        for ex in exs:\n",
        "            skip = False\n",
        "            label_dict = ex[2]\n",
        "            label_dict_new = {}\n",
        "            for col, label in label_dict.items():\n",
        "                if label in label_map.keys():\n",
        "                    label_dict_new[col] = label_map[label]\n",
        "                else:\n",
        "                    skip = True\n",
        "                    skip_count += 1\n",
        "                    #else just skip\n",
        "#             context_q, edited_sql, column_lables_real, label_dict_int, slot_values, edited_sql_pattern, context_label_list\n",
        "            if not skip:\n",
        "        \n",
        "                data_new[schema_str].append((ex[0], ex[1], ex[2], label_dict_new, ex[4], ex[5], ex[7]))   \n",
        "    \n",
        "    print(\"skip_count: \", skip_count)\n",
        "    return data_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTmtekDTOcGF"
      },
      "source": [
        "import pickle\n",
        "label_map_file = \"data/labels_map.pkl\"\n",
        "# label_map_final = get_label_map(fine_tuning_data_augment_with_dev_wikisql)\n",
        "# with open(label_map_file, 'wb') as fp:\n",
        "#     pickle.dump(label_map_final, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open(label_map_file, 'rb') as fp:\n",
        "    label_map = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6sJGI1KOcGF",
        "outputId": "6042d422-0375-4515-9e78-3a81f9995461"
      },
      "source": [
        "augment_first_webtable = map_labels(augment_first_webtable, label_map)\n",
        "augment_second_webtable = map_labels(augment_second_webtable, label_map)\n",
        "augment_third_webtable = map_labels(augment_third_webtable, label_map)\n",
        "augment_fourth_webtable = map_labels(augment_fourth_webtable, label_map)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "skip_count:  0\n",
            "skip_count:  4885\n",
            "skip_count:  3807\n",
            "skip_count:  2632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOVHfkMmOcGF",
        "outputId": "5c2d2849-e7bf-4c33-e5c1-a5128060ce1b"
      },
      "source": [
        "augment_context_all_webtable = defaultdict(list)\n",
        "for augment_one in [augment_first_webtable, augment_second_webtable, augment_third_webtable, augment_fourth_webtable]:\n",
        "    for schema, examples in augment_one.items():\n",
        "        augment_context_all_webtable[schema].extend(examples)\n",
        "\n",
        "two_count = 0\n",
        "for schema, examples in augment_context_all_webtable.items():\n",
        "    for ex in examples:\n",
        "        two_count += 1\n",
        "print(two_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "409424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hTC52FbOcGF"
      },
      "source": [
        "##### Write and save file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLGxsNKBOcGG"
      },
      "source": [
        "MAX_TOKEN_LEN = 200\n",
        "def write_final_file(augment_data):\n",
        "    data_json = []\n",
        "    skip_count = 0\n",
        "    line_count = 0\n",
        "    dup_count = 0\n",
        "    pro_count = 0\n",
        "    for schema_str, exs in augment_data.items():\n",
        "        for ex in exs:\n",
        "            line_count += 1\n",
        "            if line_count % 100000 == 0:\n",
        "                print(\"processed: \", line_count)\n",
        "            question, sql, label_strs, label_ints, sql_slot_values, sql_pattern, context_label_list = ex\n",
        "            col_str, val_str = schema_str.split(\" |-| \")\n",
        "            colns = col_str.split(\" </s> \")\n",
        "            values = val_str.split(\" </s> \")\n",
        "            assert len(colns) == len(values)\n",
        "            cols = []\n",
        "            label_num = len(label_ints)\n",
        "            label_count = 0\n",
        "            for idx, coln in enumerate(colns):\n",
        "                col = {}\n",
        "                col[\"name\"] = coln\n",
        "                col[\"value\"] = values[idx]\n",
        "                if coln != \"*\":\n",
        "                    col[\"name\"] = \" \".join(coln.split(\" \")[1:])\n",
        "                col[\"label_int\"] = 0\n",
        "                if coln in label_ints.keys():\n",
        "                    col[\"label_int\"] = label_ints[coln]\n",
        "                    label_count += 1\n",
        "                cols.append(col)\n",
        "            \n",
        "            assert label_count >= label_num\n",
        "            if label_count > label_num:\n",
        "                dup_count += 1\n",
        "#                 print(\"\\nWARNING: deplicated columns!\")\n",
        "#                 print(\"label_ints: \", label_ints)\n",
        "#                 print(\"colns: \", colns)\n",
        "            \n",
        "            col_list = []\n",
        "            label_list = []\n",
        "            value_list = []\n",
        "            col_count = 0\n",
        "            for i, col in enumerate(cols):\n",
        "                if col_count > 40 and col[\"label_int\"] == 0:\n",
        "                    continue\n",
        "                col_list.append(col[\"name\"])\n",
        "                value_list.append(col[\"value\"])\n",
        "                col_count += 1\n",
        "                label_list.append(int(col[\"label_int\"]))\n",
        "            assert len(col_list) == len(value_list)\n",
        "            \n",
        "            assert question.count(prev_token) + 1 == len(context_label_list)\n",
        "            \n",
        "            label_str = \" \".join([str(k) for k in label_list])\n",
        "            q_col_str = \"<s> \" + question.lower() + \" </s> \" + \" </s> \".join(col_list).strip() + \" </s> \"\n",
        "            example_str = q_col_str + \" ||| \" + label_str + \" ||| \" + \" \".join([str(x) for x in context_label_list])\n",
        "            tokens = tokenizer.tokenize(q_col_str)\n",
        "            if len(tokens) > MAX_TOKEN_LEN:\n",
        "                continue\n",
        "                \n",
        "            data_json.append({\"question\": question.lower(),\n",
        "                              \"columns\": col_list,\n",
        "                              \"rows\": [value_list],\n",
        "                              \"column_labels\": label_list,\n",
        "                              \"example_str\": example_str,\n",
        "                              \"context_labels\": context_label_list\n",
        "                             })\n",
        "            pro_count += 1\n",
        "\n",
        "    print(\"total line: \", line_count)\n",
        "    print(\"skiped line: \", skip_count)\n",
        "    print(\"dup line: \", dup_count)\n",
        "    print(\"pro line: \", pro_count)\n",
        "    \n",
        "    return data_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0I1oJtgOcGG",
        "outputId": "d6f3a1ad-74af-41bd-ba7b-138ea8bdf35e"
      },
      "source": [
        "data_json = write_final_file(augment_context_all_webtable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processed:  100000\n",
            "processed:  200000\n",
            "processed:  300000\n",
            "processed:  400000\n",
            "total line:  409424\n",
            "skiped line:  0\n",
            "dup line:  1577\n",
            "pro line:  391439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeBCiD86OcGG",
        "outputId": "e421718a-e728-47aa-d5c4-0b8e26535ede"
      },
      "source": [
        "len(data_json)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "391439"
            ]
          },
          "execution_count": 808,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-2-WMk0OcGG"
      },
      "source": [
        "with open('data/augment_wikitable_context.json', 'w') as outfile:\n",
        "    json.dump(data_json, outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJmZVPrCOcGG"
      },
      "source": [
        "import codecs\n",
        "def write_to_file(sql_data, output_file):\n",
        "    table_file = codecs.open(output_file, \"w\", \"utf-8\")\n",
        "    valid_count = 0\n",
        "    num_sql = len(sql_data)\n",
        "    check_point = int(num_sql*0.1)\n",
        "    max_col_num = 0\n",
        "    unique_labels = set()\n",
        "    skip_count = 0\n",
        "    for tn, sql_one in enumerate(sql_data):\n",
        "        if tn % check_point == 0:\n",
        "            print(\"processed: \", str(round(tn/num_sql, 2)))\n",
        "        example_str = sql_one['example_str']\n",
        "        valid_count += 1\n",
        "        table_file.write(example_str.strip().replace(\"\\n\", \"\"))\n",
        "        #add column names in another new line\n",
        "        table_file.write(\"\\n\")\n",
        "\n",
        "    table_file.close()\n",
        "\n",
        "    return valid_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqNo2CThOcGG"
      },
      "source": [
        "write_to_file(data_json, \"data/augment_wikitable_context.txt\")"
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}