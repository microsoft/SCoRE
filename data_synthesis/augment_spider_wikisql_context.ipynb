{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "augment_spider_wikisql_context.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "58FMWCpsIop7"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "import codecs\n",
        "from template_config import *\n",
        "from nltk import word_tokenize\n",
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GISW_jYeIop-"
      },
      "source": [
        "MAX_COL_NUM = 20\n",
        "OPS = [\"=\", \">\", \"<\", \">=\", \"<=\", \"!=\", \"LIKE\"]\n",
        "nlsql_templates_file = \"data/nlsql_templates_context.txt\"\n",
        "spider_data_file = '/home/t-tyu/projects/NL2CodeOverData/data/spider'\n",
        "sql_components_file = \"data/sql_components.json\"\n",
        "wikisql_tables_file = \"/home/t-tyu/projects/NL2CodeOverData/data/tabq_datasets/SQLNet/data/train_tok.tables.jsonl\"\n",
        "wikisql_tables_file_dev = \"/home/t-tyu/projects/NL2CodeOverData/data/tabq_datasets/SQLNet/data/dev_tok.tables.jsonl\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH9AdwDaIop_"
      },
      "source": [
        "# read NL-SQL templates\n",
        "templates = []\n",
        "with open(nlsql_templates_file) as fp:\n",
        "    lines = fp.readlines()\n",
        "    template_one = {}\n",
        "    for line in lines:\n",
        "        if \"\\n\" == line:\n",
        "            templates.append(template_one) \n",
        "        elif \"SQL Pattern:\" in line:\n",
        "            template_one = {}\n",
        "            sps = line.strip().replace(\"SQL Pattern: \", \"\").split(\"|||\")\n",
        "            template_one[\"questions\"] = []\n",
        "            if len(sps) == 1:\n",
        "                template_one[\"SQL pattern\"] = sps[0]\n",
        "                template_one[\"SQL constraints\"] = []\n",
        "            elif len(sps) == 2:\n",
        "                template_one[\"SQL pattern\"] = sps[0]\n",
        "                template_one[\"SQL constraints\"] = [x.strip() for x in sps[1].split(\"|\") if x != \" \"]\n",
        "            else:\n",
        "                print(\"\\n======Error warning!!!!\")\n",
        "        elif \"count: \" in line:\n",
        "            sql_count = int(line.strip().replace(\"count: \", \"\"))\n",
        "            template_one[\"count\"] = sql_count\n",
        "        elif \"question:  \" in line:\n",
        "            sps = line.strip().replace(\"question:  \", \"\").split(\"|||\")\n",
        "            question = sps[0]\n",
        "            if len(sps) == 2:\n",
        "                q_constraints = [x.strip() for x in sps[1].split(\"|\") if x != \" \"]\n",
        "            else:\n",
        "                q_constraints = []\n",
        "            template_one[\"questions\"].append((question, q_constraints))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQGlK9FBIoqA",
        "outputId": "9ef53000-b80b-4bdc-e854-7690c7897210"
      },
      "source": [
        "all_constraints = []\n",
        "for tmp in templates:\n",
        "    all_constraints.extend(tmp['SQL constraints'])\n",
        "    for q in tmp['questions']:\n",
        "        all_constraints.extend(q[1])\n",
        "\n",
        "print(list(set(all_constraints)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['P0==', 'C1-id', 'T0-T1-JOIN']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-LZzx_fIoqB"
      },
      "source": [
        "# read SQL component file\n",
        "with open(sql_components_file) as json_file:\n",
        "    sql_components = json.load(json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxlIZ4cqIoqB"
      },
      "source": [
        "def read_tables(table_path):\n",
        "    table_data = []\n",
        "    print (\"Loading data from %s\" % (table_path))\n",
        "    with open(table_path) as inf:\n",
        "        for line in inf:\n",
        "            tab = json.loads(line.strip())\n",
        "            table_data.append(tab)\n",
        "    print(\"table number in wikisql original table.json file: {}\".format(len(table_data)))\n",
        "    \n",
        "    return table_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyIGC6L9IoqC",
        "outputId": "05a81359-e21c-418f-8832-5fc140a5ea1f"
      },
      "source": [
        "# read WikiSQL tables\n",
        "wikisql_tables_train = read_tables(wikisql_tables_file)\n",
        "# wikisql_tables_dev = read_tables(wikisql_tables_file_dev)\n",
        "# + wikisql_tables_dev\n",
        "wikisql_tables = wikisql_tables_train "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from /home/t-tyu/projects/NL2CodeOverData/data/tabq_datasets/SQLNet/data/train_tok.tables.jsonl\n",
            "table number in wikisql original table.json file: 18585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H42Np5JkIoqD"
      },
      "source": [
        "# remove replicated tables\n",
        "unique_wikisql_tables = []\n",
        "headers = []\n",
        "for wt in wikisql_tables:\n",
        "    if wt[\"header\"] not in headers and \"page_title\" in wt.keys():\n",
        "        headers.append(wt[\"header\"])\n",
        "        unique_wikisql_tables.append(wt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7WehD73IoqD",
        "outputId": "a1b7eb53-66a3-4491-eb35-157c4d6f4443"
      },
      "source": [
        "len(unique_wikisql_tables)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6997"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Tu3ATzIoqE"
      },
      "source": [
        "# # helper code\n",
        "# unique_wikisql_tables[1000].keys()\n",
        "# types_all = []\n",
        "# for tab in unique_wikisql_tables:\n",
        "#     types_all.extend(tab[\"types\"])\n",
        "# types_all = list(set(types_all))\n",
        "# print(types_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YCRkdKWEIoqE"
      },
      "source": [
        "def hasNumbers(inputString):\n",
        "    return any(char.isdigit() for char in inputString)\n",
        "\n",
        "def check_name(inpStr):\n",
        "    return len(inpStr) > 1 and \"-\" not in inpStr and not hasNumbers(inpStr)\n",
        "\n",
        "def gen_name(title, must_have=False):\n",
        "    title_tokens = word_tokenize(title)\n",
        "    qualify_words = []\n",
        "    for w in title_tokens:\n",
        "        if check_name(w):\n",
        "            qualify_words.append(w)\n",
        "    \n",
        "    if random.random() < 0.4:\n",
        "        name = \" \".join(qualify_words[-2:])\n",
        "    else:\n",
        "        name = \" \".join(qualify_words[-1:])\n",
        "    \n",
        "    if name != \"\":\n",
        "        return name\n",
        "    \n",
        "    if must_have:\n",
        "        return title_tokens[0]\n",
        "    else:\n",
        "        return name\n",
        "    \n",
        "tables_clean = []\n",
        "for table in unique_wikisql_tables:\n",
        "    headers = [hd.lower().replace(\"*\", \"\") for hd in table[\"header\"]]\n",
        "    sec_title = table[\"section_title\"]\n",
        "    page_title = table[\"page_title\"]\n",
        "    caption = table[\"caption\"]\n",
        "    types = table[\"types\"]\n",
        "    table_name = \"table\"\n",
        "    if sec_title != \"\":\n",
        "        table_name = gen_name(sec_title)\n",
        "#         print(\"table_name: \", table_name)\n",
        "    if table_name == \"\" and caption != \"\":\n",
        "        table_name = gen_name(caption)\n",
        "    if table_name == \"\" and page_title != \"\":\n",
        "        table_name = gen_name(page_title, True)\n",
        "    if table_name == \"table\":\n",
        "         continue\n",
        "    \n",
        "    # only keep values of the first 3 rows\n",
        "    rows = [row for row in table[\"rows\"][:3]]    \n",
        "    #if no id in the table columns, add new column \"id\" or name with p=0.3 \n",
        "    # and add row ent and type for new added column id\n",
        "    if random.random() < 0.7:\n",
        "        index_col = \"id\"\n",
        "        if random.random() < 0.3:\n",
        "            index_col = \"name\"\n",
        "\n",
        "        if index_col not in headers:\n",
        "            headers = [index_col] + headers\n",
        "            val_add = 1\n",
        "            if index_col == \"name\":\n",
        "                val_add = \"value\"\n",
        "            rows = [[val_add] + row for row in rows]\n",
        "            types = [\"text\"] + types\n",
        "    \n",
        "    # add * for each table for join table prediction\n",
        "    headers = [\"*\"] + headers\n",
        "    rows = [[\"all\"] + row for row in rows]\n",
        "    types = [\"text\"] + types\n",
        "    \n",
        "    # reformat values\n",
        "    values = [[] for _ in range(len(headers))]\n",
        "    for row in rows:\n",
        "        for i, val in enumerate(row):\n",
        "            values[i].append(str(val).lower())\n",
        "    \n",
        "    table_name = table_name.lower()\n",
        "    headers[0] = table_name + \" \" + \"*\"\n",
        "    tabn_str = \"_\".join(table_name.split(\" \"))\n",
        "    headers_type = [tabn_str +\" \"+ hd + \" real\" if ty == \"real\" else tabn_str +\" \"+ hd for hd, ty in zip(headers, types)]\n",
        "#     print(len(headers), len(types), len(rows[0]))\n",
        "    assert len(headers) == len(types) == len(rows[0])\n",
        "#     print(table_name)\n",
        "    data = {'name': table_name,\n",
        "            'columns_original': headers,\n",
        "            'columns': headers_type,\n",
        "            'values': values,\n",
        "            'column_types': types}\n",
        "    tables_clean.append(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exPJozTWIoqF"
      },
      "source": [
        "def create_dbs(tables):\n",
        "    random.shuffle(tables)    \n",
        "    dbs = []\n",
        "    cur_cols = []\n",
        "    db_one = []\n",
        "    ahd_cols = []\n",
        "    for i, tab in enumerate(tables):\n",
        "        if len(db_one) <= random.choice([0,1]) and len(ahd_cols) < MAX_COL_NUM:\n",
        "            db_one.append(tab)\n",
        "            cur_cols.extend([col+\".\"+tab[\"name\"] for col in tab[\"columns\"]])\n",
        "            if i+1 < len(tables):\n",
        "                ahd_cols = cur_cols + [col+\".\"+tables[i+1][\"name\"] for col in tables[i+1][\"columns\"]]\n",
        "            else:\n",
        "                 break\n",
        "        else:\n",
        "            if len(cur_cols) == len(list(set(cur_cols))) and len(db_one) > 1:\n",
        "                dbs.append(db_one)\n",
        "            db_one = []\n",
        "            cur_cols = []\n",
        "            ahd_cols = []\n",
        "            \n",
        "    return dbs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VJ6BCNB9IoqG"
      },
      "source": [
        "wikisql_dbs = create_dbs(tables_clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "huqSggXpIoqG"
      },
      "source": [
        "# for db in wikisql_dbs:\n",
        "#     tab_names = []\n",
        "#     col_count = 0\n",
        "#     for tab in db:\n",
        "#         tab_names.append(tab[\"name\"])\n",
        "#         col_count += len(tab[\"columns\"])\n",
        "#     print(\"----------\")\n",
        "#     print(\"table names: \", tab_names)\n",
        "#     print(\"column num: \", col_count)\n",
        "#     print(\"table num: \", len(tab_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik35uCIiIoqG",
        "outputId": "f70a9b45-4a73-4370-fc37-937268233d49"
      },
      "source": [
        "len(wikisql_dbs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1197"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQrIqtakIoqG"
      },
      "source": [
        "def gen_dbs_spider(datapath, tablepath, db_list):\n",
        "    with open(datapath) as f:\n",
        "        db_data_raw = json.load(f)\n",
        "        db_data = {}\n",
        "        for dd in db_data_raw:\n",
        "            db_data[dd[\"db_id\"]] = {}\n",
        "            values = dd[\"data\"]\n",
        "            for tbn, vals in values.items():\n",
        "                db_data[dd[\"db_id\"]][tbn.lower()] = vals[:3]\n",
        "            \n",
        "    dbs = json.load(open(tablepath))\n",
        "    print(\"dbs num: \", len(dbs))\n",
        "    spider_dbs = {}\n",
        "    for db in dbs:\n",
        "        db_id = db['db_id']\n",
        "        if db_id not in db_list:\n",
        "            continue\n",
        "#         print(\"\\nprocessing db: \", db_id)\n",
        "        spider_dbs[db_id] = []\n",
        "        \n",
        "        # skip formula for now\n",
        "        if db_id == \"formula_1\":\n",
        "            continue\n",
        "            \n",
        "        if db_id in db_data.keys():\n",
        "            db_values = db_data[db_id]\n",
        "        else:\n",
        "            print(\"---------------------skipping db: \", db_id)\n",
        "            continue\n",
        "        #get table column names info\n",
        "        column_types = db['column_types']\n",
        "        table_names_original = [cn.lower() for cn in db['table_names_original']]\n",
        "        table_names = [cn.lower() for cn in db['table_names']]\n",
        "        column_names_original = [[i, x.lower()] for i, x in db['column_names_original']]\n",
        "        primary_keys = db[\"primary_keys\"]\n",
        "        foreign_keys = []\n",
        "        for ks in db[\"foreign_keys\"]:\n",
        "            if ks[0] not in primary_keys:\n",
        "                foreign_keys.append(ks[0])\n",
        "            if ks[1] not in primary_keys:\n",
        "                foreign_keys.append(ks[1])\n",
        "        column_names = []\n",
        "        for idx, ix in enumerate(db['column_names']):\n",
        "            i, x = ix[0], ix[1].lower()\n",
        "            if idx in primary_keys and \"id\" not in x:\n",
        "                x = x + \" id\"\n",
        "            elif idx in foreign_keys:\n",
        "                x = x + \" refer\"\n",
        "            column_names.append([i, x])\n",
        "        column_types = [\"text\" if i in primary_keys or i in foreign_keys else ct for i, ct in enumerate(column_types)]\n",
        "        info_ziped = list(zip(column_names, column_names_original, column_types))\n",
        "        \n",
        "        for i, tabn in enumerate(table_names):\n",
        "            table = {}\n",
        "            table[\"name\"] = tabn\n",
        "            table[\"columns_original\"] = []\n",
        "            table[\"columns\"] = []\n",
        "            table['column_types'] = []\n",
        "            tabng = table_names_original[i]\n",
        "            \n",
        "            for coln_, colng_, colty in info_ziped:\n",
        "                cid, coln = coln_\n",
        "                _, colng = colng_\n",
        "                if colty != \"text\":\n",
        "                    colty = \"real\"\n",
        "                if cid == i:\n",
        "                    table[\"columns_original\"].append(colng)\n",
        "                    table[\"columns\"].append(coln)\n",
        "                    table[\"column_types\"].append(colty)\n",
        "            \n",
        "            # add * for each table for join table prediction\n",
        "            table[\"columns_original\"] = [tabng + \" *\"] + table[\"columns_original\"]\n",
        "            table[\"columns\"] = [tabn + \" *\"] + table[\"columns\"]\n",
        "            table[\"column_types\"] = [\"text\"] + table[\"column_types\"]\n",
        "            \n",
        "            if tabng in db_values.keys():\n",
        "                rows = db_values[tabng]\n",
        "                try:\n",
        "                    col_values = [[] for _ in range(len(table[\"columns\"])-1)]\n",
        "                    for row in rows:\n",
        "                        for r, val in enumerate(row):\n",
        "                            col_values[r].append(str(val).lower())\n",
        "                    table[\"values\"] = [len(col_values[0]) * [\"all\"]] + col_values                    \n",
        "                except:\n",
        "                    print(\"--------skipping table: \", tabng)\n",
        "                    continue\n",
        "            else:\n",
        "                print(\"--------skipping table: \", tabng)\n",
        "                continue\n",
        "            \n",
        "            table[\"columns\"] = [hd + \" real\" if ty == \"real\" else hd for hd, ty in zip(table[\"columns\"], table[\"column_types\"])]\n",
        "            tabn_str = \"_\".join(tabn.split(\" \"))\n",
        "            table[\"columns\"] = [tabn_str + \" \" + hd for hd in table[\"columns\"]]\n",
        "            assert len(table[\"columns\"]) == len(table[\"columns_original\"]) == len(table[\"column_types\"]) == len(table[\"values\"])\n",
        "            spider_dbs[db_id].append(table)\n",
        "    \n",
        "    spider_dbs = [db for did, db in spider_dbs.items() if len(db) > 1]\n",
        "    \n",
        "    return spider_dbs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eTDpwnC6IoqH",
        "outputId": "f834acc6-e8a8-4971-ee69-720d0b21adb2"
      },
      "source": [
        "#read and reformat spider dbs\n",
        "datapath = \"/home/t-tyu/projects/NL2CodeOverData/data/spider/db_data.json\"\n",
        "tablepath = spider_data_file + \"/tables.json\"\n",
        "train_db_ids_file = '/home/t-tyu/projects/NL2CodeOverData/data/spider/train_db_ids.txt'\n",
        "dev_db_ids_file = '/home/t-tyu/projects/NL2CodeOverData/data/spider/dev_db_ids.txt'\n",
        "\n",
        "train_database = []\n",
        "with open(train_db_ids_file) as f:\n",
        "    for line in f:\n",
        "        train_database.append(line.strip())\n",
        "\n",
        "dev_database = []\n",
        "with open(dev_db_ids_file) as f:\n",
        "    for line in f:\n",
        "        dev_database.append(line.strip())\n",
        "        \n",
        "        \n",
        "spider_train_dbs = gen_dbs_spider(datapath, tablepath, train_database)\n",
        "spider_dev_dbs = gen_dbs_spider(datapath, tablepath, dev_database)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dbs num:  166\n",
            "---------------------skipping db:  body_builder\n",
            "---------------------skipping db:  decoration_competition\n",
            "---------------------skipping db:  phone_market\n",
            "---------------------skipping db:  company_employee\n",
            "---------------------skipping db:  manufactory_1\n",
            "---------------------skipping db:  debate\n",
            "---------------------skipping db:  ship_1\n",
            "---------------------skipping db:  entertainment_awards\n",
            "---------------------skipping db:  journal_committee\n",
            "---------------------skipping db:  station_weather\n",
            "--------skipping table:  appearances\n",
            "--------skipping table:  manager_award_vote\n",
            "--------skipping table:  player_award_vote\n",
            "--------skipping table:  batting\n",
            "--------skipping table:  batting_postseason\n",
            "--------skipping table:  fielding\n",
            "--------skipping table:  fielding_outfield\n",
            "--------skipping table:  fielding_postseason\n",
            "--------skipping table:  manager_half\n",
            "--------skipping table:  pitching\n",
            "--------skipping table:  pitching_postseason\n",
            "--------skipping table:  team_half\n",
            "---------------------skipping db:  architecture\n",
            "---------------------skipping db:  csu_1\n",
            "---------------------skipping db:  school_bus\n",
            "---------------------skipping db:  mountain_photos\n",
            "---------------------skipping db:  ship_mission\n",
            "---------------------skipping db:  performance_attendance\n",
            "---------------------skipping db:  soccer_1\n",
            "---------------------skipping db:  roller_coaster\n",
            "---------------------skipping db:  manufacturer\n",
            "---------------------skipping db:  election_representative\n",
            "---------------------skipping db:  wedding\n",
            "---------------------skipping db:  news_report\n",
            "---------------------skipping db:  phone_1\n",
            "--------skipping table:  staff\n",
            "--------skipping table:  customers\n",
            "--------skipping table:  products\n",
            "--------skipping table:  complaints\n",
            "---------------------skipping db:  department_management\n",
            "---------------------skipping db:  workshop_paper\n",
            "---------------------skipping db:  party_host\n",
            "dbs num:  166\n",
            "---------------------skipping db:  museum_visit\n",
            "---------------------skipping db:  singer\n",
            "---------------------skipping db:  poker_player\n",
            "---------------------skipping db:  course_teach\n",
            "--------skipping table:  car_names\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5VQqr_cIoqI",
        "outputId": "d9bb7f1d-076d-4dc8-93e8-5914255575e5"
      },
      "source": [
        "print(\"wikisql db num: {}\\nspider train db num: {}\\nspider dev db num: {}\".format(\n",
        "    len(wikisql_dbs),\n",
        "    len(spider_train_dbs),\n",
        "    len(spider_dev_dbs)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wikisql db num: 1197\n",
            "spider train db num: 112\n",
            "spider dev db num: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTvG4x4WIoqI"
      },
      "source": [
        "with open(\"data/qsep_label_map.json\", \"r\") as f:\n",
        "    qsep_label_map = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yM5jBPdIoqI"
      },
      "source": [
        "concat_label_map = defaultdict(list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMkOGtTjIoqI"
      },
      "source": [
        "STRUCT_KEYWORDS = [\"WHERE\", \"GROUP_BY\", \"HAVING\", \"ORDER_BY\", \"SELECT\"]\n",
        "EXTRA_OPS = [\"NOT_IN\", \"IN\", \"BETWEEN\", \"=\"]\n",
        "COUNT = \"COUNT\"\n",
        "OTHER_KEYWORDS = [\"LIMIT\"] #AGG, OP, DASC, OR, =\n",
        "NEST_KEYWORDS = [\"EXCEPT\", \"UNION\", \"INTERSECT\"]\n",
        "\n",
        "def get_labels(sql_pattern):\n",
        "    sql_tokens = sql_pattern.replace(\"GROUP BY\", \"GROUP_BY\").replace(\"ORDER BY\", \"ORDER_BY\").replace(\"NOT IN\", \"NOT_IN\").split(\" \")\n",
        "    columns = {}\n",
        "    cur_nest = \"\"\n",
        "    cur_struct = \"\"\n",
        "    cur_len = len(sql_tokens)\n",
        "    select_count = 0\n",
        "    skip = False\n",
        "    for i, tok in enumerate(sql_tokens):\n",
        "        if tok in NEST_KEYWORDS:\n",
        "            if cur_nest == \"\" or cur_nest == \"OP_SEL\":\n",
        "                cur_nest = tok\n",
        "            else:\n",
        "                cur_nest = cur_nest + \" \" + tok\n",
        "        elif tok in STRUCT_KEYWORDS:\n",
        "            cur_struct = tok\n",
        "            if tok == \"SELECT\":\n",
        "                select_count += 1\n",
        "                if select_count > 1 and cur_nest == \"\":\n",
        "                    cur_nest = \"OP_SEL\"\n",
        "        elif \"COLUMN\" in tok or \"*\" == tok:\n",
        "            if tok not in columns.keys():\n",
        "                columns[tok] = []\n",
        "            # SELECT {COLUMN0}\n",
        "            # SELECT {COLUMN0} , {COLUMN1}\n",
        "            # SELECT {AGG0} ( {COLUMN0} )\n",
        "            # SELECT {COLUMN0} {FROM} WHERE {COLUMN1} {OP} ( SELECT {AGG0} ( {COLUMN1} ) {FROM} ) AND {COLUMN2} {OP0} {VALUE0}\n",
        "            if cur_struct == \"SELECT\":\n",
        "                if \",\" == sql_tokens[i-1] or \"SELECT\" == sql_tokens[i-1]:\n",
        "                    columns[tok].append(cur_nest + \" \" + cur_struct)\n",
        "                elif \"(\" == sql_tokens[i-1]:\n",
        "                    columns[tok].append(cur_nest + \" \" + cur_struct + \" \" + sql_tokens[i-2])\n",
        "                else:\n",
        "                    print(\"\\nWarning: unexcepted SELECT format\")\n",
        "                    skip = True\n",
        "                    print(sql_pattern)\n",
        "            # WHERE {COLUMN} {OP}\n",
        "            # WHERE {COLUMN2} {OP0}\n",
        "            # WHERE OR {COLUMN2} {OP0}\n",
        "            # WHERE {COLUMN2} BETWEEN\n",
        "            elif cur_struct == \"WHERE\":\n",
        "                assert \"OP\" in sql_tokens[i+1] or sql_tokens[i+1] in EXTRA_OPS\n",
        "                last_tok = sql_tokens[i-1]\n",
        "                if \"OR\" == last_tok or (i+3 < cur_len and \"OR\" == sql_tokens[i+3]):\n",
        "                    columns[tok].append(cur_nest + \" \" + cur_struct + \" OR \" + sql_tokens[i+1])\n",
        "                elif \"WHERE\" == last_tok or \"AND\" == last_tok:\n",
        "                    columns[tok].append(cur_nest + \" \" + cur_struct + \" \" + sql_tokens[i+1])\n",
        "                else:\n",
        "                    print(\"\\nWarning: unexcepted WHERE format\")\n",
        "                    skip = True\n",
        "            # GROUP BY {COLUMN0} , {COLUMN0}\n",
        "            elif cur_struct == \"GROUP_BY\":\n",
        "                columns[tok].append(cur_nest + \" \" + cur_struct)\n",
        "            # HAVING COUNT ( * ) {OP0}\n",
        "            # HAVING {AGG0} ( {COLUMN2} ) {OP0}\n",
        "            elif cur_struct == \"HAVING\":\n",
        "                last_tok = sql_tokens[i-1]\n",
        "                if last_tok != \"(\" and not (\"AGG\" in sql_tokens[i-2] or COUNT == sql_tokens[i-2]):\n",
        "                    print(\"\\nWarning: unexcepted HAVING format\")\n",
        "                    skip = True\n",
        "                columns[tok].append(cur_nest + \" \" + cur_struct + \" \" + sql_tokens[i-2] + \" \" + sql_tokens[i+2])\n",
        "            # ORDER BY COUNT ( * ) {DASC} LIMIT\n",
        "            # ORDER BY COUNT ( * ) {DASC}\n",
        "            # ORDER BY {COLUMN1} {DASC} LIMIT\n",
        "            # ORDER BY {COLUMN1} LIMIT\n",
        "            # ORDER BY {COLUMN1} , {COLUMN1} {DASC} LIMIT\n",
        "            # ORDER BY {COLUMN1} {DASC} if no DASC then is ASC\n",
        "            elif cur_struct == \"ORDER_BY\":\n",
        "                last_tok = sql_tokens[i-1]\n",
        "                if last_tok == \"(\":\n",
        "                    dasc_tok = \"{DASC}\"\n",
        "                    limit_tok = \"\"\n",
        "                    if sql_tokens[i+2] != \"{DASC}\":\n",
        "                        dasc_tok = \"ASC\"\n",
        "                        if sql_tokens[i+2] == \"LIMIT\":\n",
        "                            limit_tok = \"LIMIT\"\n",
        "                    elif i+3 < cur_len and sql_tokens[i+3] == \"LIMIT\":\n",
        "                        limit_tok = \"LIMIT\"\n",
        "                        \n",
        "                    columns[tok].append(cur_nest + \" \" + cur_struct + \" \" + sql_tokens[i-2] + \" \" + dasc_tok + \" \" + limit_tok)\n",
        "                elif last_tok == \"ORDER_BY\" or last_tok == \",\":\n",
        "                    dasc_tok = \"ASC\"\n",
        "                    limit_tok = \"\"\n",
        "                    # small dirty pass\n",
        "                    if i+1 < cur_len and sql_tokens[i+1] == \"{DASC}\":\n",
        "                        dasc_tok = \"{DASC}\"\n",
        "                        if i+2 < cur_len and sql_tokens[i+2] == \"LIMIT\":\n",
        "                            limit_tok = \"LIMIT\"\n",
        "                    elif i+1 < cur_len and sql_tokens[i+1] == \"LIMIT\":\n",
        "                        limit_tok = \"LIMIT\"\n",
        "                    \n",
        "                    columns[tok].append(cur_nest + \" \" + cur_struct + \" \" + dasc_tok + \" \" + limit_tok)\n",
        "        \n",
        "            else:\n",
        "                print(\"\\n------------Warning: unexcepted COLUMN label format\")\n",
        "                skip = True\n",
        "    \n",
        "    column_labels = {}\n",
        "    for col, labels in columns.items():\n",
        "        label_str = \" \".join([l.strip() for l in labels])\n",
        "        column_labels[col] = label_str\n",
        "        \n",
        "    return column_labels, skip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4xGSNwaIoqJ"
      },
      "source": [
        "def get_sql_slots(sql_pattern):\n",
        "    sql_tokens = sql_pattern.split(\" \")\n",
        "    columns = {}\n",
        "    ops = {}\n",
        "    values = {}\n",
        "    aggs = {}\n",
        "    dasc = False\n",
        "    slots = []\n",
        "    val_pros = []\n",
        "    for i, tok in enumerate(sql_tokens):\n",
        "        if \"{\" in tok and \"}\" in tok and \"FROM\" not in tok:\n",
        "            if tok not in slots:\n",
        "                slots.append(tok)\n",
        "                \n",
        "        if \"AGG\" in tok:\n",
        "            if i + 2 < len(sql_tokens) and \"(\" == sql_tokens[i+1]:\n",
        "                if \"COLUMN\" in sql_tokens[i+2]:\n",
        "                    if sql_tokens[i+2] not in columns.keys():\n",
        "                        columns[sql_tokens[i+2]] = [\"number\"]\n",
        "                    else:\n",
        "                        columns[sql_tokens[i+2]].append(\"number\")\n",
        "                    aggs[tok] = sql_tokens[i+2]\n",
        "                else:\n",
        "                    print(\"\\nTemplate Error: AGG format is wrong!!!\")\n",
        "                    print(sql_pattern)\n",
        "        elif \"COLUMN\" in tok:\n",
        "            if tok not in columns.keys():\n",
        "                columns[tok] = []\n",
        "        elif \"OP\" in tok:\n",
        "            if i - 1 >= 0 and \"COLUMN\" in sql_tokens[i-1]:\n",
        "                ops[tok] = [sql_tokens[i-1]]\n",
        "                if i + 1 < len(sql_tokens) and \"VALUE\" in sql_tokens[i+1]:\n",
        "                    ops[tok].append(sql_tokens[i+1])\n",
        "                    val_pros.append(sql_tokens[i+1])\n",
        "            elif i - 2 >= 0 and \")\" == sql_tokens[i-1] and (\"COLUMN\" in sql_tokens[i-2] or \"*\" == sql_tokens[i-2]):\n",
        "                ops[tok] = [sql_tokens[i-2]]\n",
        "                if i + 1 < len(sql_tokens) and \"VALUE\" in sql_tokens[i+1]:\n",
        "                    ops[tok].append(sql_tokens[i+1])\n",
        "                    val_pros.append(sql_tokens[i+1])\n",
        "            else:\n",
        "                print(\"\\nTemplate Error: OP format is wrong!!!\")\n",
        "                print(sql_pattern)\n",
        "        elif \"VALUE\" in tok and tok not in val_pros:\n",
        "            \"\"\"\n",
        "            OP} {VALUE0}\n",
        "            LIMIT {VALUE0}\n",
        "            {COLUMN1} BETWEEN {VALUE0} AND {VALUE1}\n",
        "            HAVING COUNT ( * ) {OP1} {VALUE1}\n",
        "            = {VALUE1}\n",
        "            \"\"\"\n",
        "            if i - 2 >= 0 and (\"BETWEEN\" == sql_tokens[i-1] or \"AND\" == sql_tokens[i-1]):\n",
        "                values[tok] = \"number\"\n",
        "                if \"BETWEEN\" == sql_tokens[i-1]:\n",
        "                    columns[sql_tokens[i-2]].append(\"number\")\n",
        "            elif i - 1 >= 0 and \"LIMIT\" == sql_tokens[i-1]:\n",
        "                values[tok] = \"integer\"\n",
        "            elif i - 1 >= 0 and \"=\" == sql_tokens[i-1]:\n",
        "                assert \"COLUMN\" in sql_tokens[i-2]\n",
        "                columns[sql_tokens[i-2]].append(tok)\n",
        "            else:\n",
        "                print(\"\\nTemplate Error: VALUE format is wrong!!!\")\n",
        "                print(sql_pattern)\n",
        "        elif \"DASC\" in tok:\n",
        "            dasc = True\n",
        "    \n",
        "    return (list(set(slots)), columns, ops, values, aggs, dasc)\n",
        "\n",
        "\n",
        "def get_q_slots(question):\n",
        "    q_toks = [x.replace(\"?\", \"\").replace(\"!\", \"\").replace(\".\", \"\") for x in question.strip().split(\" \")]\n",
        "    q_slots = list(set([tok for tok in q_toks if \"TABLE\" in tok or \"SC\" in tok or (\"{\" in tok and \"}\" in tok)]))\n",
        "    \n",
        "    return q_slots\n",
        "\n",
        "\n",
        "def process_constraints(constraints, columns, slots):\n",
        "    slot_values = {}\n",
        "    for constraint in constraints:\n",
        "        if \"P0==\" == constraint:\n",
        "            assert \"{OP0}\" in slots\n",
        "            slot_values[\"{OP0}\"] = \"=\"\n",
        "        elif \"P1==\" == constraint:\n",
        "            assert \"{OP1}\" in slots\n",
        "            slot_values[\"{OP1}\"] = \"=\"\n",
        "        elif \"P0=P1==\" == constraint:\n",
        "            assert \"{OP0}\" in slots and \"{OP1}\" in slots\n",
        "            slot_values[\"{OP0}\"] = \"=\"\n",
        "            slot_values[\"{OP1}\"] = \"=\"\n",
        "        elif \"P0=P1=P2==\" == constraint:\n",
        "            assert \"{OP0}\" in slots and \"{OP1}\" in slots and \"{OP2}\" in slots\n",
        "            slot_values[\"{OP0}\"] = \"=\"\n",
        "            slot_values[\"{OP1}\"] = \"=\"\n",
        "            slot_values[\"{OP2}\"] = \"=\"\n",
        "        elif \"P0=>\" == constraint:\n",
        "            assert \"{OP0}\" in slots\n",
        "            slot_values[\"{OP0}\"] = \">\"\n",
        "        elif \"P0=<\" == constraint:\n",
        "            assert \"{OP0}\" in slots\n",
        "            slot_values[\"{OP0}\"] = \"<\"\n",
        "        elif \"{AGG0}=MIN\" == constraint:\n",
        "            assert \"{AGG0}\" in slots\n",
        "            slot_values[\"{AGG0}\"] = \"MIN\"\n",
        "        elif \"{AGG0}=MAX\" == constraint:\n",
        "            assert \"{AGG0}\" in slots\n",
        "            slot_values[\"{AGG0}\"] = \"MAX\"\n",
        "        elif \"C0-id\" == constraint:\n",
        "            assert \"{COLUMN0}\" in slots and \"{COLUMN0}\" in columns.keys()\n",
        "            columns[\"{COLUMN0}\"].append(\"id\")\n",
        "        elif \"C1-id\" == constraint:\n",
        "            assert \"{COLUMN1}\" in slots and \"{COLUMN1}\" in columns.keys()\n",
        "            columns[\"{COLUMN1}\"].append(\"id\")\n",
        "        elif \"C2-id\" == constraint:\n",
        "            assert \"{COLUMN2}\" in slots and \"{COLUMN2}\" in columns.keys()\n",
        "            columns[\"{COLUMN2}\"].append(\"id\")\n",
        "        elif \"C3-T1\" == constraint:\n",
        "            assert \"{COLUMN3}\" in slots and \"{COLUMN3}\" in columns.keys()\n",
        "            columns[\"{COLUMN3}\"].append(\"T1\")\n",
        "        elif \"T0-T1-JOIN\" == constraint or 'T0-T1-NO-JOIN' == constraint:\n",
        "            columns[\"{COLUMN0}\"].append(\"T0\")\n",
        "            if \"{COLUMN1}\" in columns.keys():\n",
        "                columns[\"{COLUMN1}\"].append(\"T1\")\n",
        "    \n",
        "    return (slot_values, columns)\n",
        "\n",
        "\n",
        "# helper function\n",
        "def gen_col_info(col_str, columns, columns_inf):\n",
        "    col_conds = columns[col_str]\n",
        "    value_slot = [cc for cc in col_conds if \"VALUE\" in cc]\n",
        "    col = \"\"\n",
        "    value_val = None\n",
        "    if \"id\" in col_conds:\n",
        "        has_id = False\n",
        "        for c, t, v in columns_inf:\n",
        "            if \"id\" in col or \"name\" in col:\n",
        "                has_id = True\n",
        "                col, ctype, values = c, t, v\n",
        "                break\n",
        "        if not has_id:\n",
        "            col, ctype, values = columns_inf[0]\n",
        "    elif \"number\" in col_conds:\n",
        "        for colinfo in columns_inf[1:]:\n",
        "            if colinfo[1] == \"real\":\n",
        "                col, ctype, values = colinfo\n",
        "    if col == \"\":\n",
        "        col, ctype, values = random.choice(columns_inf[1:])\n",
        "\n",
        "    if len(value_slot) > 0:\n",
        "        assert len(value_slot) < 3\n",
        "        if len(values) == 0:\n",
        "            values = [\"value\"]\n",
        "            print(\"\\nWarning: column values are empty!\")\n",
        "        if len(value_slot) == 1:\n",
        "            value_val = [(value_slot[0], random.choice(values))]\n",
        "        else:\n",
        "            if len(values) > 2:\n",
        "                value_val = [(value_slot[0], values[0]), (value_slot[1], values[1])]\n",
        "            else:\n",
        "                value_val = [(value_slot[0], values[0]), (value_slot[1], \"another value\")]\n",
        "        \n",
        "    return (col, value_val)\n",
        "\n",
        "\n",
        "def replace_dict(inp, dicts):\n",
        "    for rep_in, rep_out in dicts.items():\n",
        "        inp = inp.replace(rep_in, str(rep_out))\n",
        "    \n",
        "    return inp\n",
        "\n",
        "\n",
        "def populate_one(db, question, sql_pattern, constraints):\n",
        "    \"\"\"\n",
        "    'P0=P1==', 'P0=P1=P2==', 'P0==', 'P1==', 'P0=>', 'P0=<', '{AGG0}=MAX', '{AGG0}=MIN'\n",
        "    'T0-T1-JOIN', 'T0-T1-NO-JOIN', \n",
        "    'C0-id',, 'C2-id', , 'C1-id',  'C3-T1'\n",
        "    \"\"\"\n",
        "    slots, columns, ops, vals, aggs, dasc = get_sql_slots(sql_pattern)\n",
        "    slot_values, columns = process_constraints(constraints, columns, slots)\n",
        "    \n",
        "    q_slots = get_q_slots(question)\n",
        "    q_slot_values = {}\n",
        "\n",
        "    # 1 process ops - update columns and values constraints\n",
        "    for op, colv in ops.items():\n",
        "        if colv[0] == \"*\":\n",
        "            if op not in slot_values.keys():\n",
        "                op_val = random.choice([\">\", \"<\", \">=\", \"<=\", \"=\"])\n",
        "                slot_values[op] = op_val\n",
        "                if len(colv) == 2:\n",
        "                    slot_values[colv[1]] = random.randint(1, 10)\n",
        "        else:\n",
        "            if colv[0] not in columns.keys():\n",
        "                print(\"\\n-----colv[0] not in columns.keys(): \")\n",
        "                print(columns.keys())\n",
        "                print(ops)\n",
        "            assert colv[0] in columns.keys()\n",
        "            if op not in slot_values.keys():\n",
        "                if random.random() < 0.4:\n",
        "                    op_val = \"=\"\n",
        "                else:\n",
        "                    op_val = random.choice(OPS)\n",
        "                slot_values[op] = op_val\n",
        "                if op_val in [\">\", \"<\", \">=\", \"<=\"]:\n",
        "                    columns[colv[0]].append(\"number\")\n",
        "            if len(colv) == 2:\n",
        "                columns[colv[0]].append(colv[1])\n",
        "    \n",
        "    # 2 process columns\n",
        "    random.shuffle(db)\n",
        "    table_0, table_1 = None, None\n",
        "    table_label_0 = \"\"\n",
        "    table_label_1 = \"\"\n",
        "    use_table_1 = False\n",
        "    \n",
        "    if \"{COLUMN0}\" in columns.keys() or \"{TABLE0}\" in q_slots:\n",
        "        table_label_0 = \"SELECT\"\n",
        "        \n",
        "    if len(db) >= 2:\n",
        "        table_0, table_1 = db[:2]\n",
        "        if \"{TABLE1}\" in q_slots:\n",
        "            table_label_1 = \"SELECT\"\n",
        "            if \"{TABLE0}\" in q_slots:\n",
        "                # p<0.5 from T0, T1 AND to SELECT T1 *\n",
        "                # otherwise all from T0 AND to SELECT T1 *\n",
        "                if random.random() < 0.5:\n",
        "                    use_table_1 = True\n",
        "            else:\n",
        "                # p<0.7 all from T0 \n",
        "                # AND to SELECT T1 *\n",
        "                if random.random() < 0.7:\n",
        "                    use_table_1 = True\n",
        "                    if \"{COLUMN1}\" in columns.keys():\n",
        "                        table_label_1 = \"SELECT\"\n",
        "        else:\n",
        "            # p<0.5 from T0, T1 AND to SELECT T1 *\n",
        "            # otherwise all from T0, NOT to SELECT T1 *\n",
        "            if random.random() < 0.5:\n",
        "                use_table_1 = True\n",
        "                if \"{COLUMN1}\" in columns.keys():\n",
        "                    table_label_1 = \"SELECT\"\n",
        "    else:\n",
        "        print(\"\\nWarning: db has only one table!\")\n",
        "        assert len(db) > 1\n",
        "        table_0, table_1 = db[0], db[0]\n",
        "    \n",
        "    T0 = table_0[\"name\"]\n",
        "    T1 = table_1[\"name\"]\n",
        "    columns_inf_0 = list(zip(table_0[\"columns\"], table_0[\"column_types\"], table_0[\"values\"]))[1:]\n",
        "    if use_table_1:\n",
        "        columns_inf_1 = list(zip(table_1[\"columns\"], table_1[\"column_types\"], table_1[\"values\"]))[1:]\n",
        "        \n",
        "    if \"{COLUMN0}\" in columns.keys():\n",
        "        col_0, value_0 = gen_col_info(\"{COLUMN0}\", columns, columns_inf_0)\n",
        "        slot_values[\"{COLUMN0}\"] = col_0\n",
        "        if value_0 is not None:\n",
        "            for k, v in value_0:\n",
        "                slot_values[k] = v\n",
        "\n",
        "    if use_table_1:\n",
        "        columns_input = columns_inf_1\n",
        "        columns_all = columns_inf_0 + columns_inf_1\n",
        "    else:\n",
        "        columns_input = columns_inf_0\n",
        "        columns_all = columns_inf_0\n",
        "        \n",
        "    if \"{COLUMN1}\" in columns.keys():\n",
        "        col_1, value_1 = gen_col_info(\"{COLUMN1}\", columns, columns_input)\n",
        "        slot_values[\"{COLUMN1}\"] = col_1\n",
        "        if value_1 is not None:\n",
        "            for k, v in value_1:\n",
        "                slot_values[k] = v\n",
        "    \n",
        "    if \"{COLUMN2}\" in columns.keys():\n",
        "        col_2, value_2 = gen_col_info(\"{COLUMN2}\", columns, columns_input)\n",
        "        slot_values[\"{COLUMN2}\"] = col_2\n",
        "        if value_2 is not None:\n",
        "            for k, v in value_2:\n",
        "                slot_values[k] = v\n",
        "            \n",
        "    if \"{COLUMN3}\" in columns.keys():\n",
        "        col_3, value_3 = gen_col_info(\"{COLUMN3}\", columns, columns_input)\n",
        "        slot_values[\"{COLUMN3}\"] = col_3\n",
        "        if value_3 is not None:\n",
        "            for k, v in value_3:\n",
        "                slot_values[k] = v\n",
        "        \n",
        "    # 3 aggs\n",
        "    for agg in aggs.keys():\n",
        "        if agg not in slot_values.keys():\n",
        "            slot_values[agg] = random.choice([\"MAX\", \"MIN\", \"SUM\", \"AVG\"])\n",
        "    # 4 values\n",
        "    NUM = 1\n",
        "    for val, cond in vals.items():\n",
        "        assert val not in slot_values.keys()\n",
        "        if cond == \"integer\":\n",
        "            if random.random() < 0.5:\n",
        "                slot_values[val] = 1\n",
        "            else:\n",
        "                NUM = random.randint(2, 10)\n",
        "                slot_values[val] = NUM\n",
        "        else:\n",
        "            slot_values[val] = random.randint(0, 100)\n",
        "                    \n",
        "    # 5 dasc - true\n",
        "    if dasc == True:\n",
        "        slot_values[\"{DASC}\"] = random.choice([\"ASC\", \"DESC\"])\n",
        "    \n",
        "    # 6 check if all sql slot values are done\n",
        "    if len(slots) != len(slot_values):\n",
        "        print(\"\\nlen(slots) != len(slot_values)\")\n",
        "        print(\"sql_pattern: \", sql_pattern)\n",
        "        print(\"slots: \", slots)\n",
        "        print(\"slot_values: \", slot_values.keys())\n",
        "    assert len(slots) == len(slot_values)\n",
        "    \n",
        "    # 7 for the questions slots:\n",
        "    for qs in q_slots:\n",
        "        if qs == \"{TABLE0}\":\n",
        "            q_slot_values[\"{TABLE0}\"] = T0\n",
        "        elif qs == \"{TABLE1}\":\n",
        "            q_slot_values[\"{TABLE1}\"] = T1\n",
        "        elif \"SC\" in qs:\n",
        "            sc = slot_values[\"{DASC}\"]\n",
        "            if \"SC\" == qs:\n",
        "                q_slot_values[qs] = random.choice(sql_components[\"SC\"][sc])\n",
        "            elif \"SC_COL_LIMIT\" == qs:\n",
        "                if NUM > 1:\n",
        "                    sc =  sc + \"_NUM\"\n",
        "                    q_slot_values[qs] = random.choice(sql_components[\"SC_COL_LIMIT\"][sc]).replace(\"[NUM]\", str(NUM))\n",
        "                else:\n",
        "                    q_slot_values[qs] = random.choice(sql_components[\"SC_COL_LIMIT\"][sc])\n",
        "            elif \"SC_COL_COUNT_LIMIT\" in qs:\n",
        "                sc_type = qs.replace(\"SC_COL_COUNT_LIMIT\", \"\")\n",
        "                if NUM > 1:\n",
        "                    sc =  sc + \"_NUM\" + sc_type\n",
        "                    q_slot_values[qs] = random.choice(sql_components[\"SC_COL_COUNT_LIMIT\"][sc]).replace(\"[NUM]\", str(NUM))\n",
        "                else:\n",
        "                    sc =  sc + sc_type\n",
        "                    q_slot_values[qs] = random.choice(sql_components[\"SC_COL_COUNT_LIMIT\"][sc])\n",
        "            else:\n",
        "                if \"-\" not in qs:\n",
        "                    print(\"qs wrong\", qs)\n",
        "                assert \"-\" in qs\n",
        "                if \"C1\" in qs:\n",
        "                    sc_col = slot_values[\"{COLUMN1}\"]\n",
        "                elif \"C2\" in qs:\n",
        "                    sc_col = slot_values[\"{COLUMN2}\"]\n",
        "                q_slot_values[qs] = random.choice(sql_components[\"SC_COL\"][sc]).replace(\"[COL]\", sc_col)\n",
        "        else:\n",
        "            if qs not in slot_values.keys():\n",
        "                print(\"qs not in sv: \", qs)\n",
        "                print(\"sql_pattern: \", sql_pattern)\n",
        "                print(\"slot_values: \", slot_values)\n",
        "            assert qs in slot_values.keys()\n",
        "            if \"OP\" in qs:\n",
        "                q_slot_values[qs] = random.choice(sql_components[\"OP\"][slot_values[qs]])\n",
        "            elif \"AGG\" in qs:\n",
        "                q_slot_values[qs] = random.choice(sql_components[\"AGG\"][slot_values[qs]])\n",
        "            elif \"COLUMN\" in qs:\n",
        "                q_slot_values[qs] = \" \".join(slot_values[qs].split(\" \")[1:6])\n",
        "            elif \"VALUE\" in qs:\n",
        "                q_slot_values[qs] = \" \".join(str(slot_values[qs]).split(\" \")[:5])\n",
        "            else:\n",
        "                print(\"\\nWarning: some q slot type not considered!\")\n",
        "                print(qs)\n",
        "    \n",
        "    # 8 check if all question slots are processed\n",
        "    assert len(q_slots) == len(q_slot_values)\n",
        "    \n",
        "    # 9 generate final SQL-question pair\n",
        "    question_gen = replace_dict(question, q_slot_values)\n",
        "    \n",
        "    \n",
        "    # 10 generate column labels\n",
        "    slot_values_new = {}\n",
        "    for sl, vl in slot_values.items():\n",
        "        if \"COLUMN\" in sl:\n",
        "            slot_values_new[sl] = \"_=_\".join(vl.split(\" \"))\n",
        "        else:\n",
        "            slot_values_new[sl] = vl\n",
        "            \n",
        "    column_labels, skip = get_labels(sql_pattern)\n",
        "    column_lables_real = {}\n",
        "    for col, label in column_labels.items():\n",
        "        if col != \"*\":\n",
        "            col = slot_values[col]\n",
        "        for slot, value in slot_values.items():\n",
        "            label = label.replace(slot, str(value))\n",
        "        column_lables_real[col] = label\n",
        "    \n",
        "    # also add labels for table column * \n",
        "    if table_label_0 != \"\":\n",
        "        column_lables_real[table_0[\"columns\"][0]] = table_label_0\n",
        "    if table_label_1 != \"\":\n",
        "        column_lables_real[table_1[\"columns\"][0]] = table_label_1\n",
        "\n",
        "    sql_gen = replace_dict(sql_pattern.replace(\" {FROM}\", \"\"), slot_values_new)\n",
        "    \n",
        "    return (sql_gen, question_gen, column_lables_real, q_slot_values, slot_values, sql_pattern, columns_all)\n",
        "\n",
        "# let's start data augmentation!\n",
        "def augment_db(db, templates, sql_components, aug_limit):\n",
        "    count = 0\n",
        "    augment_pairs = []\n",
        "    while count < aug_limit:\n",
        "        template = random.choice(templates)\n",
        "        sql_constraints = template['SQL constraints']\n",
        "        sql_pattern = template[\"SQL pattern\"]\n",
        "        question, q_constraints = random.choice(template[\"questions\"])\n",
        "        constraints = list(set(sql_constraints + q_constraints))\n",
        "        qsep_label = qsep_label_map[sql_pattern]\n",
        "        sql_gen, question_gen, column_lables, q_slot_values, slot_values, template, columns_all = populate_one(db, question, sql_pattern, constraints)\n",
        "        augment_pairs.append((question_gen, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all, [qsep_label]))\n",
        "        count += 1\n",
        "    \n",
        "    return augment_pairs\n",
        "    \n",
        "\n",
        "def augment_all_dbs(dbs, templates, sql_components, aug_limit):\n",
        "    augment_data = {}\n",
        "    schema_dbs = {}\n",
        "    for db in dbs:\n",
        "        db_cols = [\"*\"]\n",
        "        db_values = [\"\"]\n",
        "        for tab in db:\n",
        "            db_cols.extend(tab[\"columns\"])\n",
        "            db_values.extend([k[0] if len(k) > 0 else \"\" for k in tab[\"values\"]])\n",
        "        schema_str = \" </s> \".join(db_cols)\n",
        "        values_str = \" </s> \".join([str(k) for k in db_values])\n",
        "        schema_str = schema_str + \" |-| \" + values_str\n",
        "        augment_pairs = augment_db(db, templates, sql_components, aug_limit)\n",
        "        augment_data[schema_str] = augment_pairs\n",
        "        schema_dbs[schema_str] = db\n",
        "    \n",
        "    return augment_data, schema_dbs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqKnRZNCIoqK"
      },
      "source": [
        "def count_aug(augment_data):\n",
        "    count = 0\n",
        "    for k, ll in augment_data.items():\n",
        "        count += len(ll)\n",
        "    print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4o-obgvIoqK"
      },
      "source": [
        "augment_data_wikisql, schema_dbs_wikisql = augment_all_dbs(wikisql_dbs, templates, sql_components, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1rclHJsIoqK",
        "outputId": "bc2e4eca-77c7-4878-d730-0a57414816a1"
      },
      "source": [
        "count_aug(augment_data_wikisql)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LRlrauNAIoqK",
        "outputId": "551f9992-7c4a-4b43-8d39-b015987d66dd"
      },
      "source": [
        "augment_data_spider_train, schema_dbs_spider_train = augment_all_dbs(spider_train_dbs, templates, sql_components, 150)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Warning: column values are empty!\n",
            "\n",
            "Warning: column values are empty!\n",
            "\n",
            "Warning: column values are empty!\n",
            "\n",
            "Warning: column values are empty!\n",
            "\n",
            "Warning: column values are empty!\n",
            "\n",
            "Warning: column values are empty!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB6o1B1iIoqK",
        "outputId": "57fb2564-d817-45a0-8623-ed07f6b151f5"
      },
      "source": [
        "count_aug(augment_data_spider_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMwh1kYIIoqL"
      },
      "source": [
        "augment_data_spider_dev, schema_dbs_spider_dev = augment_all_dbs(spider_dev_dbs, templates, sql_components, 150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qzKxadQIoqL",
        "outputId": "1cdf9be9-77eb-4e07-a3e3-7607e91dd78c"
      },
      "source": [
        "count_aug(augment_data_spider_dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAgmCQJ1IoqL"
      },
      "source": [
        "schema_dbs_all = {**schema_dbs_wikisql, **schema_dbs_spider_train, **schema_dbs_spider_dev}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APAQo0y4IoqL"
      },
      "source": [
        "# augment_data_with_dev_wikisql = {**augment_data_spider_dev, **augment_data_spider_train, **augment_data_wikisql}\n",
        "augment_data_no_dev_wikisql = {**augment_data_spider_train, **augment_data_wikisql}\n",
        "# augment_data_with_dev_no_wikisql = {**augment_data_spider_dev, **augment_data_spider_train}\n",
        "# augment_data_no_dev_no_wikisql = augment_data_spider_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfHPuoTeIoqL",
        "outputId": "5b12b5f6-064d-4f64-ad76-7a7095ba47cc"
      },
      "source": [
        "count_aug(augment_data_no_dev_wikisql)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "illp4uCOIoqL"
      },
      "source": [
        "### start to generate multi-turn examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUE7iw7dIoqM"
      },
      "source": [
        "# read context template file\n",
        "context_templates_file = \"data/context_templates.json\"\n",
        "with open(context_templates_file) as json_file:\n",
        "    context_templates = json.load(json_file)\n",
        "    \n",
        "SQL_OPS = ('INTERSECT', 'UNION', 'EXCEPT')\n",
        "AGG_OPS = [\"MAX\", \"MIN\", \"SUM\", \"AVG\"]\n",
        "OPS = [\">\", \"<\", \">=\", \"<=\", \"=\", \"!=\"]\n",
        "SQLPARSE_MAP = {\"\\n      \": \" \", \"\\n     \": \" \", \"\\n    \": \" \", \"\\n   \": \" \", \"\\n  \": \" \", \"\\n \": \" \", \"\\nhaving\": \" having\", \"\\nlimit\": \" limit\"}\n",
        "import sqlparse\n",
        "prev_token = \" <unk> \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tooDekxHIoqM"
      },
      "source": [
        "def col_select(col_conds, columns_inf):\n",
        "    value_slot = [cc for cc in col_conds if \"VALUE\" in cc]\n",
        "    col = \"\"\n",
        "    value_val = None\n",
        "    if \"id\" in col_conds:\n",
        "        has_id = False\n",
        "        for c, t, v in columns_inf:\n",
        "            if \"id\" in col or \"name\" in col:\n",
        "                has_id = True\n",
        "                col, ctype, values = c, t, v\n",
        "                break\n",
        "        if not has_id:\n",
        "            col, ctype, value = columns_inf[0]\n",
        "    elif \"number\" in col_conds:\n",
        "        for colinfo in columns_inf:\n",
        "            if colinfo[1] == \"real\":\n",
        "                col, ctype, value = colinfo\n",
        "    if len(columns_inf) == 0:\n",
        "        print(\"\\n---------------------------------------- columns_inf: \", columns_inf)\n",
        "    if col == \"\":\n",
        "        col, ctype, value = random.choice(columns_inf)\n",
        "\n",
        "    if len(value_slot) > 0:\n",
        "        assert len(value_slot) < 3\n",
        "        if len(value_slot) == 1:\n",
        "            value_val = [(value_slot[0], value)]\n",
        "        else:\n",
        "            value_val = [(value_slot[0], value), (value_slot[1], value)]\n",
        "    \n",
        "    return (col, value_val)\n",
        "\n",
        "\n",
        "def replace_words(s, words):\n",
        "    for k, v in words.items():\n",
        "        s = s.replace(k, v)\n",
        "    return s\n",
        "\n",
        "\n",
        "def edit_sql(sql_pattern, context_label, slot_values_prev, columns_all_prev, context_template):\n",
        "    sql = sql_pattern.lower().replace(\"{from}\", \"\", 1).strip()\n",
        "    sql_clauses = {\"select\": \"\", \"where\": \"\", \"group_by\": \"\", \"order_by\": \"\"}\n",
        "    sql = sqlparse.format(sql, reindent=True)\n",
        "    parsed = [x for x in replace_words(sql, SQLPARSE_MAP).split(\"\\n\")]\n",
        "    slot_values = slot_values_prev.copy()\n",
        "    for p in parsed:\n",
        "        p_toks = p.split(\" \")\n",
        "        if p_toks[0] == \"select\":\n",
        "            sql_clauses[\"select\"] = p\n",
        "        elif p_toks[0] == \"where\":\n",
        "            sql_clauses[\"where\"] = p\n",
        "        elif p_toks[0] == \"group\":\n",
        "            sql_clauses[\"group_by\"] = p\n",
        "        elif p_toks[0] == \"order\":\n",
        "            sql_clauses[\"order_by\"] = p\n",
        "        else:\n",
        "            raise Exception(\"unexcepted sql clause: \", p)\n",
        "            \n",
        "    context_question, context_constraints = random.choice(context_template[\"questions\"])\n",
        "    context_q_slots = get_q_slots(context_question)\n",
        "    context_q_slots = [x.replace(\"1\", \"10\").replace(\"2\", \"20\").replace(\"3\", \"30\") for x in context_q_slots]\n",
        "            \n",
        "    q_slot_values = {}\n",
        "    sql_pattern_new = \"\"\n",
        "    context_q = \"\"\n",
        "    satisfy = True\n",
        "    \n",
        "    if context_label == \"select replace column\":\n",
        "        if sql_clauses[\"group_by\"] != \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            sql_clauses[\"select\"] = \"select \" + \" , \".join(context_q_slots)\n",
        "            col_num = len(context_q_slots)\n",
        "            for i, qs in enumerate(context_q_slots):\n",
        "                col, _ = col_select([], columns_all_prev)\n",
        "    #             if col_num - i <= len(columns_all_prev) and len(columns_all_prev) > 1:\n",
        "    #                 columns_all_prev = [x for x in columns_all_prev if x[0] != col]\n",
        "                q_slot_values[qs] = \" \".join(col.split(\" \")[:5])\n",
        "                slot_values[qs] = col\n",
        "    elif context_label == \"select insert column\":\n",
        "        sql_clauses[\"select\"] = sql_clauses[\"select\"] + \" , \" + \" , \".join(context_q_slots)\n",
        "        col_num = len(context_q_slots)\n",
        "        for i, qs in enumerate(context_q_slots):\n",
        "            col, _ = col_select([], columns_all_prev)\n",
        "#             if col_num - i <= len(columns_all_prev) and len(columns_all_prev) > 1:\n",
        "#                 columns_all_prev = [x for x in columns_all_prev if x[0] != col]\n",
        "            q_slot_values[qs] = \" \".join(col.split(\" \")[:5])\n",
        "            slot_values[qs] = col\n",
        "    elif context_label == \"select replace agg\":\n",
        "        if 'agg' not in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"agg\") > 1:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            assert sql_clauses[\"select\"].count(\"agg\") == 1\n",
        "            for s, v in slot_values.items():\n",
        "                if \"AGG\" in s:\n",
        "                    agg_kw_prev, agg_prev = s, v\n",
        "                    break\n",
        "            agg_cur_list = [x for x in AGG_OPS if x != agg_prev]\n",
        "            agg_kw_cur = context_q_slots[0]\n",
        "            sql_clauses[\"select\"] = sql_clauses[\"select\"].replace(agg_kw_prev.lower(), agg_kw_cur)\n",
        "            agg_cur = random.choice(agg_cur_list)\n",
        "            q_slot_values[agg_kw_cur] = random.choice(sql_components[\"AGG\"][agg_cur])\n",
        "            slot_values[agg_kw_cur] = agg_cur\n",
        "            if \"COLUMN0\" in context_question:\n",
        "                q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "    elif context_label == \"select delete column\":\n",
        "        if \"agg\" in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"column\") <= 1 or (sql_clauses[\"select\"].count(\"column\") <= 2 and len(context_q_slots) == 2):\n",
        "            satisfy = False\n",
        "        else:\n",
        "            assert sql_clauses[\"select\"].count(\"column\") > 1\n",
        "            sql_clauses[\"select\"] = \"select \" + \" , \".join(context_q_slots)\n",
        "            for qs in context_q_slots:\n",
        "                if \"{COLUMN10}\" == qs:\n",
        "                    if \"{COLUMN12}\" in slot_values.keys():\n",
        "                        slot_values[\"{COLUMN10}\"] = slot_values[\"{COLUMN12}\"]\n",
        "                    elif \"{COLUMN11}\" in slot_values.keys():\n",
        "                        slot_values[\"{COLUMN10}\"] = slot_values[\"{COLUMN11}\"]\n",
        "                    elif \"{COLUMN1}\" in slot_values.keys():\n",
        "                        slot_values[\"{COLUMN10}\"] = slot_values[\"{COLUMN1}\"]\n",
        "                    q_slot_values[qs] = slot_values[\"{COLUMN10}\"]\n",
        "                else:\n",
        "                    q_slot_values[qs] = slot_values[qs]\n",
        "    elif context_label == \"select delete agg\": # need to check more examples\n",
        "        if \"count\" not in sql_clauses[\"select\"] or (\"*\" in sql_clauses[\"select\"] and \"column\" in sql_clauses[\"select\"]) or (sql_clauses[\"select\"].count(\"column\") == 0 and len(context_q_slots) == 0) or (sql_clauses[\"select\"].count(\"column0\") == 0 and \"COLUMN0\" in context_question):\n",
        "            satisfy = False\n",
        "        else:\n",
        "            if len(context_q_slots) == 0:\n",
        "                sql_clauses[\"select\"] = \"select {COLUMN0}\"\n",
        "            elif \"{COLUMN0}\" in context_q_slots:\n",
        "                q_slot_values[context_q_slots[0]] = slot_values[\"{COLUMN0}\"]\n",
        "            else:\n",
        "                col, _ = col_select([], columns_all_prev)\n",
        "                q_slot_values[context_q_slots[0]] = col\n",
        "                slot_values[context_q_slots[0]] = col\n",
        "                sql_clauses[\"select\"] = \"select \" + context_q_slots[0]\n",
        "    elif context_label == \"select insert agg\":\n",
        "        if \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"column\") > 1:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            \n",
        "            if \"{AGG0}\" in context_q_slots:\n",
        "                slot_values[\"{AGG0}\"] = random.choices([\"MAX\", \"MIN\", \"SUM\", \"AVG\", \"COUNT\"], weights=(1, 1, 1, 1, 3), k=1)[0]\n",
        "                q_slot_values[\"{AGG0}\"] = random.choice(sql_components[\"AGG\"][slot_values[\"{AGG0}\"]])\n",
        "            else:\n",
        "                slot_values[\"{AGG0}\"] = \"COUNT\"\n",
        "                \n",
        "            if sql_clauses[\"select\"].count(\"column\") == 0:\n",
        "                sql_clauses[\"select\"] = \"select {AGG0} (*)\"\n",
        "                q_slot_values[\"{COLUMN0}\"] = \"\"\n",
        "            elif sql_clauses[\"select\"].count(\"column\") == 1:\n",
        "                sql_clauses[\"select\"] = \"select {AGG0} ({COLUMN0})\"\n",
        "                q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            else:\n",
        "                raise Exception(\"unexcepted select clause: \", sql_clauses[\"select\"])\n",
        "    elif context_label == \"select insert agg and column\":\n",
        "        if \"agg\" not in sql_clauses[\"select\"] and sql_clauses[\"group_by\"] == \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            sql_clauses[\"select\"] = sql_clauses[\"select\"] + \" , \" + \"{agg10} ({column10})\"\n",
        "            for i, qs in enumerate(context_q_slots):\n",
        "                if \"AGG\" in qs:\n",
        "                    slot_values[qs] = random.choice(AGG_OPS)\n",
        "                    q_slot_values[qs] = random.choice(sql_components[\"AGG\"][slot_values[qs]])\n",
        "                elif \"COLUMN\" in qs:\n",
        "                    col, _ = col_select([\"number\"], columns_all_prev)\n",
        "                    q_slot_values[qs] = \" \".join(col.split(\" \")[:5])\n",
        "                    slot_values[qs] = col\n",
        "\n",
        "            if \"agg\" in sql_clauses[\"select\"] and \"COLUMN\" not in context_question:\n",
        "                slot_values[\"{COLUMN10}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            \n",
        "            if \"agg\" not in sql_clauses[\"select\"] and \"COLUMN\" not in context_question:\n",
        "                satisfy = False\n",
        "    elif context_label == \"select replace agg and column\":\n",
        "        if sql_clauses[\"group_by\"] == \"\" and sql_clauses[\"where\"] == \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            sql_clauses[\"select\"] = \"select {agg10} ({column10})\"\n",
        "            for i, qs in enumerate(context_q_slots):\n",
        "                if \"AGG\" in qs:\n",
        "                    slot_values[qs] = random.choice(AGG_OPS)\n",
        "                    q_slot_values[qs] = random.choice(sql_components[\"AGG\"][slot_values[qs]])\n",
        "                elif \"COLUMN\" in qs:\n",
        "                    col, _ = col_select([\"number\"], columns_all_prev)\n",
        "                    q_slot_values[qs] = \" \".join(col.split(\" \")[:5])\n",
        "                    slot_values[qs] = col\n",
        "                    \n",
        "            if len(context_q_slots) == 0:\n",
        "                slot_values[\"{AGG10}\"] = \"COUNT\"\n",
        "                slot_values[\"{COLUMN10}\"] = \"*\"\n",
        "            elif len(context_q_slots) == 4:\n",
        "                sql_clauses[\"select\"] = \"select {agg10} ({column10}) , {agg20} ({column20})\"\n",
        "            \n",
        "            if sql_clauses[\"group_by\"] != \"\":\n",
        "                gb_col = sql_clauses[\"group_by\"].split(\" \")[2].upper()\n",
        "                assert \"COLUMN\" in gb_col\n",
        "                sql_clauses[\"select\"] = sql_clauses[\"select\"] + \" , \" + gb_col\n",
        "    elif context_label == \"where insert\":\n",
        "        if \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"]:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            if sql_clauses[\"where\"] != \"\":\n",
        "                sql_clauses[\"where\"] = sql_clauses[\"where\"] + \" AND \" + \"{COLUMN10} {OP10} {VALUE10}\"\n",
        "            else:\n",
        "                sql_clauses[\"where\"] = \"WHERE {COLUMN10} {OP10} {VALUE10}\"\n",
        "            \n",
        "            if \"{OP\" in context_question:\n",
        "                op_val = random.choice([\">\", \"<\", \">=\", \"<=\", \"=\"])\n",
        "            else:\n",
        "                op_val = \"=\"\n",
        "                \n",
        "            slot_values[\"{OP10}\"] = op_val\n",
        "            q_slot_values[\"{OP10}\"] = random.choice(sql_components[\"OP\"][op_val])\n",
        "                \n",
        "            if op_val != \"=\":\n",
        "                col, value = col_select([\"number\", \"VALUE10\"], columns_all_prev)\n",
        "            else:\n",
        "                col, value = col_select([\"VALUE10\"], columns_all_prev)\n",
        "            \n",
        "            q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "            slot_values[\"{COLUMN10}\"] = col\n",
        "            q_slot_values[\"{VALUE10}\"] = \" \".join(str(value[0][1]).split(\" \")[:5])\n",
        "            slot_values[\"{VALUE10}\"] = value[0][1]\n",
        "            if \"COLUMN0\" in context_question:\n",
        "                q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "    elif context_label == \"where replace\":\n",
        "        if sql_clauses[\"where\"].count(\"column\") != 1:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            sql_clauses[\"where\"] = \"WHERE {COLUMN10} {OP10} {VALUE10}\"\n",
        "            \n",
        "            if \"{OP\" in context_question:\n",
        "                op_val = random.choice([\">\", \"<\", \">=\", \"<=\", \"=\"])\n",
        "            else:\n",
        "                op_val = \"=\"\n",
        "                \n",
        "            slot_values[\"{OP10}\"] = op_val\n",
        "            q_slot_values[\"{OP10}\"] = random.choice(sql_components[\"OP\"][op_val])\n",
        "                \n",
        "            if op_val != \"=\":\n",
        "                col, value = col_select([\"number\", \"VALUE10\"], columns_all_prev)\n",
        "            else:\n",
        "                col, value = col_select([\"VALUE10\"], columns_all_prev)\n",
        "            \n",
        "            q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "            slot_values[\"{COLUMN10}\"] = col\n",
        "            q_slot_values[\"{VALUE10}\"] = \" \".join(str(value[0][1]).split(\" \")[:5])\n",
        "            slot_values[\"{VALUE10}\"] = value[0][1]\n",
        "            if \"COLUMN0\" in context_question:\n",
        "                q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "    elif context_label == \"where replace value\":\n",
        "        if sql_clauses[\"where\"].count(\"column\") != 1 or sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            wh_toks = sql_clauses[\"where\"].split(\" \")\n",
        "            for tok in wh_toks:\n",
        "                if \"column\" in tok:\n",
        "                    wh_col = tok\n",
        "                elif \"value\" in tok:\n",
        "                    wh_val = tok\n",
        "            sql_clauses[\"where\"] = sql_clauses[\"where\"].replace(wh_val, \"{VALUE10}\")\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[wh_col.upper()]\n",
        "            q_slot_values[\"{VALUE10}\"] = \" \".join(str(slot_values[wh_val.upper()]).split(\" \")[:2]) + \" \" + q_slot_values[\"{COLUMN0}\"].split(\" \")[0] #just to add noisy to fake value\n",
        "            slot_values[\"{VALUE10}\"] = q_slot_values[\"{VALUE10}\"]\n",
        "    elif context_label == \"where replace operation\":\n",
        "        if sql_clauses[\"where\"].count(\"column\") != 1 or sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            wh_toks = sql_clauses[\"where\"].split(\" \")\n",
        "            for tok in wh_toks:\n",
        "                if \"column\" in tok:\n",
        "                    wh_col = tok\n",
        "                elif \"value\" in tok:\n",
        "                    wh_val = tok\n",
        "                elif \"op\" in tok:\n",
        "                    wh_op = tok\n",
        "            sql_clauses[\"where\"] = sql_clauses[\"where\"].replace(wh_op, \"{OP10}\")\n",
        "            q_slot_values[\"{VALUE0}\"] = \" \".join(str(slot_values[wh_val.upper()]).split(\" \")[:4])\n",
        "            op_prev = slot_values[wh_op.upper()]\n",
        "            op_cur_list = [x for x in OPS if x != op_prev]\n",
        "            op_val = random.choice(op_cur_list)\n",
        "            slot_values[\"{OP10}\"] = op_val\n",
        "            q_slot_values[\"{OP10}\"] = random.choice(sql_components[\"OP\"][op_val])\n",
        "    \n",
        "    elif context_label == \"order_by insert\":\n",
        "        if \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            sql_clauses[\"order_by\"] = \"order by {column10} {dasc}\"\n",
        "            sc = random.choice([\"ASC\", \"DESC\"])\n",
        "            slot_values[\"{DASC}\"] = sc\n",
        "            col, _ = col_select([], columns_all_prev)\n",
        "            slot_values[\"{COLUMN10}\"] = col\n",
        "            q_slot_values[\"SC_COL\"] = random.choice(sql_components[\"SC_COL\"][sc]).replace(\"[COL]\", \" \".join(col.split(\" \")[:5]))\n",
        "    elif context_label == \"order_by insert limit\":\n",
        "        if \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or sql_clauses[\"order_by\"] == \"\" or \"limit\" in sql_clauses[\"order_by\"]:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            if \"{dasc}\" in sql_clauses[\"order_by\"]:\n",
        "                sc = slot_values[\"{DASC}\"]\n",
        "            else:\n",
        "                sc = \"ASC\"\n",
        "            sql_clauses[\"order_by\"] += \" limit {value10}\"\n",
        "            limit_val = random.choice([1,1,1,2,3,5])\n",
        "            slot_values[\"{VALUE10}\"] = limit_val\n",
        "            if limit_val == 1:\n",
        "                q_slot_values[\"SC_COL_LIMIT\"] = random.choice(sql_components[\"SC_COL_LIMIT\"][sc])\n",
        "            else:\n",
        "                q_slot_values[\"SC_COL_LIMIT\"] = random.choice(sql_components[\"SC_COL_LIMIT\"][sc+\"_NUM\"]).replace(\"[NUM]\", str(limit_val))\n",
        "    elif context_label == \"order_by insert limit | select delete agg and column\":\n",
        "        if \"count\" not in sql_clauses[\"select\"] or sql_clauses[\"group_by\"] == \"\" or sql_clauses[\"order_by\"] != \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            sql_clauses[\"order_by\"] = \"order by count (*) {dasc} limit 1\"\n",
        "            sel_cols = [x for x in sql_clauses[\"select\"].split(\" \") if \"column\" in x]\n",
        "            sql_clauses[\"select\"] = \"select \" + \" , \".join(sel_cols)\n",
        "            sc = random.choice([\"ASC\", \"DESC\"])\n",
        "            slot_values[\"{DASC}\"] = sc\n",
        "            q_slot_values[\"SC_COL_LIMIT\"] = random.choice(sql_components[\"SC_COL_LIMIT\"][sc])\n",
        "            if \"{COLUMN0}\" in slot_values.keys():\n",
        "                q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "    elif context_label == \"order_by insert limit | select replace column\":\n",
        "        if sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"] != \"\":\n",
        "            satisfy = False\n",
        "        else:\n",
        "            col, _ = col_select([], columns_all_prev)\n",
        "            q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "            slot_values[\"{COLUMN10}\"] = col\n",
        "            sql_clauses[\"select\"] = \"select {column10}\"\n",
        "            \n",
        "            sc = random.choice([\"ASC\", \"DESC\"])\n",
        "            slot_values[\"{DASC}\"] = sc\n",
        "            q_slot_values[\"SC_COL_LIMIT\"] = random.choice(sql_components[\"SC_COL_LIMIT\"][sc])\n",
        "            \n",
        "            if \"{COLUMN2}\" in context_question:\n",
        "                col2, _ = col_select([\"number\"], columns_all_prev)\n",
        "                q_slot_values[\"{COLUMN20}\"] = \" \".join(col2.split(\" \")[:5])\n",
        "                slot_values[\"{COLUMN20}\"] = col2\n",
        "                sql_clauses[\"order_by\"] = \"order by {column20} {dasc} limit 1\" \n",
        "            else:\n",
        "                sql_clauses[\"order_by\"] = \"order by count (*) {dasc} limit 1\"           \n",
        "    elif context_label == \"order_by replace sc\":\n",
        "        if \"agg\" in sql_clauses[\"select\"] or \"limit\" not in sql_clauses[\"order_by\"]:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            if \"{dasc}\" in sql_clauses[\"order_by\"]:\n",
        "                sc_prev = slot_values[\"{DASC}\"]\n",
        "            else:\n",
        "                sc_prev = \"ASC\"\n",
        "            sc = \"DESC\" if sc_prev == \"ASC\" else \"ASC\"\n",
        "            slot_values[\"{DASC}\"] = sc\n",
        "            q_slot_values[\"SC_COL_LIMIT\"] = random.choice(sql_components[\"SC_COL_LIMIT\"][sc])\n",
        "            if \"{COLUMN0}\" in slot_values.keys():\n",
        "                q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "    elif context_label == \"no change\":\n",
        "        if \"having\" not in sql_clauses[\"group_by\"] and \"value\" not in sql_clauses[\"order_by\"]:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            q_slot_values[\"{OP0}\"] = \"top\"\n",
        "            q_slot_values[\"[NUM]\"] = random.choice([3,5,10])\n",
        "            if \"having\" in sql_clauses[\"group_by\"]:\n",
        "                gb_toks = sql_clauses[\"group_by\"].split(\" \")\n",
        "                for tok in gb_toks:\n",
        "                    if \"op\" in tok:\n",
        "                        gb_op = tok.upper()\n",
        "                        q_slot_values[\"{OP0}\"] = random.choice(sql_components[\"OP\"][slot_values[gb_op]])\n",
        "    elif context_label == \"group_by insert | select insert agg and column\":\n",
        "        if sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"].count(\"column\") > 1 or \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or \"column0\" not in sql_clauses[\"select\"]:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            sql_clauses[\"group_by\"] = \"group by {column0}\"\n",
        "            if \"AGG\" not in context_question:\n",
        "                sql_clauses[\"select\"] = sql_clauses[\"select\"] + \" , count (*)\"\n",
        "            else:\n",
        "                sql_clauses[\"select\"] = sql_clauses[\"select\"] + \" , {agg10} ({column10})\"\n",
        "                agg_cur = random.choice(AGG_OPS)\n",
        "                slot_values[\"{AGG10}\"] = agg_cur\n",
        "                q_slot_values[\"{AGG10}\"] = random.choice(sql_components[\"AGG\"][agg_cur])\n",
        "                col, _ = col_select([\"number\"], columns_all_prev)\n",
        "                q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "                slot_values[\"{COLUMN10}\"] = col\n",
        "    elif context_label == \"group_by insert | select replace agg and column\":\n",
        "        if sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"] != \"\" or \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or \"column0\" not in sql_clauses[\"select\"]:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            sql_clauses[\"group_by\"] = \"group by {column0}\"\n",
        "            if \"AGG\" not in context_question:\n",
        "                sql_clauses[\"select\"] = \"select {column0} , count (*)\"\n",
        "            else:\n",
        "                if \"COLUMN1\" in context_question:\n",
        "                    col, _ = col_select([], columns_all_prev)\n",
        "                    q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "                    slot_values[\"{COLUMN10}\"] = col\n",
        "                    sql_clauses[\"select\"] = \"select {column10} , {agg10} ({column20})\"\n",
        "                    sql_clauses[\"group_by\"] = \"group by {column10}\"\n",
        "                else:\n",
        "                    sql_clauses[\"select\"] = \"select {column0} , {agg10} ({column20})\"\n",
        "                agg_cur = random.choice(AGG_OPS)\n",
        "                slot_values[\"{AGG10}\"] = agg_cur\n",
        "                q_slot_values[\"{AGG10}\"] = random.choice(sql_components[\"AGG\"][agg_cur])\n",
        "                col, _ = col_select([\"number\"], columns_all_prev)\n",
        "                q_slot_values[\"{COLUMN20}\"] = \" \".join(col.split(\" \")[:5])\n",
        "                slot_values[\"{COLUMN20}\"] = col\n",
        "    elif context_label == \"group_by insert | order_by insert\":\n",
        "        if sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"] != \"\" or \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or \"column0\" not in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"column\") > 2:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            sql_clauses[\"group_by\"] = \"group by {column0}\"\n",
        "            sql_clauses[\"order_by\"] = \"order by count (*) {dasc}\"\n",
        "\n",
        "            if \"COLUMN1\" in context_question:\n",
        "                col, _ = col_select([], columns_all_prev)\n",
        "                q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "                slot_values[\"{COLUMN10}\"] = col\n",
        "                sql_clauses[\"group_by\"] = \"group by {column10}\"\n",
        "            \n",
        "            sc = random.choice([\"ASC\", \"DESC\"])\n",
        "            slot_values[\"{DASC}\"] = sc\n",
        "            q_slot_values[\"SC\"] = random.choice(sql_components[\"SC\"][sc])\n",
        "    elif context_label == \"group_by insert having\":\n",
        "        if \"having\" in sql_clauses[\"group_by\"] or sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"] != \"\" or \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or \"column0\" not in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"column\") > 2:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            if sql_clauses[\"group_by\"] == \"\":\n",
        "                sql_clauses[\"group_by\"] = \"group by {column0} having count (*) {op0} {value0}\"\n",
        "            else:\n",
        "                sql_clauses[\"group_by\"] += \" having count (*) {op0} {value0}\"\n",
        "            \n",
        "            op_val = random.choice(OPS)\n",
        "            slot_values[\"{OP0}\"] = op_val\n",
        "            q_slot_values[\"{OP0}\"] = random.choice(sql_components[\"OP\"][op_val])\n",
        "            \n",
        "            value = random.choice([1, 3, 5, 10])\n",
        "            slot_values[\"{VALUE0}\"] = value\n",
        "            q_slot_values[\"{VALUE0}\"] = str(value)\n",
        "    elif context_label == \"group_by insert having | select delete agg and column\":\n",
        "        if \"having\" in sql_clauses[\"group_by\"] or sql_clauses[\"group_by\"] == \"\" or sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"] != \"\" or (\"agg\" not in sql_clauses[\"select\"] and \"count\" not in sql_clauses[\"select\"]) or \"column0\" not in sql_clauses[\"select\"]:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            sel_toks = sql_clauses[\"select\"].split(\" \")\n",
        "            agg_col_toks = []\n",
        "            for tok in sel_toks:\n",
        "                if \"select\" not in tok and \",\" not in tok:\n",
        "                    if \"({column\" in tok or \"column\" not in tok:\n",
        "                        agg_col_toks.append(tok)\n",
        "                if \")\" in tok:\n",
        "                    break\n",
        "            agg_col = \" \".join(agg_col_toks)\n",
        "            sql_clauses[\"select\"] = \" \".join([x for x in sel_toks if x not in agg_col_toks])\n",
        "            \n",
        "            sql_clauses[\"group_by\"] += \" having \" + agg_col + \" {op0} {value0}\"\n",
        "            \n",
        "            op_val = random.choice(OPS)\n",
        "            slot_values[\"{OP0}\"] = op_val\n",
        "            q_slot_values[\"{OP0}\"] = random.choice(sql_components[\"OP\"][op_val])\n",
        "            \n",
        "            value = random.choice([1, 3, 5, 10])\n",
        "            slot_values[\"{VALUE0}\"] = value\n",
        "            q_slot_values[\"{VALUE0}\"] = str(value)\n",
        "    elif context_label == \"group_by replace | select replace column\":\n",
        "        if sql_clauses[\"group_by\"] == \"\" or sql_clauses[\"where\"] != \"\" or \"column0\" not in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"column\") > 2:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            col, _ = col_select([], columns_all_prev)\n",
        "            q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "            slot_values[\"{COLUMN10}\"] = col\n",
        "            if \"{column0}\" in sql_clauses[\"group_by\"]:\n",
        "                sql_clauses[\"select\"] = sql_clauses[\"select\"].replace(\"{column0}\", \"{column10}\")\n",
        "                sql_clauses[\"group_by\"] = sql_clauses[\"group_by\"].replace(\"{column0}\", \"{column10}\")\n",
        "            elif \"{column1}\" in sql_clauses[\"group_by\"]:\n",
        "                sql_clauses[\"select\"] = sql_clauses[\"select\"].replace(\"{column1}\", \"{column10}\")\n",
        "                sql_clauses[\"group_by\"] = sql_clauses[\"group_by\"].replace(\"{column1}\", \"{column10}\")\n",
        "            else:\n",
        "                satisfy = False\n",
        "    elif context_label == \"insert SQL\":\n",
        "        if sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"].count(\"value\") != 1 or \"select\" in sql_clauses[\"where\"] or \"agg\" in sql_clauses[\"select\"] or \"count\" in sql_clauses[\"select\"] or \"column0\" not in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"column\") > 2:\n",
        "            satisfy = False\n",
        "        else:\n",
        "            wh_toks = sql_clauses[\"where\"].split(\" \")\n",
        "            for tok in wh_toks:\n",
        "                if \"column\" in tok:\n",
        "                    wh_col = tok\n",
        "                elif \"value\" in tok:\n",
        "                    wh_val = tok\n",
        "                elif \"op\" in tok:\n",
        "                    wh_op = tok\n",
        "            \n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[wh_col.upper()]\n",
        "            q_slot_values[\"{VALUE0}\"] = slot_values[wh_val.upper()]\n",
        "            value = random.choice([1, 3, 5, 10])\n",
        "            slot_values[\"{VALUE10}\"] = value\n",
        "            q_slot_values[\"{VALUE10}\"] = str(value)\n",
        "            op_val = random.choice(OPS)\n",
        "            slot_values[\"{OP10}\"] = op_val\n",
        "            q_slot_values[\"{OP10}\"] = random.choice(sql_components[\"OP\"][op_val])\n",
        "            if \"{OP1\" in context_question:\n",
        "                sql_where = \" where {column0} {op10} {value10}\"\n",
        "            elif \"{VALUE1\" in context_question:\n",
        "                sql_where = \" where {column0} {op0} {value10}\"\n",
        "            else:\n",
        "                sql_where = \" where {column0} {op0} {value0}\"\n",
        "            if \"COLUMN1\" in context_question:\n",
        "                col, _ = col_select([], columns_all_prev)\n",
        "                q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "                slot_values[\"{COLUMN10}\"] = col\n",
        "                sql_clauses[\"select\"] = \"select {column10}\"\n",
        "            if context_constraints[0] == \"intersect\":\n",
        "                sql_clauses[\"group_by\"] = \"intersect \" + sql_clauses[\"select\"] + sql_where\n",
        "            else:\n",
        "                sql_clauses[\"group_by\"] = \"except \" + sql_clauses[\"select\"] + sql_where\n",
        "                sql_clauses[\"where\"] = \"\"\n",
        "    elif context_label == \"where insert SQL\":\n",
        "        if sql_clauses[\"group_by\"] != \"\" or sql_clauses[\"order_by\"] != \"\" or sql_clauses[\"where\"].count(\"column\") > 1 or \"select\" in sql_clauses[\"where\"] or \"count\" in sql_clauses[\"select\"] or \"column0\" not in sql_clauses[\"select\"] or sql_clauses[\"select\"].count(\"column\") > 1:\n",
        "            satisfy = False\n",
        "        elif \"agg\" in sql_clauses[\"select\"] and context_constraints[0] == \"op\":\n",
        "            col, _ = col_select([], columns_all_prev)\n",
        "            q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "            slot_values[\"{COLUMN10}\"] = col\n",
        "            sql_clauses[\"select\"] = \"select {column10}\"\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            op_val = random.choice(OPS)\n",
        "            slot_values[\"{OP10}\"] = op_val\n",
        "            q_slot_values[\"{OP10}\"] = random.choice(sql_components[\"OP\"][op_val])\n",
        "            sql_clauses[\"where\"] = \"where {column0} {op10} (\" + sql_pattern.lower() + \")\"\n",
        "            sql_clauses[\"where\"] = sql_clauses[\"where\"].replace(\"( \", \"(\").replace(\" )\", \")\")\n",
        "        elif \"agg\" not in sql_clauses[\"select\"] and context_constraints[0] != \"op\":\n",
        "            q_slot_values[\"{COLUMN0}\"] = slot_values[\"{COLUMN0}\"]\n",
        "            if \"{TABLE0}\" in slot_values.keys():\n",
        "                q_slot_values[\"{TABLE0}\"] = slot_values[\"{TABLE0}\"]\n",
        "            else:\n",
        "                q_slot_values[\"{TABLE0}\"] = \"\"\n",
        "                \n",
        "            if \"COLUMN1\" in context_question:\n",
        "                col, _ = col_select([], columns_all_prev)\n",
        "                q_slot_values[\"{COLUMN10}\"] = \" \".join(col.split(\" \")[:5])\n",
        "                slot_values[\"{COLUMN10}\"] = col\n",
        "                sql_clauses[\"select\"] = \"select {column10}\"\n",
        "                \n",
        "            if context_constraints[0] == \"not in\":\n",
        "                sql_clauses[\"where\"] = \"where {column0} not in (\" + sql_pattern.lower() + \")\"\n",
        "            else:\n",
        "                sql_clauses[\"where\"] = \"where {column0} in (\" + sql_pattern.lower() + \")\"\n",
        "            sql_clauses[\"where\"] = sql_clauses[\"where\"].replace(\"( \", \"(\").replace(\" )\", \")\")\n",
        "        else:\n",
        "            satisfy = False\n",
        "    else:\n",
        "        print(\"\\n--------------------Unexcepted context template: \", context_label)\n",
        "        satisfy = False\n",
        "    \n",
        "        \n",
        "    if satisfy:\n",
        "#         print(\"parsed prev sql: \", parsed)\n",
        "#         print(\"slot_values: \", slot_values)\n",
        "#         print(\"q_slot_values: \", q_slot_values)\n",
        "        sql_str_list = [v for k, v in sql_clauses.items() if v != \"\"]\n",
        "        sql_str_list.insert(1, \"{from}\")\n",
        "\n",
        "        sql_pattern_new = \" \".join(sql_str_list).upper().replace(\"(\", \"( \").replace(\")\", \" )\")\n",
        "        \n",
        "        # 9 generate final SQL-question pair\n",
        "        q_slot_values = {k.replace(\"10\", \"1\").replace(\"20\", \"2\").replace(\"30\", \"3\"): v for k, v in q_slot_values.items()}\n",
        "        context_q = replace_dict(context_question, q_slot_values)\n",
        "\n",
        "    return sql_pattern_new, slot_values, context_q, satisfy\n",
        "\n",
        "\n",
        "def add_augment_context(augment_data, context_templates, schema_dbs):\n",
        "    #question_gen, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all\n",
        "\n",
        "    data_new = {}\n",
        "    skip_count = 0\n",
        "    count = 0\n",
        "    augment_iso = augment_data.copy()\n",
        "    for schema_str, exs in augment_iso.items():\n",
        "        count += 1\n",
        "        if count % 10000 == 0:\n",
        "            print(\"processed: \", count)\n",
        "        data_new[schema_str] = []\n",
        "        for ex in exs:\n",
        "            sql_pattern = ex[5]\n",
        "            columns_all_prev = ex[6].copy()\n",
        "            question_prev = ex[0]\n",
        "            sql_prev = ex[1]\n",
        "            col_labels_prev = ex[2].copy()\n",
        "            q_slot_values_prev = ex[3]\n",
        "            slot_values_prev = ex[4].copy()\n",
        "            context_label_list = ex[7].copy()\n",
        "            \n",
        "            if random.random() <= 0.8:\n",
        "                try_num = 0\n",
        "                if \"INTERSECT\" in sql_pattern or \"UNION\" in sql_pattern or \"EXCEPT\" in sql_pattern or len(columns_all_prev) < 1:\n",
        "                    continue\n",
        "\n",
        "                while try_num < 3:\n",
        "                    context_template = random.choice(context_templates)\n",
        "                    context_label = context_template['label']\n",
        "                    prereqs = context_template[\"prereqs\"]\n",
        "                    edited_sql_pattern, slot_values, context_q, satisfy = edit_sql(sql_pattern, context_label, slot_values_prev, columns_all_prev, context_template)\n",
        "\n",
        "                    try_num += 1\n",
        "                    if satisfy:\n",
        "                        break\n",
        "\n",
        "                if not satisfy:\n",
        "                    continue\n",
        "\n",
        "                context_q = context_q + prev_token + question_prev\n",
        "\n",
        "    #             print(\"question: \", context_q)\n",
        "    #             print(\"previous sql pattern: \", sql_pattern)\n",
        "    #             print(\"edited_sql_pattern: \", edited_sql_pattern)\n",
        "\n",
        "                # 10 generate column labels\n",
        "                slot_values_new = {}\n",
        "                for sl, vl in slot_values.items():\n",
        "                    if \"COLUMN\" in sl:\n",
        "                        slot_values_new[sl] = \"_=_\".join(vl.split(\" \"))\n",
        "                    else:\n",
        "                        slot_values_new[sl] = vl\n",
        "\n",
        "                column_labels, skip = get_labels(edited_sql_pattern)\n",
        "                if skip:\n",
        "                    continue\n",
        "                column_lables_real = {}\n",
        "                for col, label in column_labels.items():\n",
        "                    if col != \"*\":\n",
        "                        if col not in slot_values.keys():\n",
        "                            print(\"slot_values_prev: \", slot_values_prev)\n",
        "                            print(\"q_slot_values_prev: \", q_slot_values_prev)\n",
        "                            print(\"sql_pattern: \", sql_pattern)\n",
        "                            print(\"context_label: \", context_label)\n",
        "                            print(\"edited_sql_pattern: \", edited_sql_pattern)\n",
        "                            print(\"slot_values: \", slot_values)\n",
        "                            print(\"column_labels: \", column_labels)\n",
        "                        col = slot_values[col]\n",
        "                    for slot, value in slot_values.items():\n",
        "                        label = label.replace(slot, str(value))\n",
        "                    column_lables_real[col] = label\n",
        "\n",
        "                edited_sql = replace_dict(edited_sql_pattern.replace(\" {FROM}\", \"\"), slot_values_new)\n",
        "\n",
        "                #(question_gen, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all)\n",
        "\n",
        "    #             print(\"edited_sql: \", edited_sql)\n",
        "    #             print(\"column_lables_real: \", column_lables_real)\n",
        "    #             print(\"\")\n",
        "                context_label_int = qsep_label_map[context_label]\n",
        "                context_label_list.insert(0, context_label_int)\n",
        "                data_new[schema_str].append((context_q, edited_sql, column_lables_real, None, slot_values, edited_sql_pattern, columns_all_prev, context_label_list))\n",
        "            else:\n",
        "                db = schema_dbs[schema_str]\n",
        "                template = random.choice(templates)\n",
        "                sql_constraints = template['SQL constraints']\n",
        "                sql_pattern = template[\"SQL pattern\"]\n",
        "                question, q_constraints = random.choice(template[\"questions\"])\n",
        "                constraints = list(set(sql_constraints + q_constraints))\n",
        "                sql_gen, question_gen, column_lables, q_slot_values, slot_values, template, columns_all = populate_one(db, question, sql_pattern, constraints)\n",
        "                context_q = question_gen + prev_token + question_prev\n",
        "                context_label_list.insert(0, 0)\n",
        "                data_new[schema_str].append((context_q, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all, context_label_list))\n",
        "            \n",
        "    return data_new       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtxxLzBrIoqO",
        "outputId": "32acbd01-5607-4cc6-933f-7bb1c7511caa"
      },
      "source": [
        "augment_second_spider_wikisql = add_augment_context(augment_data_no_dev_wikisql, context_templates, schema_dbs_all)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Warning: column values are empty!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOd2X4Q1IoqO"
      },
      "source": [
        "slot_update_dict = {\"10\": \"11\", \"20\": \"21\", \"30\": \"31\"}\n",
        "\n",
        "def add_augment_context_second(augment_second_data, context_templates, schema_dbs):\n",
        "    #question_gen, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all, [context_label_int]\n",
        "\n",
        "    data_new = {}\n",
        "    skip_count = 0\n",
        "    count = 0\n",
        "    augment_second_iso = augment_second_data.copy()\n",
        "    for schema_str, exs in augment_second_iso.items():\n",
        "        count += 1\n",
        "        if count % 10000 == 0:\n",
        "            print(\"processed: \", count)\n",
        "        data_new[schema_str] = []\n",
        "        for ex in exs:\n",
        "            sql_pattern = replace_dict(ex[5], slot_update_dict)\n",
        "            columns_all_prev = ex[6].copy()\n",
        "            question_prev = ex[0]\n",
        "            sql_prev = ex[1]\n",
        "            col_labels_prev = ex[2].copy()\n",
        "            q_slot_values_prev = ex[3]\n",
        "            slot_values_prev = {replace_dict(k, slot_update_dict) : v for k, v in ex[4].items()}.copy()\n",
        "            context_label_list = ex[7].copy()\n",
        "            \n",
        "            \n",
        "            if random.random() <= 0.8:\n",
        "                try_num = 0\n",
        "                if \"INTERSECT\" in sql_pattern or \"UNION\" in sql_pattern or \"EXCEPT\" in sql_pattern or len(columns_all_prev) < 1:\n",
        "                    continue\n",
        "\n",
        "                while try_num < 3:\n",
        "                    context_template = random.choice(context_templates)\n",
        "                    context_label = context_template['label']\n",
        "                    prereqs = context_template[\"prereqs\"]\n",
        "                    edited_sql_pattern, slot_values, context_q, satisfy = edit_sql(sql_pattern, context_label, slot_values_prev, columns_all_prev, context_template)\n",
        "\n",
        "                    try_num += 1\n",
        "                    if satisfy:\n",
        "                        break\n",
        "\n",
        "                if not satisfy:\n",
        "                    continue\n",
        "\n",
        "                context_q = context_q + prev_token + question_prev\n",
        "\n",
        "    #             print(\"question: \", context_q)\n",
        "    #             print(\"previous sql pattern: \", sql_pattern)\n",
        "    #             print(\"edited_sql_pattern: \", edited_sql_pattern)\n",
        "\n",
        "                # 10 generate column labels\n",
        "                slot_values_new = {}\n",
        "                for sl, vl in slot_values.items():\n",
        "                    if \"COLUMN\" in sl:\n",
        "                        slot_values_new[sl] = \"_=_\".join(vl.split(\" \"))\n",
        "                    else:\n",
        "                        slot_values_new[sl] = vl\n",
        "\n",
        "                column_labels, skip = get_labels(edited_sql_pattern)\n",
        "                if skip:\n",
        "                    continue\n",
        "                column_lables_real = {}\n",
        "                for col, label in column_labels.items():\n",
        "                    if col != \"*\":\n",
        "                        if col not in slot_values.keys():\n",
        "                            print(\"slot_values_prev: \", slot_values_prev)\n",
        "                            print(\"q_slot_values_prev: \", q_slot_values_prev)\n",
        "                            print(\"sql_pattern: \", sql_pattern)\n",
        "                            print(\"context_label: \", context_label)\n",
        "                            print(\"edited_sql_pattern: \", edited_sql_pattern)\n",
        "                            print(\"slot_values: \", slot_values)\n",
        "                            print(\"column_labels: \", column_labels)\n",
        "                        col = slot_values[col]\n",
        "                    for slot, value in slot_values.items():\n",
        "                        label = label.replace(slot, str(value))\n",
        "                    column_lables_real[col] = label\n",
        "\n",
        "                edited_sql = replace_dict(edited_sql_pattern.replace(\" {FROM}\", \"\"), slot_values_new)\n",
        "\n",
        "                #(question_gen, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all)\n",
        "\n",
        "    #             print(\"edited_sql: \", edited_sql)\n",
        "    #             print(\"column_lables_real: \", column_lables_real)\n",
        "    #             print(\"\")\n",
        "                context_label_int = qsep_label_map[context_label]\n",
        "                context_label_list.insert(0, context_label_int)\n",
        "                \n",
        "                data_new[schema_str].append((context_q, edited_sql, column_lables_real, None, slot_values, edited_sql_pattern, columns_all_prev, context_label_list))\n",
        "            else:\n",
        "                db = schema_dbs[schema_str]\n",
        "                template = random.choice(templates)\n",
        "                sql_constraints = template['SQL constraints']\n",
        "                sql_pattern = template[\"SQL pattern\"]\n",
        "                question, q_constraints = random.choice(template[\"questions\"])\n",
        "                constraints = list(set(sql_constraints + q_constraints))\n",
        "                sql_gen, question_gen, column_lables, q_slot_values, slot_values, template, columns_all = populate_one(db, question, sql_pattern, constraints)\n",
        "                context_q = question_gen + prev_token + question_prev\n",
        "                context_label_list.insert(0, 0)\n",
        "                data_new[schema_str].append((context_q, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all, context_label_list))\n",
        "                \n",
        "    return data_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMz_A9nrIoqP",
        "outputId": "fca5d98c-0f75-42b6-d04a-49a8195e4b36"
      },
      "source": [
        "augment_third_spider_wikisql = add_augment_context_second(augment_second_spider_wikisql, context_templates, schema_dbs_all)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Warning: unexcepted SELECT format\n",
            "SELECT {COLUMN0} {FROM} WHERE {COLUMN0} IN ( SELECT {COLUMN0} { FROM} ) AND {COLUMN10} {OP10} {VALUE10}\n",
            "\n",
            "Warning: column values are empty!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ywFWzzoIoqP",
        "outputId": "ca9f22da-4382-416d-e7d3-6da089522906"
      },
      "source": [
        "count_aug(augment_third_spider_wikisql)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwlNtTnFIoqP"
      },
      "source": [
        "slot_update_dict = {\"10\": \"12\", \"20\": \"22\", \"30\": \"32\"}\n",
        "\n",
        "def add_augment_context_third(augment_third_data, context_templates, schema_dbs):\n",
        "    #question_gen, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all, [context_label_int]\n",
        "\n",
        "    data_new = {}\n",
        "    skip_count = 0\n",
        "    count = 0\n",
        "    augment_third_iso = augment_third_data.copy()\n",
        "    for schema_str, exs in augment_third_iso.items():\n",
        "        count += 1\n",
        "        if count % 10000 == 0:\n",
        "            print(\"processed: \", count)\n",
        "        data_new[schema_str] = []\n",
        "        for ex in exs:\n",
        "            sql_pattern = replace_dict(ex[5], slot_update_dict)\n",
        "            columns_all_prev = ex[6].copy()\n",
        "            question_prev = ex[0]\n",
        "            sql_prev = ex[1]\n",
        "            col_labels_prev = ex[2].copy()\n",
        "            q_slot_values_prev = ex[3]\n",
        "            slot_values_prev = {replace_dict(k, slot_update_dict) : v for k, v in ex[4].items()}.copy()\n",
        "            context_label_list = ex[7].copy()\n",
        "            \n",
        "            \n",
        "            if random.random() <= 0.8:\n",
        "                try_num = 0\n",
        "                if \"INTERSECT\" in sql_pattern or \"UNION\" in sql_pattern or \"EXCEPT\" in sql_pattern or len(columns_all_prev) < 1:\n",
        "                    continue\n",
        "\n",
        "                while try_num < 3:\n",
        "                    context_template = random.choice(context_templates)\n",
        "                    context_label = context_template['label']\n",
        "                    prereqs = context_template[\"prereqs\"]\n",
        "                    edited_sql_pattern, slot_values, context_q, satisfy = edit_sql(sql_pattern, context_label, slot_values_prev, columns_all_prev, context_template)\n",
        "\n",
        "                    try_num += 1\n",
        "                    if satisfy:\n",
        "                        break\n",
        "\n",
        "                if not satisfy:\n",
        "                    continue\n",
        "\n",
        "                context_q = context_q + prev_token + question_prev\n",
        "\n",
        "    #             print(\"question: \", context_q)\n",
        "    #             print(\"previous sql pattern: \", sql_pattern)\n",
        "    #             print(\"edited_sql_pattern: \", edited_sql_pattern)\n",
        "\n",
        "                # 10 generate column labels\n",
        "                slot_values_new = {}\n",
        "                for sl, vl in slot_values.items():\n",
        "                    if \"COLUMN\" in sl:\n",
        "                        slot_values_new[sl] = \"_=_\".join(vl.split(\" \"))\n",
        "                    else:\n",
        "                        slot_values_new[sl] = vl\n",
        "\n",
        "                column_labels, skip = get_labels(edited_sql_pattern)\n",
        "                if skip:\n",
        "                    continue\n",
        "                column_lables_real = {}\n",
        "                for col, label in column_labels.items():\n",
        "                    if col != \"*\":\n",
        "                        if col not in slot_values.keys():\n",
        "                            print(\"slot_values_prev: \", slot_values_prev)\n",
        "                            print(\"q_slot_values_prev: \", q_slot_values_prev)\n",
        "                            print(\"sql_pattern: \", sql_pattern)\n",
        "                            print(\"context_label: \", context_label)\n",
        "                            print(\"edited_sql_pattern: \", edited_sql_pattern)\n",
        "                            print(\"slot_values: \", slot_values)\n",
        "                            print(\"column_labels: \", column_labels)\n",
        "                        col = slot_values[col]\n",
        "                    for slot, value in slot_values.items():\n",
        "                        label = label.replace(slot, str(value))\n",
        "                    column_lables_real[col] = label\n",
        "\n",
        "                edited_sql = replace_dict(edited_sql_pattern.replace(\" {FROM}\", \"\"), slot_values_new)\n",
        "\n",
        "                #(question_gen, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all)\n",
        "\n",
        "    #             print(\"edited_sql: \", edited_sql)\n",
        "    #             print(\"column_lables_real: \", column_lables_real)\n",
        "    #             print(\"\")\n",
        "                context_label_int = qsep_label_map[context_label]\n",
        "                context_label_list.insert(0, context_label_int)\n",
        "                \n",
        "                data_new[schema_str].append((context_q, edited_sql, column_lables_real, None, slot_values, edited_sql_pattern, columns_all_prev, context_label_list))\n",
        "            else:\n",
        "                db = schema_dbs[schema_str]\n",
        "                template = random.choice(templates)\n",
        "                sql_constraints = template['SQL constraints']\n",
        "                sql_pattern = template[\"SQL pattern\"]\n",
        "                question, q_constraints = random.choice(template[\"questions\"])\n",
        "                constraints = list(set(sql_constraints + q_constraints))\n",
        "                sql_gen, question_gen, column_lables, q_slot_values, slot_values, template, columns_all = populate_one(db, question, sql_pattern, constraints)\n",
        "                context_q = question_gen + prev_token + question_prev\n",
        "                context_label_list.insert(0, 0)\n",
        "                data_new[schema_str].append((context_q, sql_gen, column_lables, q_slot_values, slot_values, template, columns_all, context_label_list))\n",
        "                \n",
        "    return data_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaoAx6e-IoqP",
        "outputId": "4dafc1bd-52f0-45bc-d3a6-24bbc3745d36"
      },
      "source": [
        "augment_fourth_spider_wikisql = add_augment_context_third(augment_third_spider_wikisql, context_templates, schema_dbs_all)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Warning: unexcepted SELECT format\n",
            "SELECT {COLUMN12} {FROM} WHERE {COLUMN0} NOT IN ( SELECT {COLUMN0} { FROM} ) AND {COLUMN10} {OP10} {VALUE10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POBWmiASIoqQ"
      },
      "source": [
        "### process label prints for each column\n",
        "def get_label_map(data):\n",
        "    label_dict = defaultdict(int)\n",
        "    for schema_str, example_list in data.items():\n",
        "        for example in example_list:\n",
        "            (question, sql, col_labels) = example\n",
        "            for val in col_labels.values():\n",
        "                label_dict[val] += 1\n",
        "    label_list = sorted(label_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
        "    label_map = {}\n",
        "    count = 1\n",
        "    for label, _ in label_list:\n",
        "        label_map[label] = count\n",
        "        count += 1\n",
        "    \n",
        "    return label_map\n",
        "\n",
        "def map_labels(data, label_map, is_dev=False):\n",
        "    data_new = {}\n",
        "    skip_count = 0\n",
        "    count = 0\n",
        "    augment_data = data.copy()\n",
        "    for schema_str, exs in augment_data.items():\n",
        "        count += 1\n",
        "        if count % 100000 == 0:\n",
        "            print(\"processed: \", count)\n",
        "        data_new[schema_str] = []\n",
        "        for ex in exs:\n",
        "            skip = False\n",
        "            label_dict = ex[2]\n",
        "            label_dict_new = {}\n",
        "            for col, label in label_dict.items():\n",
        "                if label in label_map.keys():\n",
        "                    label_dict_new[col] = label_map[label]\n",
        "                else:\n",
        "                    skip = True\n",
        "                    skip_count += 1\n",
        "                    #else just skip\n",
        "#             context_q, edited_sql, column_lables_real, label_dict_int, slot_values, edited_sql_pattern, context_label_list\n",
        "            if not skip:\n",
        "        \n",
        "                data_new[schema_str].append((ex[0], ex[1], ex[2], label_dict_new, ex[4], ex[5], ex[7]))   \n",
        "    \n",
        "    print(\"skip_count: \", skip_count)\n",
        "    return data_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CCnsGRnIoqQ",
        "outputId": "4fa438c2-47fa-49e5-98c4-c78aebd7bb01"
      },
      "source": [
        "augment_first_spider_wikisql = map_labels(augment_data_no_dev_wikisql, label_map)\n",
        "augment_second_spider_wikisql = map_labels(augment_second_spider_wikisql, label_map)\n",
        "augment_third_spider_wikisql = map_labels(augment_third_spider_wikisql, label_map)\n",
        "augment_fourth_spider_wikisql = map_labels(augment_fourth_spider_wikisql, label_map)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "skip_count:  0\n",
            "skip_count:  604\n",
            "skip_count:  467\n",
            "skip_count:  343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWgGjjBpIoqQ",
        "outputId": "97deb5a1-1fdb-47d3-9b29-42ba61195244"
      },
      "source": [
        "augment_context_all_spider_wikisql = defaultdict(list)\n",
        "for augment_one in [augment_first_spider_wikisql, augment_second_spider_wikisql, augment_third_spider_wikisql, augment_fourth_spider_wikisql]:\n",
        "    for schema, examples in augment_one.items():\n",
        "        augment_context_all_spider_wikisql[schema].extend(examples)\n",
        "\n",
        "two_count = 0\n",
        "for schema, examples in augment_context_all_spider_wikisql.items():\n",
        "    for ex in examples:\n",
        "        two_count += 1\n",
        "print(two_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH0T78sxIoqQ"
      },
      "source": [
        "MAX_TOKEN_LEN = 200\n",
        "def write_final_file(augment_data):\n",
        "    data_json = []\n",
        "    skip_count = 0\n",
        "    line_count = 0\n",
        "    dup_count = 0\n",
        "    pro_count = 0\n",
        "    for schema_str, exs in augment_data.items():\n",
        "        for ex in exs:\n",
        "            line_count += 1\n",
        "            if line_count % 100000 == 0:\n",
        "                print(\"processed: \", line_count)\n",
        "            question, sql, label_strs, label_ints, sql_slot_values, sql_pattern, context_label_list = ex\n",
        "            col_str, val_str = schema_str.split(\" |-| \")\n",
        "            colns = col_str.split(\" </s> \")\n",
        "            values = val_str.split(\" </s> \")\n",
        "            assert len(colns) == len(values)\n",
        "            cols = []\n",
        "            label_num = len(label_ints)\n",
        "            label_count = 0\n",
        "            for idx, coln in enumerate(colns):\n",
        "                col = {}\n",
        "                col[\"name\"] = coln\n",
        "                col[\"value\"] = values[idx]\n",
        "                if coln != \"*\":\n",
        "                    col[\"name\"] = \" \".join(coln.split(\" \")[1:])\n",
        "                col[\"label_int\"] = 0\n",
        "                if coln in label_ints.keys():\n",
        "                    col[\"label_int\"] = label_ints[coln]\n",
        "                    label_count += 1\n",
        "                cols.append(col)\n",
        "            \n",
        "            assert label_count >= label_num\n",
        "            if label_count > label_num:\n",
        "                dup_count += 1\n",
        "#                 print(\"\\nWARNING: deplicated columns!\")\n",
        "#                 print(\"label_ints: \", label_ints)\n",
        "#                 print(\"colns: \", colns)\n",
        "            \n",
        "            col_list = []\n",
        "            label_list = []\n",
        "            value_list = []\n",
        "            col_count = 0\n",
        "            for i, col in enumerate(cols):\n",
        "                if col_count > 40 and col[\"label_int\"] == 0:\n",
        "                    continue\n",
        "                col_list.append(col[\"name\"])\n",
        "                value_list.append(col[\"value\"])\n",
        "                col_count += 1\n",
        "                label_list.append(int(col[\"label_int\"]))\n",
        "            assert len(col_list) == len(value_list)\n",
        "            \n",
        "            assert question.count(prev_token) + 1 == len(context_label_list)\n",
        "            \n",
        "            label_str = \" \".join([str(k) for k in label_list])\n",
        "            q_col_str = \"<s> \" + question.lower() + \" </s> \" + \" </s> \".join(col_list).strip() + \" </s> \"\n",
        "            example_str = q_col_str + \" ||| \" + label_str + \" ||| \" + \" \".join([str(x) for x in context_label_list])\n",
        "            tokens = tokenizer.tokenize(q_col_str)\n",
        "            if len(tokens) > MAX_TOKEN_LEN:\n",
        "                continue\n",
        "                \n",
        "            data_json.append({\"question\": question.lower(),\n",
        "                              \"columns\": col_list,\n",
        "                              \"rows\": [value_list],\n",
        "                              \"column_labels\": label_list,\n",
        "                              \"example_str\": example_str,\n",
        "                              \"context_labels\": context_label_list\n",
        "                             })\n",
        "            pro_count += 1\n",
        "\n",
        "    print(\"total line: \", line_count)\n",
        "    print(\"skiped line: \", skip_count)\n",
        "    print(\"dup line: \", dup_count)\n",
        "    print(\"pro line: \", pro_count)\n",
        "    \n",
        "    return data_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jDiEYNeIoqQ",
        "outputId": "4800c622-1000-4783-9674-472856bf4a58"
      },
      "source": [
        "data_json = write_final_file(augment_context_all_spider_wikisql)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total line:  55477\n",
            "skiped line:  0\n",
            "dup line:  0\n",
            "pro line:  43726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNFK7Um4IoqR"
      },
      "source": [
        "with open('data/augment_spider_wikisql_context.json', 'w') as outfile:\n",
        "    json.dump(data_json, outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TFqpYpmIoqR"
      },
      "source": [
        "import codecs\n",
        "def write_to_file(sql_data, output_file):\n",
        "    table_file = codecs.open(output_file, \"w\", \"utf-8\")\n",
        "    valid_count = 0\n",
        "    num_sql = len(sql_data)\n",
        "    check_point = int(num_sql*0.1)\n",
        "    max_col_num = 0\n",
        "    unique_labels = set()\n",
        "    skip_count = 0\n",
        "    for tn, sql_one in enumerate(sql_data):\n",
        "        if tn % check_point == 0:\n",
        "            print(\"processed: \", str(round(tn/num_sql, 2)))\n",
        "        example_str = sql_one['example_str']\n",
        "        valid_count += 1\n",
        "        table_file.write(example_str.strip().replace(\"\\n\", \"\"))\n",
        "        #add column names in another new line\n",
        "        table_file.write(\"\\n\")\n",
        "\n",
        "    table_file.close()\n",
        "\n",
        "    return valid_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upZ51zbNIoqR",
        "outputId": "13a64262-85e0-45be-e736-630baa01d439"
      },
      "source": [
        "write_to_file(data_json, \"data/augment_spider_wikisql_context.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processed:  0.0\n",
            "processed:  0.1\n",
            "processed:  0.2\n",
            "processed:  0.3\n",
            "processed:  0.4\n",
            "processed:  0.5\n",
            "processed:  0.6\n",
            "processed:  0.7\n",
            "processed:  0.8\n",
            "processed:  0.9\n",
            "processed:  1.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "43726"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivuiJ9p3IoqR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LOKWnfjgIoqR"
      },
      "source": [
        "two_count = 0\n",
        "for schema, examples in augment_fourth_spider_wikisql.items():\n",
        "    if two_count > 100:\n",
        "        break\n",
        "    for ex in examples:\n",
        "        two_count += 1\n",
        "        sql_pattern = ex[5]\n",
        "        columns_all_prev = ex[6]\n",
        "        question_prev = ex[0]\n",
        "        sql_prev = ex[1]\n",
        "        col_labels_prev = ex[2]\n",
        "        q_slot_values_prev = ex[3]\n",
        "        slot_values_prev = ex[4]\n",
        "        context_label_list = ex[7]\n",
        "        print(\"\\nsql_pattern: \", sql_pattern)\n",
        "        print(\"question: \", question_prev)\n",
        "        print(\"sql: \", sql_prev)\n",
        "        print(\"column labels: \", col_labels_prev)\n",
        "        print(\"slot values: \", slot_values_prev)\n",
        "        print(\"context_label_list: \", context_label_list)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ7TcdrfIoqR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}